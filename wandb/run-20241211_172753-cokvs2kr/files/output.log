Created new wandb run! cokvs2kr
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02930
Policy Entropy: 4.49946
Value Function Loss: nan

Mean KL Divergence: 0.00007
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.68358
Value Function Update Magnitude: 0.59329

Collected Steps per Second: 13,257.65526
Overall Steps per Second: 8,329.81998

Timestep Collection Time: 3.77367
Timestep Consumption Time: 2.23246
PPO Batch Consumption Time: 0.59106
Total Iteration Time: 6.00613

Cumulative Model Updates: 2
Cumulative Timesteps: 50,030

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00738
Policy Entropy: 4.49683
Value Function Loss: 0.26111

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.00741
Policy Update Magnitude: 0.93148
Value Function Update Magnitude: 0.77575

Collected Steps per Second: 13,877.69882
Overall Steps per Second: 7,408.31188

Timestep Collection Time: 3.60377
Timestep Consumption Time: 3.14703
PPO Batch Consumption Time: 0.49608
Total Iteration Time: 6.75080

Cumulative Model Updates: 6
Cumulative Timesteps: 100,042

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 100042...
Checkpoint 100042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00982
Policy Entropy: 4.49006
Value Function Loss: 0.55977

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06893
Policy Update Magnitude: 1.02818
Value Function Update Magnitude: 1.12947

Collected Steps per Second: 13,301.32890
Overall Steps per Second: 6,119.85830

Timestep Collection Time: 3.76173
Timestep Consumption Time: 4.41428
PPO Batch Consumption Time: 0.55317
Total Iteration Time: 8.17601

Cumulative Model Updates: 12
Cumulative Timesteps: 150,078

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04589
Policy Entropy: 4.48973
Value Function Loss: 0.66705

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 0.92483
Value Function Update Magnitude: 1.15830

Collected Steps per Second: 12,137.67320
Overall Steps per Second: 5,706.29025

Timestep Collection Time: 4.12138
Timestep Consumption Time: 4.64508
PPO Batch Consumption Time: 0.56636
Total Iteration Time: 8.76647

Cumulative Model Updates: 18
Cumulative Timesteps: 200,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 200102...
Checkpoint 200102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01104
Policy Entropy: 4.48688
Value Function Loss: 0.55222

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03262
Policy Update Magnitude: 0.90396
Value Function Update Magnitude: 0.87648

Collected Steps per Second: 12,997.57318
Overall Steps per Second: 6,128.30982

Timestep Collection Time: 3.84733
Timestep Consumption Time: 4.31250
PPO Batch Consumption Time: 0.54392
Total Iteration Time: 8.15984

Cumulative Model Updates: 24
Cumulative Timesteps: 250,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01458
Policy Entropy: 4.48480
Value Function Loss: 0.38037

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.01325
Policy Update Magnitude: 0.81403
Value Function Update Magnitude: 0.52852

Collected Steps per Second: 13,486.22649
Overall Steps per Second: 6,355.73608

Timestep Collection Time: 3.70882
Timestep Consumption Time: 4.16092
PPO Batch Consumption Time: 0.49006
Total Iteration Time: 7.86974

Cumulative Model Updates: 30
Cumulative Timesteps: 300,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 300126...
Checkpoint 300126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02969
Policy Entropy: 4.48669
Value Function Loss: 0.10395

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01269
Policy Update Magnitude: 0.66897
Value Function Update Magnitude: 0.44567

Collected Steps per Second: 13,636.64535
Overall Steps per Second: 6,423.15224

Timestep Collection Time: 3.66747
Timestep Consumption Time: 4.11874
PPO Batch Consumption Time: 0.49247
Total Iteration Time: 7.78621

Cumulative Model Updates: 36
Cumulative Timesteps: 350,138

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01955
Policy Entropy: 4.48901
Value Function Loss: 0.08254

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.01807
Policy Update Magnitude: 0.56397
Value Function Update Magnitude: 0.31695

Collected Steps per Second: 13,187.16257
Overall Steps per Second: 6,180.05395

Timestep Collection Time: 3.79323
Timestep Consumption Time: 4.30087
PPO Batch Consumption Time: 0.52796
Total Iteration Time: 8.09410

Cumulative Model Updates: 42
Cumulative Timesteps: 400,160

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 400160...
Checkpoint 400160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01666
Policy Entropy: 4.48877
Value Function Loss: 0.06704

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.01275
Policy Update Magnitude: 0.49901
Value Function Update Magnitude: 0.24547

Collected Steps per Second: 13,438.92336
Overall Steps per Second: 6,168.74319

Timestep Collection Time: 3.72098
Timestep Consumption Time: 4.38537
PPO Batch Consumption Time: 0.53992
Total Iteration Time: 8.10635

Cumulative Model Updates: 48
Cumulative Timesteps: 450,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04157
Policy Entropy: 4.48992
Value Function Loss: 0.04397

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.00569
Policy Update Magnitude: 0.48581
Value Function Update Magnitude: 0.20418

Collected Steps per Second: 13,726.55566
Overall Steps per Second: 6,382.43477

Timestep Collection Time: 3.64345
Timestep Consumption Time: 4.19243
PPO Batch Consumption Time: 0.50963
Total Iteration Time: 7.83588

Cumulative Model Updates: 54
Cumulative Timesteps: 500,178

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 500178...
Checkpoint 500178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00387
Policy Entropy: 4.48881
Value Function Loss: 0.03093

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.00650
Policy Update Magnitude: 0.49912
Value Function Update Magnitude: 0.21249

Collected Steps per Second: 13,363.17093
Overall Steps per Second: 6,228.93300

Timestep Collection Time: 3.74297
Timestep Consumption Time: 4.28697
PPO Batch Consumption Time: 0.51625
Total Iteration Time: 8.02995

Cumulative Model Updates: 60
Cumulative Timesteps: 550,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01679
Policy Entropy: 4.48703
Value Function Loss: 0.03089

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.51554
Value Function Update Magnitude: 0.26946

Collected Steps per Second: 13,526.81140
Overall Steps per Second: 6,383.69222

Timestep Collection Time: 3.69740
Timestep Consumption Time: 4.13725
PPO Batch Consumption Time: 0.49639
Total Iteration Time: 7.83465

Cumulative Model Updates: 66
Cumulative Timesteps: 600,210

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 600210...
Checkpoint 600210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03682
Policy Entropy: 4.48767
Value Function Loss: 0.03315

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01293
Policy Update Magnitude: 0.51682
Value Function Update Magnitude: 0.31432

Collected Steps per Second: 13,324.85393
Overall Steps per Second: 6,151.07995

Timestep Collection Time: 3.75404
Timestep Consumption Time: 4.37819
PPO Batch Consumption Time: 0.53610
Total Iteration Time: 8.13223

Cumulative Model Updates: 72
Cumulative Timesteps: 650,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04325
Policy Entropy: 4.48988
Value Function Loss: 0.04993

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.56132
Value Function Update Magnitude: 0.34658

Collected Steps per Second: 12,635.08611
Overall Steps per Second: 6,249.27444

Timestep Collection Time: 3.95882
Timestep Consumption Time: 4.04531
PPO Batch Consumption Time: 0.48415
Total Iteration Time: 8.00413

Cumulative Model Updates: 78
Cumulative Timesteps: 700,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 700252...
Checkpoint 700252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02238
Policy Entropy: 4.48490
Value Function Loss: 0.05887

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.03954
Policy Update Magnitude: 0.63000
Value Function Update Magnitude: 0.39439

Collected Steps per Second: 13,848.74956
Overall Steps per Second: 6,498.42274

Timestep Collection Time: 3.61318
Timestep Consumption Time: 4.08684
PPO Batch Consumption Time: 0.49713
Total Iteration Time: 7.70002

Cumulative Model Updates: 84
Cumulative Timesteps: 750,290

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04724
Policy Entropy: 4.48081
Value Function Loss: 0.04551

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.65667
Value Function Update Magnitude: 0.37925

Collected Steps per Second: 13,762.49570
Overall Steps per Second: 6,364.01097

Timestep Collection Time: 3.63379
Timestep Consumption Time: 4.22446
PPO Batch Consumption Time: 0.50431
Total Iteration Time: 7.85825

Cumulative Model Updates: 90
Cumulative Timesteps: 800,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 800300...
Checkpoint 800300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03841
Policy Entropy: 4.48597
Value Function Loss: 0.03303

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01238
Policy Update Magnitude: 0.64036
Value Function Update Magnitude: 0.36114

Collected Steps per Second: 13,301.82278
Overall Steps per Second: 6,363.43872

Timestep Collection Time: 3.76204
Timestep Consumption Time: 4.10195
PPO Batch Consumption Time: 0.49495
Total Iteration Time: 7.86399

Cumulative Model Updates: 96
Cumulative Timesteps: 850,342

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03800
Policy Entropy: 4.48887
Value Function Loss: 0.03533

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02815
Policy Update Magnitude: 0.60583
Value Function Update Magnitude: 0.33501

Collected Steps per Second: 13,901.59755
Overall Steps per Second: 6,194.57501

Timestep Collection Time: 3.59728
Timestep Consumption Time: 4.47559
PPO Batch Consumption Time: 0.55781
Total Iteration Time: 8.07287

Cumulative Model Updates: 102
Cumulative Timesteps: 900,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 900350...
Checkpoint 900350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02981
Policy Entropy: 4.48843
Value Function Loss: 0.03621

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02270
Policy Update Magnitude: 0.62968
Value Function Update Magnitude: 0.32436

Collected Steps per Second: 13,498.76338
Overall Steps per Second: 6,197.02750

Timestep Collection Time: 3.70404
Timestep Consumption Time: 4.36434
PPO Batch Consumption Time: 0.54064
Total Iteration Time: 8.06838

Cumulative Model Updates: 108
Cumulative Timesteps: 950,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02040
Policy Entropy: 4.48932
Value Function Loss: 0.03254

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.01118
Policy Update Magnitude: 0.63200
Value Function Update Magnitude: 0.28106

Collected Steps per Second: 13,533.75565
Overall Steps per Second: 6,105.88984

Timestep Collection Time: 3.69580
Timestep Consumption Time: 4.49597
PPO Batch Consumption Time: 0.55478
Total Iteration Time: 8.19176

Cumulative Model Updates: 114
Cumulative Timesteps: 1,000,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1000368...
Checkpoint 1000368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00652
Policy Entropy: 4.49453
Value Function Loss: 0.01438

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02232
Policy Update Magnitude: 0.54416
Value Function Update Magnitude: 0.23042

Collected Steps per Second: 13,289.92666
Overall Steps per Second: 6,330.83594

Timestep Collection Time: 3.76375
Timestep Consumption Time: 4.13726
PPO Batch Consumption Time: 0.49325
Total Iteration Time: 7.90101

Cumulative Model Updates: 120
Cumulative Timesteps: 1,050,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00123
Policy Entropy: 4.49424
Value Function Loss: 0.03092

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.00791
Policy Update Magnitude: 0.55635
Value Function Update Magnitude: 0.20479

Collected Steps per Second: 14,553.51861
Overall Steps per Second: 6,718.45686

Timestep Collection Time: 3.43738
Timestep Consumption Time: 4.00867
PPO Batch Consumption Time: 0.49482
Total Iteration Time: 7.44606

Cumulative Model Updates: 126
Cumulative Timesteps: 1,100,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1100414...
Checkpoint 1100414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02180
Policy Entropy: 4.49099
Value Function Loss: 0.04818

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01150
Policy Update Magnitude: 0.68898
Value Function Update Magnitude: 0.31029

Collected Steps per Second: 13,707.79876
Overall Steps per Second: 6,360.81152

Timestep Collection Time: 3.65033
Timestep Consumption Time: 4.21628
PPO Batch Consumption Time: 0.50799
Total Iteration Time: 7.86661

Cumulative Model Updates: 132
Cumulative Timesteps: 1,150,452

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01589
Policy Entropy: 4.48866
Value Function Loss: 0.04527

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.01723
Policy Update Magnitude: 0.74382
Value Function Update Magnitude: 0.38386

Collected Steps per Second: 13,833.06270
Overall Steps per Second: 6,361.88248

Timestep Collection Time: 3.61641
Timestep Consumption Time: 4.24699
PPO Batch Consumption Time: 0.51863
Total Iteration Time: 7.86340

Cumulative Model Updates: 138
Cumulative Timesteps: 1,200,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1200478...
Checkpoint 1200478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00867
Policy Entropy: 4.48975
Value Function Loss: 0.04361

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.01486
Policy Update Magnitude: 0.75763
Value Function Update Magnitude: 0.38302

Collected Steps per Second: 13,381.66746
Overall Steps per Second: 6,335.38861

Timestep Collection Time: 3.73870
Timestep Consumption Time: 4.15821
PPO Batch Consumption Time: 0.50100
Total Iteration Time: 7.89691

Cumulative Model Updates: 144
Cumulative Timesteps: 1,250,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01618
Policy Entropy: 4.48695
Value Function Loss: 0.04358

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.03447
Policy Update Magnitude: 0.77104
Value Function Update Magnitude: 0.43474

Collected Steps per Second: 13,837.72704
Overall Steps per Second: 6,443.05236

Timestep Collection Time: 3.61562
Timestep Consumption Time: 4.14964
PPO Batch Consumption Time: 0.50152
Total Iteration Time: 7.76526

Cumulative Model Updates: 150
Cumulative Timesteps: 1,300,540

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1300540...
Checkpoint 1300540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00462
Policy Entropy: 4.48592
Value Function Loss: 0.04286

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02852
Policy Update Magnitude: 0.77352
Value Function Update Magnitude: 0.53088

Collected Steps per Second: 13,019.32919
Overall Steps per Second: 6,017.72077

Timestep Collection Time: 3.84183
Timestep Consumption Time: 4.46996
PPO Batch Consumption Time: 0.54611
Total Iteration Time: 8.31178

Cumulative Model Updates: 156
Cumulative Timesteps: 1,350,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01414
Policy Entropy: 4.48936
Value Function Loss: 0.02647

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.00560
Policy Update Magnitude: 0.71583
Value Function Update Magnitude: 0.53870

Collected Steps per Second: 13,530.87469
Overall Steps per Second: 6,397.91977

Timestep Collection Time: 3.69806
Timestep Consumption Time: 4.12292
PPO Batch Consumption Time: 0.48693
Total Iteration Time: 7.82098

Cumulative Model Updates: 162
Cumulative Timesteps: 1,400,596

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1400596...
Checkpoint 1400596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00031
Policy Entropy: 4.49170
Value Function Loss: 0.01972

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.01115
Policy Update Magnitude: 0.67679
Value Function Update Magnitude: 0.44982

Collected Steps per Second: 14,122.35444
Overall Steps per Second: 6,396.92555

Timestep Collection Time: 3.54247
Timestep Consumption Time: 4.27816
PPO Batch Consumption Time: 0.51730
Total Iteration Time: 7.82063

Cumulative Model Updates: 168
Cumulative Timesteps: 1,450,624

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04892
Policy Entropy: 4.49046
Value Function Loss: 0.01749

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01165
Policy Update Magnitude: 0.68993
Value Function Update Magnitude: 0.42726

Collected Steps per Second: 13,135.52760
Overall Steps per Second: 6,280.26867

Timestep Collection Time: 3.80769
Timestep Consumption Time: 4.15630
PPO Batch Consumption Time: 0.48707
Total Iteration Time: 7.96399

Cumulative Model Updates: 174
Cumulative Timesteps: 1,500,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1500640...
Checkpoint 1500640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06220
Policy Entropy: 4.49043
Value Function Loss: 0.01888

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.00793
Policy Update Magnitude: 0.66778
Value Function Update Magnitude: 0.45138

Collected Steps per Second: 12,856.96006
Overall Steps per Second: 6,418.44801

Timestep Collection Time: 3.89034
Timestep Consumption Time: 3.90251
PPO Batch Consumption Time: 0.48706
Total Iteration Time: 7.79285

Cumulative Model Updates: 180
Cumulative Timesteps: 1,550,658

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01773
Policy Entropy: 4.48940
Value Function Loss: 0.00900

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.00973
Policy Update Magnitude: 0.65961
Value Function Update Magnitude: 0.39684

Collected Steps per Second: 13,463.71853
Overall Steps per Second: 6,406.46097

Timestep Collection Time: 3.71591
Timestep Consumption Time: 4.09339
PPO Batch Consumption Time: 0.48375
Total Iteration Time: 7.80930

Cumulative Model Updates: 186
Cumulative Timesteps: 1,600,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1600688...
Checkpoint 1600688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00864
Policy Entropy: 4.48799
Value Function Loss: 0.03129

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01406
Policy Update Magnitude: 0.73631
Value Function Update Magnitude: 0.39746

Collected Steps per Second: 13,708.36063
Overall Steps per Second: 6,498.84057

Timestep Collection Time: 3.64945
Timestep Consumption Time: 4.04854
PPO Batch Consumption Time: 0.49279
Total Iteration Time: 7.69799

Cumulative Model Updates: 192
Cumulative Timesteps: 1,650,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06198
Policy Entropy: 4.48484
Value Function Loss: 0.04801

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02052
Policy Update Magnitude: 0.87857
Value Function Update Magnitude: 0.49756

Collected Steps per Second: 13,917.73153
Overall Steps per Second: 6,433.03566

Timestep Collection Time: 3.59441
Timestep Consumption Time: 4.18201
PPO Batch Consumption Time: 0.49549
Total Iteration Time: 7.77642

Cumulative Model Updates: 198
Cumulative Timesteps: 1,700,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1700742...
Checkpoint 1700742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01013
Policy Entropy: 4.48398
Value Function Loss: 0.06579

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.95389
Value Function Update Magnitude: 0.65527

Collected Steps per Second: 13,633.30529
Overall Steps per Second: 6,230.24561

Timestep Collection Time: 3.66954
Timestep Consumption Time: 4.36032
PPO Batch Consumption Time: 0.53196
Total Iteration Time: 8.02986

Cumulative Model Updates: 204
Cumulative Timesteps: 1,750,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02904
Policy Entropy: 4.48566
Value Function Loss: 0.06685

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02230
Policy Update Magnitude: 1.00398
Value Function Update Magnitude: 0.67430

Collected Steps per Second: 13,391.55899
Overall Steps per Second: 5,843.24364

Timestep Collection Time: 3.73608
Timestep Consumption Time: 4.82628
PPO Batch Consumption Time: 0.59456
Total Iteration Time: 8.56237

Cumulative Model Updates: 210
Cumulative Timesteps: 1,800,802

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1800802...
Checkpoint 1800802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02741
Policy Entropy: 4.48376
Value Function Loss: 0.05837

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02446
Policy Update Magnitude: 0.98093
Value Function Update Magnitude: 0.71691

Collected Steps per Second: 12,738.11438
Overall Steps per Second: 5,928.71806

Timestep Collection Time: 3.92617
Timestep Consumption Time: 4.50938
PPO Batch Consumption Time: 0.56337
Total Iteration Time: 8.43555

Cumulative Model Updates: 216
Cumulative Timesteps: 1,850,814

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01445
Policy Entropy: 4.48508
Value Function Loss: 0.05171

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02083
Policy Update Magnitude: 0.92046
Value Function Update Magnitude: 0.71978

Collected Steps per Second: 11,173.41073
Overall Steps per Second: 5,520.13579

Timestep Collection Time: 4.47670
Timestep Consumption Time: 4.58467
PPO Batch Consumption Time: 0.58071
Total Iteration Time: 9.06137

Cumulative Model Updates: 222
Cumulative Timesteps: 1,900,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1900834...
Checkpoint 1900834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04841
Policy Entropy: 4.48557
Value Function Loss: 0.05369

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02585
Policy Update Magnitude: 0.88738
Value Function Update Magnitude: 0.68178

Collected Steps per Second: 12,725.29188
Overall Steps per Second: 6,101.63548

Timestep Collection Time: 3.93138
Timestep Consumption Time: 4.26773
PPO Batch Consumption Time: 0.50937
Total Iteration Time: 8.19911

Cumulative Model Updates: 228
Cumulative Timesteps: 1,950,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00581
Policy Entropy: 4.48529
Value Function Loss: 0.07213

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.96020
Value Function Update Magnitude: 0.63392

Collected Steps per Second: 13,231.10478
Overall Steps per Second: 6,470.26677

Timestep Collection Time: 3.78018
Timestep Consumption Time: 3.94995
PPO Batch Consumption Time: 0.46936
Total Iteration Time: 7.73013

Cumulative Model Updates: 234
Cumulative Timesteps: 2,000,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2000878...
Checkpoint 2000878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05222
Policy Entropy: 4.48517
Value Function Loss: 0.05957

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02230
Policy Update Magnitude: 0.94116
Value Function Update Magnitude: 0.57649

Collected Steps per Second: 13,421.26758
Overall Steps per Second: 6,376.54671

Timestep Collection Time: 3.72603
Timestep Consumption Time: 4.11646
PPO Batch Consumption Time: 0.48532
Total Iteration Time: 7.84249

Cumulative Model Updates: 240
Cumulative Timesteps: 2,050,886

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06471
Policy Entropy: 4.48484
Value Function Loss: 0.05468

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.01776
Policy Update Magnitude: 0.82724
Value Function Update Magnitude: 0.51548

Collected Steps per Second: 13,271.93165
Overall Steps per Second: 6,445.37295

Timestep Collection Time: 3.76780
Timestep Consumption Time: 3.99063
PPO Batch Consumption Time: 0.46724
Total Iteration Time: 7.75843

Cumulative Model Updates: 246
Cumulative Timesteps: 2,100,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2100892...
Checkpoint 2100892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01206
Policy Entropy: 4.48426
Value Function Loss: 0.02283

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.00894
Policy Update Magnitude: 0.75493
Value Function Update Magnitude: 0.38338

Collected Steps per Second: 13,894.53434
Overall Steps per Second: 6,623.66612

Timestep Collection Time: 3.59926
Timestep Consumption Time: 3.95094
PPO Batch Consumption Time: 0.47455
Total Iteration Time: 7.55020

Cumulative Model Updates: 252
Cumulative Timesteps: 2,150,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01345
Policy Entropy: 4.48615
Value Function Loss: 0.02019

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.01812
Policy Update Magnitude: 0.71774
Value Function Update Magnitude: 0.37686

Collected Steps per Second: 14,380.03698
Overall Steps per Second: 6,545.73092

Timestep Collection Time: 3.47718
Timestep Consumption Time: 4.16169
PPO Batch Consumption Time: 0.49211
Total Iteration Time: 7.63887

Cumulative Model Updates: 258
Cumulative Timesteps: 2,200,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2200904...
Checkpoint 2200904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02194
Policy Entropy: 4.48590
Value Function Loss: 0.01798

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02246
Policy Update Magnitude: 0.71730
Value Function Update Magnitude: 0.45847

Collected Steps per Second: 13,565.62946
Overall Steps per Second: 6,330.95433

Timestep Collection Time: 3.68638
Timestep Consumption Time: 4.21259
PPO Batch Consumption Time: 0.50846
Total Iteration Time: 7.89897

Cumulative Model Updates: 264
Cumulative Timesteps: 2,250,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04417
Policy Entropy: 4.48630
Value Function Loss: 0.01517

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01123
Policy Update Magnitude: 0.66653
Value Function Update Magnitude: 0.45367

Collected Steps per Second: 14,483.70316
Overall Steps per Second: 6,687.39077

Timestep Collection Time: 3.45326
Timestep Consumption Time: 4.02589
PPO Batch Consumption Time: 0.47300
Total Iteration Time: 7.47915

Cumulative Model Updates: 270
Cumulative Timesteps: 2,300,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2300928...
Checkpoint 2300928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00162
Policy Entropy: 4.48793
Value Function Loss: 0.02234

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02102
Policy Update Magnitude: 0.69528
Value Function Update Magnitude: 0.46074

Collected Steps per Second: 14,497.64290
Overall Steps per Second: 6,707.21923

Timestep Collection Time: 3.44884
Timestep Consumption Time: 4.00582
PPO Batch Consumption Time: 0.47060
Total Iteration Time: 7.45465

Cumulative Model Updates: 276
Cumulative Timesteps: 2,350,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05674
Policy Entropy: 4.48810
Value Function Loss: 0.03761

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02100
Policy Update Magnitude: 0.76124
Value Function Update Magnitude: 0.43285

Collected Steps per Second: 14,524.48855
Overall Steps per Second: 6,775.92210

Timestep Collection Time: 3.44315
Timestep Consumption Time: 3.93739
PPO Batch Consumption Time: 0.46565
Total Iteration Time: 7.38055

Cumulative Model Updates: 282
Cumulative Timesteps: 2,400,938

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2400938...
Checkpoint 2400938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03801
Policy Entropy: 4.48412
Value Function Loss: 0.03696

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02413
Policy Update Magnitude: 0.78954
Value Function Update Magnitude: 0.53078

Collected Steps per Second: 14,494.21127
Overall Steps per Second: 6,654.21750

Timestep Collection Time: 3.45007
Timestep Consumption Time: 4.06487
PPO Batch Consumption Time: 0.47987
Total Iteration Time: 7.51493

Cumulative Model Updates: 288
Cumulative Timesteps: 2,450,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01273
Policy Entropy: 4.48603
Value Function Loss: 0.06432

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.87018
Value Function Update Magnitude: 0.58641

Collected Steps per Second: 14,469.58321
Overall Steps per Second: 6,795.38458

Timestep Collection Time: 3.45718
Timestep Consumption Time: 3.90428
PPO Batch Consumption Time: 0.47547
Total Iteration Time: 7.36147

Cumulative Model Updates: 294
Cumulative Timesteps: 2,500,968

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2500968...
Checkpoint 2500968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04019
Policy Entropy: 4.48303
Value Function Loss: 0.09083

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.03378
Policy Update Magnitude: 1.00854
Value Function Update Magnitude: 0.76649

Collected Steps per Second: 14,462.27169
Overall Steps per Second: 6,668.83289

Timestep Collection Time: 3.45755
Timestep Consumption Time: 4.04062
PPO Batch Consumption Time: 0.48195
Total Iteration Time: 7.49816

Cumulative Model Updates: 300
Cumulative Timesteps: 2,550,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00431
Policy Entropy: 4.48625
Value Function Loss: 0.10214

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02716
Policy Update Magnitude: 1.04839
Value Function Update Magnitude: 0.90553

Collected Steps per Second: 14,430.35920
Overall Steps per Second: 6,774.54643

Timestep Collection Time: 3.46547
Timestep Consumption Time: 3.91628
PPO Batch Consumption Time: 0.47628
Total Iteration Time: 7.38175

Cumulative Model Updates: 306
Cumulative Timesteps: 2,600,980

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2600980...
Checkpoint 2600980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02559
Policy Entropy: 4.48537
Value Function Loss: 0.10849

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01808
Policy Update Magnitude: 1.06581
Value Function Update Magnitude: 0.79978

Collected Steps per Second: 14,609.43896
Overall Steps per Second: 6,701.65146

Timestep Collection Time: 3.42299
Timestep Consumption Time: 4.03905
PPO Batch Consumption Time: 0.48328
Total Iteration Time: 7.46204

Cumulative Model Updates: 312
Cumulative Timesteps: 2,650,988

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03322
Policy Entropy: 4.48387
Value Function Loss: 0.08100

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.01980
Policy Update Magnitude: 1.02895
Value Function Update Magnitude: 0.71962

Collected Steps per Second: 14,488.60358
Overall Steps per Second: 6,767.15028

Timestep Collection Time: 3.45099
Timestep Consumption Time: 3.93765
PPO Batch Consumption Time: 0.46511
Total Iteration Time: 7.38863

Cumulative Model Updates: 318
Cumulative Timesteps: 2,700,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2700988...
Checkpoint 2700988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04313
Policy Entropy: 4.48097
Value Function Loss: 0.08718

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02498
Policy Update Magnitude: 0.99807
Value Function Update Magnitude: 0.86963

Collected Steps per Second: 14,236.32910
Overall Steps per Second: 6,722.57647

Timestep Collection Time: 3.51256
Timestep Consumption Time: 3.92595
PPO Batch Consumption Time: 0.46369
Total Iteration Time: 7.43852

Cumulative Model Updates: 324
Cumulative Timesteps: 2,750,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07314
Policy Entropy: 4.47907
Value Function Loss: 0.09291

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03089
Policy Update Magnitude: 1.03624
Value Function Update Magnitude: 0.75366

Collected Steps per Second: 14,548.46769
Overall Steps per Second: 6,766.82529

Timestep Collection Time: 3.43899
Timestep Consumption Time: 3.95473
PPO Batch Consumption Time: 0.46738
Total Iteration Time: 7.39372

Cumulative Model Updates: 330
Cumulative Timesteps: 2,801,026

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2801026...
Checkpoint 2801026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02034
Policy Entropy: 4.47847
Value Function Loss: 0.08467

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02804
Policy Update Magnitude: 1.06113
Value Function Update Magnitude: 0.56175

Collected Steps per Second: 14,545.05109
Overall Steps per Second: 6,800.16426

Timestep Collection Time: 3.43938
Timestep Consumption Time: 3.91720
PPO Batch Consumption Time: 0.47243
Total Iteration Time: 7.35659

Cumulative Model Updates: 336
Cumulative Timesteps: 2,851,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02934
Policy Entropy: 4.47713
Value Function Loss: 0.04822

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.03713
Policy Update Magnitude: 0.99917
Value Function Update Magnitude: 0.46650

Collected Steps per Second: 14,585.30807
Overall Steps per Second: 6,727.30415

Timestep Collection Time: 3.42852
Timestep Consumption Time: 4.00477
PPO Batch Consumption Time: 0.46926
Total Iteration Time: 7.43329

Cumulative Model Updates: 342
Cumulative Timesteps: 2,901,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2901058...
Checkpoint 2901058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00775
Policy Entropy: 4.48076
Value Function Loss: 0.03199

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.88336
Value Function Update Magnitude: 0.48384

Collected Steps per Second: 14,463.56794
Overall Steps per Second: 6,742.21245

Timestep Collection Time: 3.45807
Timestep Consumption Time: 3.96027
PPO Batch Consumption Time: 0.46708
Total Iteration Time: 7.41834

Cumulative Model Updates: 348
Cumulative Timesteps: 2,951,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02379
Policy Entropy: 4.48134
Value Function Loss: 0.02683

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02304
Policy Update Magnitude: 0.79450
Value Function Update Magnitude: 0.52524

Collected Steps per Second: 14,844.62729
Overall Steps per Second: 6,810.94842

Timestep Collection Time: 3.36876
Timestep Consumption Time: 3.97354
PPO Batch Consumption Time: 0.47403
Total Iteration Time: 7.34230

Cumulative Model Updates: 354
Cumulative Timesteps: 3,001,082

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3001082...
Checkpoint 3001082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04936
Policy Entropy: 4.47817
Value Function Loss: 0.03020

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02408
Policy Update Magnitude: 0.80894
Value Function Update Magnitude: 0.55826

Collected Steps per Second: 14,321.73609
Overall Steps per Second: 6,646.76934

Timestep Collection Time: 3.49162
Timestep Consumption Time: 4.03174
PPO Batch Consumption Time: 0.47528
Total Iteration Time: 7.52335

Cumulative Model Updates: 360
Cumulative Timesteps: 3,051,088

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00209
Policy Entropy: 4.47869
Value Function Loss: 0.04493

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.01917
Policy Update Magnitude: 0.87333
Value Function Update Magnitude: 0.62160

Collected Steps per Second: 14,561.48781
Overall Steps per Second: 6,776.34039

Timestep Collection Time: 3.43468
Timestep Consumption Time: 3.94600
PPO Batch Consumption Time: 0.47439
Total Iteration Time: 7.38068

Cumulative Model Updates: 366
Cumulative Timesteps: 3,101,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3101102...
Checkpoint 3101102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00597
Policy Entropy: 4.47838
Value Function Loss: 0.03407

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.87102
Value Function Update Magnitude: 0.67216

Collected Steps per Second: 14,467.11381
Overall Steps per Second: 6,689.79962

Timestep Collection Time: 3.45805
Timestep Consumption Time: 4.02020
PPO Batch Consumption Time: 0.47986
Total Iteration Time: 7.47825

Cumulative Model Updates: 372
Cumulative Timesteps: 3,151,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00070
Policy Entropy: 4.47896
Value Function Loss: 0.04501

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02789
Policy Update Magnitude: 0.84035
Value Function Update Magnitude: 0.71944

Collected Steps per Second: 14,374.47491
Overall Steps per Second: 6,743.58522

Timestep Collection Time: 3.47867
Timestep Consumption Time: 3.93638
PPO Batch Consumption Time: 0.46681
Total Iteration Time: 7.41505

Cumulative Model Updates: 378
Cumulative Timesteps: 3,201,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3201134...
Checkpoint 3201134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00833
Policy Entropy: 4.48134
Value Function Loss: 0.04263

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02529
Policy Update Magnitude: 0.89784
Value Function Update Magnitude: 0.80232

Collected Steps per Second: 14,563.69717
Overall Steps per Second: 6,681.46109

Timestep Collection Time: 3.43539
Timestep Consumption Time: 4.05279
PPO Batch Consumption Time: 0.48471
Total Iteration Time: 7.48818

Cumulative Model Updates: 384
Cumulative Timesteps: 3,251,166

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02868
Policy Entropy: 4.47832
Value Function Loss: 0.05492

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 0.95538
Value Function Update Magnitude: 0.82567

Collected Steps per Second: 14,380.03243
Overall Steps per Second: 6,747.82737

Timestep Collection Time: 3.47718
Timestep Consumption Time: 3.93291
PPO Batch Consumption Time: 0.46836
Total Iteration Time: 7.41009

Cumulative Model Updates: 390
Cumulative Timesteps: 3,301,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3301168...
Checkpoint 3301168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00130
Policy Entropy: 4.47745
Value Function Loss: 0.04120

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03265
Policy Update Magnitude: 0.93200
Value Function Update Magnitude: 0.76857

Collected Steps per Second: 14,563.22409
Overall Steps per Second: 6,808.20760

Timestep Collection Time: 3.43509
Timestep Consumption Time: 3.91280
PPO Batch Consumption Time: 0.47445
Total Iteration Time: 7.34790

Cumulative Model Updates: 396
Cumulative Timesteps: 3,351,194

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04739
Policy Entropy: 4.47961
Value Function Loss: 0.03903

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.89851
Value Function Update Magnitude: 0.73945

Collected Steps per Second: 14,486.66173
Overall Steps per Second: 6,716.96925

Timestep Collection Time: 3.45173
Timestep Consumption Time: 3.99270
PPO Batch Consumption Time: 0.46813
Total Iteration Time: 7.44443

Cumulative Model Updates: 402
Cumulative Timesteps: 3,401,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3401198...
Checkpoint 3401198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04059
Policy Entropy: 4.47909
Value Function Loss: 0.02483

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02503
Policy Update Magnitude: 0.85947
Value Function Update Magnitude: 0.70822

Collected Steps per Second: 14,414.78863
Overall Steps per Second: 6,725.91652

Timestep Collection Time: 3.47060
Timestep Consumption Time: 3.96749
PPO Batch Consumption Time: 0.46879
Total Iteration Time: 7.43809

Cumulative Model Updates: 408
Cumulative Timesteps: 3,451,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00327
Policy Entropy: 4.47707
Value Function Loss: 0.03627

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02882
Policy Update Magnitude: 0.81646
Value Function Update Magnitude: 0.70732

Collected Steps per Second: 14,898.76703
Overall Steps per Second: 6,791.10240

Timestep Collection Time: 3.35665
Timestep Consumption Time: 4.00739
PPO Batch Consumption Time: 0.47095
Total Iteration Time: 7.36405

Cumulative Model Updates: 414
Cumulative Timesteps: 3,501,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3501236...
Checkpoint 3501236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00756
Policy Entropy: 4.47948
Value Function Loss: 0.02069

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.83008
Value Function Update Magnitude: 0.73316

Collected Steps per Second: 14,467.76674
Overall Steps per Second: 6,722.26491

Timestep Collection Time: 3.45596
Timestep Consumption Time: 3.98201
PPO Batch Consumption Time: 0.46786
Total Iteration Time: 7.43797

Cumulative Model Updates: 420
Cumulative Timesteps: 3,551,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02137
Policy Entropy: 4.47993
Value Function Loss: 0.02202

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02093
Policy Update Magnitude: 0.77170
Value Function Update Magnitude: 0.63307

Collected Steps per Second: 14,407.41795
Overall Steps per Second: 6,757.08877

Timestep Collection Time: 3.47141
Timestep Consumption Time: 3.93030
PPO Batch Consumption Time: 0.46949
Total Iteration Time: 7.40171

Cumulative Model Updates: 426
Cumulative Timesteps: 3,601,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3601250...
Checkpoint 3601250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04598
Policy Entropy: 4.48027
Value Function Loss: 0.02052

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01103
Policy Update Magnitude: 0.74109
Value Function Update Magnitude: 0.60495

Collected Steps per Second: 14,602.24607
Overall Steps per Second: 6,646.39757

Timestep Collection Time: 3.42714
Timestep Consumption Time: 4.10235
PPO Batch Consumption Time: 0.48579
Total Iteration Time: 7.52949

Cumulative Model Updates: 432
Cumulative Timesteps: 3,651,294

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00070
Policy Entropy: 4.48035
Value Function Loss: 0.03775

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02446
Policy Update Magnitude: 0.79993
Value Function Update Magnitude: 0.77546

Collected Steps per Second: 14,295.43849
Overall Steps per Second: 6,696.29827

Timestep Collection Time: 3.49790
Timestep Consumption Time: 3.96951
PPO Batch Consumption Time: 0.47031
Total Iteration Time: 7.46741

Cumulative Model Updates: 438
Cumulative Timesteps: 3,701,298

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3701298...
Checkpoint 3701298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03706
Policy Entropy: 4.47821
Value Function Loss: 0.02737

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02093
Policy Update Magnitude: 0.86474
Value Function Update Magnitude: 0.73533

Collected Steps per Second: 14,618.82334
Overall Steps per Second: 6,763.27695

Timestep Collection Time: 3.42148
Timestep Consumption Time: 3.97405
PPO Batch Consumption Time: 0.46714
Total Iteration Time: 7.39553

Cumulative Model Updates: 444
Cumulative Timesteps: 3,751,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00677
Policy Entropy: 4.47993
Value Function Loss: 0.03582

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02094
Policy Update Magnitude: 0.84867
Value Function Update Magnitude: 0.66427

Collected Steps per Second: 14,441.31008
Overall Steps per Second: 6,727.17112

Timestep Collection Time: 3.46326
Timestep Consumption Time: 3.97137
PPO Batch Consumption Time: 0.47019
Total Iteration Time: 7.43463

Cumulative Model Updates: 450
Cumulative Timesteps: 3,801,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3801330...
Checkpoint 3801330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02243
Policy Entropy: 4.48111
Value Function Loss: 0.03553

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.85934
Value Function Update Magnitude: 0.71055

Collected Steps per Second: 14,420.10151
Overall Steps per Second: 6,714.75855

Timestep Collection Time: 3.46946
Timestep Consumption Time: 3.98129
PPO Batch Consumption Time: 0.47594
Total Iteration Time: 7.45075

Cumulative Model Updates: 456
Cumulative Timesteps: 3,851,360

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05955
Policy Entropy: 4.47868
Value Function Loss: 0.02800

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02721
Policy Update Magnitude: 0.85827
Value Function Update Magnitude: 0.63598

Collected Steps per Second: 14,523.01828
Overall Steps per Second: 6,734.59822

Timestep Collection Time: 3.44377
Timestep Consumption Time: 3.98265
PPO Batch Consumption Time: 0.47525
Total Iteration Time: 7.42643

Cumulative Model Updates: 462
Cumulative Timesteps: 3,901,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3901374...
Checkpoint 3901374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01155
Policy Entropy: 4.47826
Value Function Loss: 0.02996

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02279
Policy Update Magnitude: 0.81977
Value Function Update Magnitude: 0.62252

Collected Steps per Second: 14,248.22585
Overall Steps per Second: 6,666.42935

Timestep Collection Time: 3.50935
Timestep Consumption Time: 3.99122
PPO Batch Consumption Time: 0.47920
Total Iteration Time: 7.50057

Cumulative Model Updates: 468
Cumulative Timesteps: 3,951,376

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02222
Policy Entropy: 4.47719
Value Function Loss: 0.03293

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02764
Policy Update Magnitude: 0.83653
Value Function Update Magnitude: 0.60240

Collected Steps per Second: 14,731.10360
Overall Steps per Second: 6,736.04074

Timestep Collection Time: 3.39472
Timestep Consumption Time: 4.02922
PPO Batch Consumption Time: 0.47815
Total Iteration Time: 7.42395

Cumulative Model Updates: 474
Cumulative Timesteps: 4,001,384

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 4001384...
Checkpoint 4001384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08212
Policy Entropy: 4.47838
Value Function Loss: 0.04726

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02865
Policy Update Magnitude: 0.92026
Value Function Update Magnitude: 0.58383

Collected Steps per Second: 14,281.58781
Overall Steps per Second: 6,630.54136

Timestep Collection Time: 3.50143
Timestep Consumption Time: 4.04034
PPO Batch Consumption Time: 0.48164
Total Iteration Time: 7.54177

Cumulative Model Updates: 480
Cumulative Timesteps: 4,051,390

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02432
Policy Entropy: 4.47577
Value Function Loss: 0.03421

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02819
Policy Update Magnitude: 0.92788
Value Function Update Magnitude: 0.64095

Collected Steps per Second: 14,355.38032
Overall Steps per Second: 6,659.21113

Timestep Collection Time: 3.48469
Timestep Consumption Time: 4.02731
PPO Batch Consumption Time: 0.48764
Total Iteration Time: 7.51200

Cumulative Model Updates: 486
Cumulative Timesteps: 4,101,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 4101414...
Checkpoint 4101414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05281
Policy Entropy: 4.47615
Value Function Loss: 0.02817

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.86250
Value Function Update Magnitude: 0.54707

Collected Steps per Second: 14,317.05298
Overall Steps per Second: 6,737.00565

Timestep Collection Time: 3.49290
Timestep Consumption Time: 3.92998
PPO Batch Consumption Time: 0.46917
Total Iteration Time: 7.42288

Cumulative Model Updates: 492
Cumulative Timesteps: 4,151,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04335
Policy Entropy: 4.47170
Value Function Loss: 0.02034

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.03554
Policy Update Magnitude: 0.81209
Value Function Update Magnitude: 0.52618

Collected Steps per Second: 14,513.76704
Overall Steps per Second: 6,809.13936

Timestep Collection Time: 3.44611
Timestep Consumption Time: 3.89931
PPO Batch Consumption Time: 0.46783
Total Iteration Time: 7.34542

Cumulative Model Updates: 498
Cumulative Timesteps: 4,201,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 4201438...
Checkpoint 4201438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01605
Policy Entropy: 4.47259
Value Function Loss: 0.03562

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03628
Policy Update Magnitude: 0.83000
Value Function Update Magnitude: 0.49534

Collected Steps per Second: 14,328.17276
Overall Steps per Second: 6,671.04251

Timestep Collection Time: 3.48963
Timestep Consumption Time: 4.00545
PPO Batch Consumption Time: 0.47414
Total Iteration Time: 7.49508

Cumulative Model Updates: 504
Cumulative Timesteps: 4,251,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00608
Policy Entropy: 4.47051
Value Function Loss: 0.03511

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.03331
Policy Update Magnitude: 0.87462
Value Function Update Magnitude: 0.51774

Collected Steps per Second: 14,502.51126
Overall Steps per Second: 6,765.77740

Timestep Collection Time: 3.44851
Timestep Consumption Time: 3.94340
PPO Batch Consumption Time: 0.47507
Total Iteration Time: 7.39191

Cumulative Model Updates: 510
Cumulative Timesteps: 4,301,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 4301450...
Checkpoint 4301450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07577
Policy Entropy: 4.46989
Value Function Loss: 0.04469

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04205
Policy Update Magnitude: 0.90661
Value Function Update Magnitude: 0.55189

Collected Steps per Second: 14,592.64708
Overall Steps per Second: 6,740.30270

Timestep Collection Time: 3.42652
Timestep Consumption Time: 3.99184
PPO Batch Consumption Time: 0.47581
Total Iteration Time: 7.41836

Cumulative Model Updates: 516
Cumulative Timesteps: 4,351,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00363
Policy Entropy: 4.47154
Value Function Loss: 0.03154

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03637
Policy Update Magnitude: 0.86429
Value Function Update Magnitude: 0.54302

Collected Steps per Second: 13,995.86120
Overall Steps per Second: 6,627.85800

Timestep Collection Time: 3.57248
Timestep Consumption Time: 3.97143
PPO Batch Consumption Time: 0.46869
Total Iteration Time: 7.54392

Cumulative Model Updates: 522
Cumulative Timesteps: 4,401,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 4401452...
Checkpoint 4401452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08713
Policy Entropy: 4.47441
Value Function Loss: 0.03192

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02455
Policy Update Magnitude: 0.81468
Value Function Update Magnitude: 0.52714

Collected Steps per Second: 14,514.84593
Overall Steps per Second: 6,640.45013

Timestep Collection Time: 3.44516
Timestep Consumption Time: 4.08535
PPO Batch Consumption Time: 0.49723
Total Iteration Time: 7.53051

Cumulative Model Updates: 528
Cumulative Timesteps: 4,451,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03784
Policy Entropy: 4.47608
Value Function Loss: 0.04607

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03049
Policy Update Magnitude: 0.87959
Value Function Update Magnitude: 0.63023

Collected Steps per Second: 14,304.45059
Overall Steps per Second: 6,695.66991

Timestep Collection Time: 3.49779
Timestep Consumption Time: 3.97480
PPO Batch Consumption Time: 0.46876
Total Iteration Time: 7.47259

Cumulative Model Updates: 534
Cumulative Timesteps: 4,501,492

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 4501492...
Checkpoint 4501492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02037
Policy Entropy: 4.47648
Value Function Loss: 0.03616

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03698
Policy Update Magnitude: 0.91073
Value Function Update Magnitude: 0.61264

Collected Steps per Second: 14,301.29203
Overall Steps per Second: 6,738.74860

Timestep Collection Time: 3.49675
Timestep Consumption Time: 3.92422
PPO Batch Consumption Time: 0.47072
Total Iteration Time: 7.42096

Cumulative Model Updates: 540
Cumulative Timesteps: 4,551,500

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02069
Policy Entropy: 4.47479
Value Function Loss: 0.02905

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03652
Policy Update Magnitude: 0.81745
Value Function Update Magnitude: 0.49927

Collected Steps per Second: 14,581.60462
Overall Steps per Second: 6,753.59343

Timestep Collection Time: 3.42898
Timestep Consumption Time: 3.97449
PPO Batch Consumption Time: 0.47168
Total Iteration Time: 7.40347

Cumulative Model Updates: 546
Cumulative Timesteps: 4,601,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 4601500...
Checkpoint 4601500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01278
Policy Entropy: 4.48004
Value Function Loss: 0.01195

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01495
Policy Update Magnitude: 0.71264
Value Function Update Magnitude: 0.41429

Collected Steps per Second: 14,225.12281
Overall Steps per Second: 6,754.94885

Timestep Collection Time: 3.51660
Timestep Consumption Time: 3.88894
PPO Batch Consumption Time: 0.46585
Total Iteration Time: 7.40553

Cumulative Model Updates: 552
Cumulative Timesteps: 4,651,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01717
Policy Entropy: 4.48220
Value Function Loss: 0.03051

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01377
Policy Update Magnitude: 0.71734
Value Function Update Magnitude: 0.43244

Collected Steps per Second: 14,897.16921
Overall Steps per Second: 6,782.45938

Timestep Collection Time: 3.35795
Timestep Consumption Time: 4.01754
PPO Batch Consumption Time: 0.47164
Total Iteration Time: 7.37550

Cumulative Model Updates: 558
Cumulative Timesteps: 4,701,548

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 4701548...
Checkpoint 4701548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02929
Policy Entropy: 4.47931
Value Function Loss: 0.05400

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.91960
Value Function Update Magnitude: 0.56172

Collected Steps per Second: 14,402.42384
Overall Steps per Second: 6,689.73970

Timestep Collection Time: 3.47192
Timestep Consumption Time: 4.00281
PPO Batch Consumption Time: 0.47421
Total Iteration Time: 7.47473

Cumulative Model Updates: 564
Cumulative Timesteps: 4,751,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11908
Policy Entropy: 4.47410
Value Function Loss: 0.05119

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04240
Policy Update Magnitude: 0.99521
Value Function Update Magnitude: 0.55287

Collected Steps per Second: 14,626.05421
Overall Steps per Second: 6,835.04920

Timestep Collection Time: 3.41856
Timestep Consumption Time: 3.89668
PPO Batch Consumption Time: 0.46296
Total Iteration Time: 7.31524

Cumulative Model Updates: 570
Cumulative Timesteps: 4,801,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 4801552...
Checkpoint 4801552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01359
Policy Entropy: 4.47081
Value Function Loss: 0.04081

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03588
Policy Update Magnitude: 0.96232
Value Function Update Magnitude: 0.56273

Collected Steps per Second: 14,302.08747
Overall Steps per Second: 6,712.53877

Timestep Collection Time: 3.49753
Timestep Consumption Time: 3.95449
PPO Batch Consumption Time: 0.46626
Total Iteration Time: 7.45202

Cumulative Model Updates: 576
Cumulative Timesteps: 4,851,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00851
Policy Entropy: 4.47336
Value Function Loss: 0.03674

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02758
Policy Update Magnitude: 0.90082
Value Function Update Magnitude: 0.56922

Collected Steps per Second: 14,613.58643
Overall Steps per Second: 6,662.88365

Timestep Collection Time: 3.42243
Timestep Consumption Time: 4.08393
PPO Batch Consumption Time: 0.48738
Total Iteration Time: 7.50636

Cumulative Model Updates: 582
Cumulative Timesteps: 4,901,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 4901588...
Checkpoint 4901588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00109
Policy Entropy: 4.47192
Value Function Loss: 0.07214

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03323
Policy Update Magnitude: 0.96138
Value Function Update Magnitude: 0.55515

Collected Steps per Second: 14,367.30044
Overall Steps per Second: 6,656.83550

Timestep Collection Time: 3.48012
Timestep Consumption Time: 4.03095
PPO Batch Consumption Time: 0.47289
Total Iteration Time: 7.51108

Cumulative Model Updates: 588
Cumulative Timesteps: 4,951,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03251
Policy Entropy: 4.46842
Value Function Loss: 0.07502

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.03721
Policy Update Magnitude: 1.04744
Value Function Update Magnitude: 0.50493

Collected Steps per Second: 14,779.47392
Overall Steps per Second: 6,812.64613

Timestep Collection Time: 3.38456
Timestep Consumption Time: 3.95796
PPO Batch Consumption Time: 0.46565
Total Iteration Time: 7.34252

Cumulative Model Updates: 594
Cumulative Timesteps: 5,001,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 5001610...
Checkpoint 5001610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00856
Policy Entropy: 4.46623
Value Function Loss: 0.06736

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.04855
Policy Update Magnitude: 1.03632
Value Function Update Magnitude: 0.53508

Collected Steps per Second: 14,210.52013
Overall Steps per Second: 6,713.97030

Timestep Collection Time: 3.52007
Timestep Consumption Time: 3.93037
PPO Batch Consumption Time: 0.46465
Total Iteration Time: 7.45044

Cumulative Model Updates: 600
Cumulative Timesteps: 5,051,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02857
Policy Entropy: 4.46985
Value Function Loss: 0.02997

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02864
Policy Update Magnitude: 0.93497
Value Function Update Magnitude: 0.51118

Collected Steps per Second: 14,428.81646
Overall Steps per Second: 6,776.30591

Timestep Collection Time: 3.46667
Timestep Consumption Time: 3.91493
PPO Batch Consumption Time: 0.46744
Total Iteration Time: 7.38160

Cumulative Model Updates: 606
Cumulative Timesteps: 5,101,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 5101652...
Checkpoint 5101652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06815
Policy Entropy: 4.47126
Value Function Loss: 0.03387

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03001
Policy Update Magnitude: 0.85461
Value Function Update Magnitude: 0.47746

Collected Steps per Second: 14,229.43913
Overall Steps per Second: 6,704.84043

Timestep Collection Time: 3.51426
Timestep Consumption Time: 3.94393
PPO Batch Consumption Time: 0.46867
Total Iteration Time: 7.45819

Cumulative Model Updates: 612
Cumulative Timesteps: 5,151,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01505
Policy Entropy: 4.47071
Value Function Loss: 0.03373

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.03595
Policy Update Magnitude: 0.86092
Value Function Update Magnitude: 0.57909

Collected Steps per Second: 14,370.12843
Overall Steps per Second: 6,774.22893

Timestep Collection Time: 3.48083
Timestep Consumption Time: 3.90303
PPO Batch Consumption Time: 0.46798
Total Iteration Time: 7.38387

Cumulative Model Updates: 618
Cumulative Timesteps: 5,201,678

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 5201678...
Checkpoint 5201678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00263
Policy Entropy: 4.46966
Value Function Loss: 0.03034

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03017
Policy Update Magnitude: 0.85615
Value Function Update Magnitude: 0.56820

Collected Steps per Second: 14,239.98662
Overall Steps per Second: 6,678.98131

Timestep Collection Time: 3.51222
Timestep Consumption Time: 3.97605
PPO Batch Consumption Time: 0.48286
Total Iteration Time: 7.48827

Cumulative Model Updates: 624
Cumulative Timesteps: 5,251,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03326
Policy Entropy: 4.46862
Value Function Loss: 0.03716

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02776
Policy Update Magnitude: 0.84726
Value Function Update Magnitude: 0.56604

Collected Steps per Second: 14,367.96054
Overall Steps per Second: 6,657.55372

Timestep Collection Time: 3.48136
Timestep Consumption Time: 4.03191
PPO Batch Consumption Time: 0.47049
Total Iteration Time: 7.51327

Cumulative Model Updates: 630
Cumulative Timesteps: 5,301,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 5301712...
Checkpoint 5301712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00555
Policy Entropy: 4.46498
Value Function Loss: 0.06336

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04424
Policy Update Magnitude: 0.94934
Value Function Update Magnitude: 0.57981

Collected Steps per Second: 14,296.87194
Overall Steps per Second: 6,736.15759

Timestep Collection Time: 3.49741
Timestep Consumption Time: 3.92552
PPO Batch Consumption Time: 0.47192
Total Iteration Time: 7.42293

Cumulative Model Updates: 636
Cumulative Timesteps: 5,351,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03044
Policy Entropy: 4.46129
Value Function Loss: 0.07473

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06087
Policy Update Magnitude: 1.03283
Value Function Update Magnitude: 0.56569

Collected Steps per Second: 14,276.71329
Overall Steps per Second: 6,665.65219

Timestep Collection Time: 3.50263
Timestep Consumption Time: 3.99941
PPO Batch Consumption Time: 0.47495
Total Iteration Time: 7.50204

Cumulative Model Updates: 642
Cumulative Timesteps: 5,401,720

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 5401720...
Checkpoint 5401720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10914
Policy Entropy: 4.46445
Value Function Loss: 0.06645

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04536
Policy Update Magnitude: 1.04941
Value Function Update Magnitude: 0.60089

Collected Steps per Second: 14,369.71042
Overall Steps per Second: 6,688.90615

Timestep Collection Time: 3.48135
Timestep Consumption Time: 3.99760
PPO Batch Consumption Time: 0.47414
Total Iteration Time: 7.47895

Cumulative Model Updates: 648
Cumulative Timesteps: 5,451,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02096
Policy Entropy: 4.46486
Value Function Loss: 0.04242

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04171
Policy Update Magnitude: 0.98924
Value Function Update Magnitude: 0.57627

Collected Steps per Second: 14,751.79006
Overall Steps per Second: 6,754.86407

Timestep Collection Time: 3.38983
Timestep Consumption Time: 4.01314
PPO Batch Consumption Time: 0.46874
Total Iteration Time: 7.40296

Cumulative Model Updates: 654
Cumulative Timesteps: 5,501,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 5501752...
Checkpoint 5501752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06237
Policy Entropy: 4.46881
Value Function Loss: 0.02704

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.03748
Policy Update Magnitude: 0.88872
Value Function Update Magnitude: 0.50653

Collected Steps per Second: 14,257.13868
Overall Steps per Second: 6,736.37736

Timestep Collection Time: 3.50814
Timestep Consumption Time: 3.91662
PPO Batch Consumption Time: 0.46619
Total Iteration Time: 7.42476

Cumulative Model Updates: 660
Cumulative Timesteps: 5,551,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04676
Policy Entropy: 4.46820
Value Function Loss: 0.03156

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03071
Policy Update Magnitude: 0.81853
Value Function Update Magnitude: 0.47074

Collected Steps per Second: 14,528.83284
Overall Steps per Second: 6,740.90284

Timestep Collection Time: 3.44295
Timestep Consumption Time: 3.97772
PPO Batch Consumption Time: 0.47752
Total Iteration Time: 7.42067

Cumulative Model Updates: 666
Cumulative Timesteps: 5,601,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 5601790...
Checkpoint 5601790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02253
Policy Entropy: 4.46952
Value Function Loss: 0.03713

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03435
Policy Update Magnitude: 0.86173
Value Function Update Magnitude: 0.52213

Collected Steps per Second: 14,177.72243
Overall Steps per Second: 6,616.40465

Timestep Collection Time: 3.52807
Timestep Consumption Time: 4.03193
PPO Batch Consumption Time: 0.47758
Total Iteration Time: 7.56000

Cumulative Model Updates: 672
Cumulative Timesteps: 5,651,810

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01786
Policy Entropy: 4.46929
Value Function Loss: 0.02809

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03029
Policy Update Magnitude: 0.87048
Value Function Update Magnitude: 0.47073

Collected Steps per Second: 14,700.34861
Overall Steps per Second: 6,664.49472

Timestep Collection Time: 3.40318
Timestep Consumption Time: 4.10346
PPO Batch Consumption Time: 0.50091
Total Iteration Time: 7.50665

Cumulative Model Updates: 678
Cumulative Timesteps: 5,701,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 5701838...
Checkpoint 5701838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02045
Policy Entropy: 4.47414
Value Function Loss: 0.02536

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02111
Policy Update Magnitude: 0.79350
Value Function Update Magnitude: 0.46467

Collected Steps per Second: 14,370.23062
Overall Steps per Second: 6,666.67955

Timestep Collection Time: 3.48109
Timestep Consumption Time: 4.02250
PPO Batch Consumption Time: 0.47610
Total Iteration Time: 7.50359

Cumulative Model Updates: 684
Cumulative Timesteps: 5,751,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02006
Policy Entropy: 4.47183
Value Function Loss: 0.01934

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.75102
Value Function Update Magnitude: 0.44132

Collected Steps per Second: 14,517.47994
Overall Steps per Second: 6,741.23899

Timestep Collection Time: 3.44619
Timestep Consumption Time: 3.97529
PPO Batch Consumption Time: 0.47095
Total Iteration Time: 7.42148

Cumulative Model Updates: 690
Cumulative Timesteps: 5,801,892

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 5801892...
Checkpoint 5801892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00694
Policy Entropy: 4.46907
Value Function Loss: 0.02759

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02397
Policy Update Magnitude: 0.76578
Value Function Update Magnitude: 0.44325

Collected Steps per Second: 14,643.27077
Overall Steps per Second: 6,761.35502

Timestep Collection Time: 3.41522
Timestep Consumption Time: 3.98123
PPO Batch Consumption Time: 0.46781
Total Iteration Time: 7.39645

Cumulative Model Updates: 696
Cumulative Timesteps: 5,851,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02407
Policy Entropy: 4.47011
Value Function Loss: 0.02746

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02360
Policy Update Magnitude: 0.79871
Value Function Update Magnitude: 0.51021

Collected Steps per Second: 14,401.15555
Overall Steps per Second: 6,712.65725

Timestep Collection Time: 3.47389
Timestep Consumption Time: 3.97890
PPO Batch Consumption Time: 0.47390
Total Iteration Time: 7.45279

Cumulative Model Updates: 702
Cumulative Timesteps: 5,901,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 5901930...
Checkpoint 5901930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00398
Policy Entropy: 4.46852
Value Function Loss: 0.03023

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02842
Policy Update Magnitude: 0.79802
Value Function Update Magnitude: 0.47705

Collected Steps per Second: 14,342.84857
Overall Steps per Second: 6,735.53369

Timestep Collection Time: 3.48717
Timestep Consumption Time: 3.93852
PPO Batch Consumption Time: 0.47585
Total Iteration Time: 7.42569

Cumulative Model Updates: 708
Cumulative Timesteps: 5,951,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01726
Policy Entropy: 4.47217
Value Function Loss: 0.01743

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01684
Policy Update Magnitude: 0.74720
Value Function Update Magnitude: 0.45122

Collected Steps per Second: 14,280.46834
Overall Steps per Second: 6,676.94977

Timestep Collection Time: 3.50339
Timestep Consumption Time: 3.98956
PPO Batch Consumption Time: 0.46567
Total Iteration Time: 7.49294

Cumulative Model Updates: 714
Cumulative Timesteps: 6,001,976

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 6001976...
Checkpoint 6001976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01453
Policy Entropy: 4.47596
Value Function Loss: 0.01558

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01696
Policy Update Magnitude: 0.66573
Value Function Update Magnitude: 0.39568

Collected Steps per Second: 14,371.70532
Overall Steps per Second: 6,697.55498

Timestep Collection Time: 3.48073
Timestep Consumption Time: 3.98827
PPO Batch Consumption Time: 0.47107
Total Iteration Time: 7.46899

Cumulative Model Updates: 720
Cumulative Timesteps: 6,052,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01378
Policy Entropy: 4.47657
Value Function Loss: 0.01950

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.01919
Policy Update Magnitude: 0.66692
Value Function Update Magnitude: 0.35320

Collected Steps per Second: 14,822.28625
Overall Steps per Second: 6,763.05563

Timestep Collection Time: 3.37384
Timestep Consumption Time: 4.02045
PPO Batch Consumption Time: 0.46998
Total Iteration Time: 7.39429

Cumulative Model Updates: 726
Cumulative Timesteps: 6,102,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 6102008...
Checkpoint 6102008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05069
Policy Entropy: 4.47626
Value Function Loss: 0.04308

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02180
Policy Update Magnitude: 0.80149
Value Function Update Magnitude: 0.34482

Collected Steps per Second: 14,289.32295
Overall Steps per Second: 6,577.51626

Timestep Collection Time: 3.50150
Timestep Consumption Time: 4.10533
PPO Batch Consumption Time: 0.49784
Total Iteration Time: 7.60682

Cumulative Model Updates: 732
Cumulative Timesteps: 6,152,042

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00994
Policy Entropy: 4.47423
Value Function Loss: 0.04797

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02587
Policy Update Magnitude: 0.87390
Value Function Update Magnitude: 0.46974

Collected Steps per Second: 14,543.25913
Overall Steps per Second: 6,772.81509

Timestep Collection Time: 3.43857
Timestep Consumption Time: 3.94507
PPO Batch Consumption Time: 0.47490
Total Iteration Time: 7.38364

Cumulative Model Updates: 738
Cumulative Timesteps: 6,202,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 6202050...
Checkpoint 6202050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02868
Policy Entropy: 4.47210
Value Function Loss: 0.04790

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.83094
Value Function Update Magnitude: 0.50565

Collected Steps per Second: 14,251.07815
Overall Steps per Second: 6,714.96314

Timestep Collection Time: 3.51033
Timestep Consumption Time: 3.93960
PPO Batch Consumption Time: 0.46832
Total Iteration Time: 7.44993

Cumulative Model Updates: 744
Cumulative Timesteps: 6,252,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00459
Policy Entropy: 4.47490
Value Function Loss: 0.03882

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02317
Policy Update Magnitude: 0.80127
Value Function Update Magnitude: 0.50251

Collected Steps per Second: 14,429.69288
Overall Steps per Second: 6,801.15987

Timestep Collection Time: 3.46896
Timestep Consumption Time: 3.89096
PPO Batch Consumption Time: 0.46704
Total Iteration Time: 7.35992

Cumulative Model Updates: 750
Cumulative Timesteps: 6,302,132

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 6302132...
Checkpoint 6302132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01458
Policy Entropy: 4.47139
Value Function Loss: 0.03467

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02832
Policy Update Magnitude: 0.79939
Value Function Update Magnitude: 0.53487

Collected Steps per Second: 14,319.43010
Overall Steps per Second: 6,720.15425

Timestep Collection Time: 3.49399
Timestep Consumption Time: 3.95107
PPO Batch Consumption Time: 0.46768
Total Iteration Time: 7.44507

Cumulative Model Updates: 756
Cumulative Timesteps: 6,352,164

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03699
Policy Entropy: 4.47214
Value Function Loss: 0.02093

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01937
Policy Update Magnitude: 0.75818
Value Function Update Magnitude: 0.46529

Collected Steps per Second: 14,510.44973
Overall Steps per Second: 6,785.54315

Timestep Collection Time: 3.44676
Timestep Consumption Time: 3.92391
PPO Batch Consumption Time: 0.46587
Total Iteration Time: 7.37067

Cumulative Model Updates: 762
Cumulative Timesteps: 6,402,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 6402178...
Checkpoint 6402178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01205
Policy Entropy: 4.47051
Value Function Loss: 0.01345

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.01585
Policy Update Magnitude: 0.65352
Value Function Update Magnitude: 0.35866

Collected Steps per Second: 14,566.43754
Overall Steps per Second: 6,731.23305

Timestep Collection Time: 3.43461
Timestep Consumption Time: 3.99791
PPO Batch Consumption Time: 0.46964
Total Iteration Time: 7.43252

Cumulative Model Updates: 768
Cumulative Timesteps: 6,452,208

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05405
Policy Entropy: 4.47646
Value Function Loss: 0.00928

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01504
Policy Update Magnitude: 0.58846
Value Function Update Magnitude: 0.29077

Collected Steps per Second: 14,457.92966
Overall Steps per Second: 6,726.96831

Timestep Collection Time: 3.45997
Timestep Consumption Time: 3.97637
PPO Batch Consumption Time: 0.47371
Total Iteration Time: 7.43634

Cumulative Model Updates: 774
Cumulative Timesteps: 6,502,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 6502232...
Checkpoint 6502232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02670
Policy Entropy: 4.47552
Value Function Loss: 0.02600

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01785
Policy Update Magnitude: 0.66390
Value Function Update Magnitude: 0.36707

Collected Steps per Second: 14,367.93455
Overall Steps per Second: 6,728.77317

Timestep Collection Time: 3.48095
Timestep Consumption Time: 3.95191
PPO Batch Consumption Time: 0.47570
Total Iteration Time: 7.43286

Cumulative Model Updates: 780
Cumulative Timesteps: 6,552,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03284
Policy Entropy: 4.47223
Value Function Loss: 0.04099

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.81910
Value Function Update Magnitude: 0.45073

Collected Steps per Second: 14,325.37254
Overall Steps per Second: 6,704.50550

Timestep Collection Time: 3.49115
Timestep Consumption Time: 3.96831
PPO Batch Consumption Time: 0.46954
Total Iteration Time: 7.45946

Cumulative Model Updates: 786
Cumulative Timesteps: 6,602,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 6602258...
Checkpoint 6602258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04463
Policy Entropy: 4.46950
Value Function Loss: 0.03452

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.85790
Value Function Update Magnitude: 0.47376

Collected Steps per Second: 14,384.80483
Overall Steps per Second: 6,828.78945

Timestep Collection Time: 3.47686
Timestep Consumption Time: 3.84713
PPO Batch Consumption Time: 0.46839
Total Iteration Time: 7.32399

Cumulative Model Updates: 792
Cumulative Timesteps: 6,652,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01209
Policy Entropy: 4.47007
Value Function Loss: 0.04749

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.83725
Value Function Update Magnitude: 0.42806

Collected Steps per Second: 14,449.42466
Overall Steps per Second: 6,667.52552

Timestep Collection Time: 3.46145
Timestep Consumption Time: 4.03998
PPO Batch Consumption Time: 0.48356
Total Iteration Time: 7.50143

Cumulative Model Updates: 798
Cumulative Timesteps: 6,702,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 6702288...
Checkpoint 6702288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08031
Policy Entropy: 4.47026
Value Function Loss: 0.04240

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.03311
Policy Update Magnitude: 0.87327
Value Function Update Magnitude: 0.41477

Collected Steps per Second: 14,298.56539
Overall Steps per Second: 6,687.32522

Timestep Collection Time: 3.49853
Timestep Consumption Time: 3.98189
PPO Batch Consumption Time: 0.46989
Total Iteration Time: 7.48042

Cumulative Model Updates: 804
Cumulative Timesteps: 6,752,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02461
Policy Entropy: 4.47071
Value Function Loss: 0.04047

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03007
Policy Update Magnitude: 0.84506
Value Function Update Magnitude: 0.41270

Collected Steps per Second: 14,883.09175
Overall Steps per Second: 6,806.50358

Timestep Collection Time: 3.36032
Timestep Consumption Time: 3.98736
PPO Batch Consumption Time: 0.46703
Total Iteration Time: 7.34768

Cumulative Model Updates: 810
Cumulative Timesteps: 6,802,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 6802324...
Checkpoint 6802324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00579
Policy Entropy: 4.47134
Value Function Loss: 0.02446

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02707
Policy Update Magnitude: 0.79575
Value Function Update Magnitude: 0.36774

Collected Steps per Second: 14,402.86232
Overall Steps per Second: 6,706.31166

Timestep Collection Time: 3.47181
Timestep Consumption Time: 3.98445
PPO Batch Consumption Time: 0.46682
Total Iteration Time: 7.45626

Cumulative Model Updates: 816
Cumulative Timesteps: 6,852,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00612
Policy Entropy: 4.47123
Value Function Loss: 0.02203

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02093
Policy Update Magnitude: 0.77805
Value Function Update Magnitude: 0.34334

Collected Steps per Second: 14,534.65864
Overall Steps per Second: 6,830.40795

Timestep Collection Time: 3.44198
Timestep Consumption Time: 3.88233
PPO Batch Consumption Time: 0.46271
Total Iteration Time: 7.32431

Cumulative Model Updates: 822
Cumulative Timesteps: 6,902,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 6902356...
Checkpoint 6902356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11737
Policy Entropy: 4.47280
Value Function Loss: 0.02453

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.01969
Policy Update Magnitude: 0.74295
Value Function Update Magnitude: 0.33114

Collected Steps per Second: 14,184.99462
Overall Steps per Second: 6,563.32891

Timestep Collection Time: 3.52556
Timestep Consumption Time: 4.09405
PPO Batch Consumption Time: 0.48822
Total Iteration Time: 7.61961

Cumulative Model Updates: 828
Cumulative Timesteps: 6,952,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00115
Policy Entropy: 4.47398
Value Function Loss: 0.02970

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02761
Policy Update Magnitude: 0.77624
Value Function Update Magnitude: 0.35045

Collected Steps per Second: 14,484.77741
Overall Steps per Second: 6,647.81551

Timestep Collection Time: 3.45411
Timestep Consumption Time: 4.07197
PPO Batch Consumption Time: 0.47971
Total Iteration Time: 7.52608

Cumulative Model Updates: 834
Cumulative Timesteps: 7,002,398

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 7002398...
Checkpoint 7002398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03578
Policy Entropy: 4.47604
Value Function Loss: 0.04563

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02825
Policy Update Magnitude: 0.82913
Value Function Update Magnitude: 0.38650

Collected Steps per Second: 14,631.11531
Overall Steps per Second: 6,788.42788

Timestep Collection Time: 3.41942
Timestep Consumption Time: 3.95047
PPO Batch Consumption Time: 0.46831
Total Iteration Time: 7.36989

Cumulative Model Updates: 840
Cumulative Timesteps: 7,052,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04624
Policy Entropy: 4.47646
Value Function Loss: 0.05482

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02948
Policy Update Magnitude: 0.88718
Value Function Update Magnitude: 0.37054

Collected Steps per Second: 14,389.10927
Overall Steps per Second: 6,703.46707

Timestep Collection Time: 3.47610
Timestep Consumption Time: 3.98541
PPO Batch Consumption Time: 0.47274
Total Iteration Time: 7.46151

Cumulative Model Updates: 846
Cumulative Timesteps: 7,102,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 7102446...
Checkpoint 7102446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01640
Policy Entropy: 4.47328
Value Function Loss: 0.04965

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02372
Policy Update Magnitude: 0.90238
Value Function Update Magnitude: 0.37233

Collected Steps per Second: 14,295.28401
Overall Steps per Second: 6,788.15220

Timestep Collection Time: 3.49794
Timestep Consumption Time: 3.86843
PPO Batch Consumption Time: 0.46952
Total Iteration Time: 7.36636

Cumulative Model Updates: 852
Cumulative Timesteps: 7,152,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05609
Policy Entropy: 4.47344
Value Function Loss: 0.03700

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02473
Policy Update Magnitude: 0.86259
Value Function Update Magnitude: 0.39832

Collected Steps per Second: 14,510.74823
Overall Steps per Second: 6,756.66441

Timestep Collection Time: 3.44765
Timestep Consumption Time: 3.95659
PPO Batch Consumption Time: 0.47315
Total Iteration Time: 7.40425

Cumulative Model Updates: 858
Cumulative Timesteps: 7,202,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 7202478...
Checkpoint 7202478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00270
Policy Entropy: 4.47330
Value Function Loss: 0.03436

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02694
Policy Update Magnitude: 0.83929
Value Function Update Magnitude: 0.35698

Collected Steps per Second: 14,308.90561
Overall Steps per Second: 6,774.73147

Timestep Collection Time: 3.49503
Timestep Consumption Time: 3.88682
PPO Batch Consumption Time: 0.46528
Total Iteration Time: 7.38184

Cumulative Model Updates: 864
Cumulative Timesteps: 7,252,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06614
Policy Entropy: 4.47533
Value Function Loss: 0.03733

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01844
Policy Update Magnitude: 0.82845
Value Function Update Magnitude: 0.36726

Collected Steps per Second: 14,653.10059
Overall Steps per Second: 6,779.69869

Timestep Collection Time: 3.41361
Timestep Consumption Time: 3.96430
PPO Batch Consumption Time: 0.46832
Total Iteration Time: 7.37791

Cumulative Model Updates: 870
Cumulative Timesteps: 7,302,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 7302508...
Checkpoint 7302508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06563
Policy Entropy: 4.47512
Value Function Loss: 0.06293

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02284
Policy Update Magnitude: 0.91086
Value Function Update Magnitude: 0.50693

Collected Steps per Second: 14,466.41552
Overall Steps per Second: 6,717.91116

Timestep Collection Time: 3.45628
Timestep Consumption Time: 3.98651
PPO Batch Consumption Time: 0.47293
Total Iteration Time: 7.44279

Cumulative Model Updates: 876
Cumulative Timesteps: 7,352,508

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02535
Policy Entropy: 4.47111
Value Function Loss: 0.05130

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03267
Policy Update Magnitude: 0.93847
Value Function Update Magnitude: 0.49108

Collected Steps per Second: 14,242.16958
Overall Steps per Second: 6,737.70620

Timestep Collection Time: 3.51084
Timestep Consumption Time: 3.91038
PPO Batch Consumption Time: 0.47247
Total Iteration Time: 7.42122

Cumulative Model Updates: 882
Cumulative Timesteps: 7,402,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 7402510...
Checkpoint 7402510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06078
Policy Entropy: 4.47175
Value Function Loss: 0.04339

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02207
Policy Update Magnitude: 0.86573
Value Function Update Magnitude: 0.45180

Collected Steps per Second: 14,253.05103
Overall Steps per Second: 6,718.01949

Timestep Collection Time: 3.50844
Timestep Consumption Time: 3.93512
PPO Batch Consumption Time: 0.46586
Total Iteration Time: 7.44356

Cumulative Model Updates: 888
Cumulative Timesteps: 7,452,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06615
Policy Entropy: 4.46886
Value Function Loss: 0.02702

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 0.78166
Value Function Update Magnitude: 0.40320

Collected Steps per Second: 14,425.43764
Overall Steps per Second: 6,733.80963

Timestep Collection Time: 3.46721
Timestep Consumption Time: 3.96038
PPO Batch Consumption Time: 0.47150
Total Iteration Time: 7.42759

Cumulative Model Updates: 894
Cumulative Timesteps: 7,502,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 7502532...
Checkpoint 7502532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05723
Policy Entropy: 4.47067
Value Function Loss: 0.03475

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.76808
Value Function Update Magnitude: 0.40949

Collected Steps per Second: 14,510.56541
Overall Steps per Second: 6,747.98506

Timestep Collection Time: 3.44618
Timestep Consumption Time: 3.96433
PPO Batch Consumption Time: 0.47339
Total Iteration Time: 7.41051

Cumulative Model Updates: 900
Cumulative Timesteps: 7,552,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07201
Policy Entropy: 4.46677
Value Function Loss: 0.03446

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.82029
Value Function Update Magnitude: 0.41548

Collected Steps per Second: 14,349.91225
Overall Steps per Second: 6,670.48235

Timestep Collection Time: 3.48574
Timestep Consumption Time: 4.01297
PPO Batch Consumption Time: 0.47065
Total Iteration Time: 7.49871

Cumulative Model Updates: 906
Cumulative Timesteps: 7,602,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 7602558...
Checkpoint 7602558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10516
Policy Entropy: 4.46577
Value Function Loss: 0.04029

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02604
Policy Update Magnitude: 0.83525
Value Function Update Magnitude: 0.41017

Collected Steps per Second: 14,250.47668
Overall Steps per Second: 6,762.49212

Timestep Collection Time: 3.50908
Timestep Consumption Time: 3.88554
PPO Batch Consumption Time: 0.46448
Total Iteration Time: 7.39461

Cumulative Model Updates: 912
Cumulative Timesteps: 7,652,564

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06214
Policy Entropy: 4.46358
Value Function Loss: 0.04191

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02992
Policy Update Magnitude: 0.83039
Value Function Update Magnitude: 0.36965

Collected Steps per Second: 14,456.99751
Overall Steps per Second: 6,740.89214

Timestep Collection Time: 3.45922
Timestep Consumption Time: 3.95967
PPO Batch Consumption Time: 0.46967
Total Iteration Time: 7.41890

Cumulative Model Updates: 918
Cumulative Timesteps: 7,702,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 7702574...
Checkpoint 7702574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00040
Policy Entropy: 4.46265
Value Function Loss: 0.04463

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03160
Policy Update Magnitude: 0.88024
Value Function Update Magnitude: 0.33438

Collected Steps per Second: 14,265.32832
Overall Steps per Second: 6,636.43370

Timestep Collection Time: 3.50724
Timestep Consumption Time: 4.03174
PPO Batch Consumption Time: 0.48471
Total Iteration Time: 7.53899

Cumulative Model Updates: 924
Cumulative Timesteps: 7,752,606

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01301
Policy Entropy: 4.46555
Value Function Loss: 0.03151

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03607
Policy Update Magnitude: 0.84278
Value Function Update Magnitude: 0.35172

Collected Steps per Second: 14,758.77428
Overall Steps per Second: 6,674.29829

Timestep Collection Time: 3.38985
Timestep Consumption Time: 4.10607
PPO Batch Consumption Time: 0.49429
Total Iteration Time: 7.49592

Cumulative Model Updates: 930
Cumulative Timesteps: 7,802,636

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 7802636...
Checkpoint 7802636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00386
Policy Entropy: 4.46661
Value Function Loss: 0.02425

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02222
Policy Update Magnitude: 0.77993
Value Function Update Magnitude: 0.32511

Collected Steps per Second: 13,945.37062
Overall Steps per Second: 6,618.20775

Timestep Collection Time: 3.58771
Timestep Consumption Time: 3.97204
PPO Batch Consumption Time: 0.47243
Total Iteration Time: 7.55975

Cumulative Model Updates: 936
Cumulative Timesteps: 7,852,668

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13827
Policy Entropy: 4.46800
Value Function Loss: 0.02739

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.79045
Value Function Update Magnitude: 0.33264

Collected Steps per Second: 14,400.92912
Overall Steps per Second: 6,708.22583

Timestep Collection Time: 3.47200
Timestep Consumption Time: 3.98154
PPO Batch Consumption Time: 0.47726
Total Iteration Time: 7.45354

Cumulative Model Updates: 942
Cumulative Timesteps: 7,902,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 7902668...
Checkpoint 7902668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04827
Policy Entropy: 4.46365
Value Function Loss: 0.03706

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02790
Policy Update Magnitude: 0.82092
Value Function Update Magnitude: 0.36364

Collected Steps per Second: 14,168.32863
Overall Steps per Second: 6,625.37014

Timestep Collection Time: 3.53027
Timestep Consumption Time: 4.01920
PPO Batch Consumption Time: 0.47243
Total Iteration Time: 7.54947

Cumulative Model Updates: 948
Cumulative Timesteps: 7,952,686

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01210
Policy Entropy: 4.46556
Value Function Loss: 0.03382

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02673
Policy Update Magnitude: 0.84372
Value Function Update Magnitude: 0.42451

Collected Steps per Second: 14,488.11476
Overall Steps per Second: 6,732.46594

Timestep Collection Time: 3.45193
Timestep Consumption Time: 3.97655
PPO Batch Consumption Time: 0.47083
Total Iteration Time: 7.42848

Cumulative Model Updates: 954
Cumulative Timesteps: 8,002,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 8002698...
Checkpoint 8002698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00804
Policy Entropy: 4.46350
Value Function Loss: 0.02676

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.82300
Value Function Update Magnitude: 0.38602

Collected Steps per Second: 14,616.77044
Overall Steps per Second: 6,750.58205

Timestep Collection Time: 3.42223
Timestep Consumption Time: 3.98779
PPO Batch Consumption Time: 0.46724
Total Iteration Time: 7.41003

Cumulative Model Updates: 960
Cumulative Timesteps: 8,052,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04503
Policy Entropy: 4.46813
Value Function Loss: 0.02145

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02284
Policy Update Magnitude: 0.77804
Value Function Update Magnitude: 0.37872

Collected Steps per Second: 14,568.33684
Overall Steps per Second: 6,724.17164

Timestep Collection Time: 3.43265
Timestep Consumption Time: 4.00440
PPO Batch Consumption Time: 0.47529
Total Iteration Time: 7.43705

Cumulative Model Updates: 966
Cumulative Timesteps: 8,102,728

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 8102728...
Checkpoint 8102728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01141
Policy Entropy: 4.46648
Value Function Loss: 0.02968

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03058
Policy Update Magnitude: 0.76293
Value Function Update Magnitude: 0.37615

Collected Steps per Second: 14,409.73040
Overall Steps per Second: 6,727.26115

Timestep Collection Time: 3.47127
Timestep Consumption Time: 3.96415
PPO Batch Consumption Time: 0.47780
Total Iteration Time: 7.43542

Cumulative Model Updates: 972
Cumulative Timesteps: 8,152,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02209
Policy Entropy: 4.46184
Value Function Loss: 0.04977

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03658
Policy Update Magnitude: 0.86463
Value Function Update Magnitude: 0.44921

Collected Steps per Second: 14,417.28539
Overall Steps per Second: 6,680.05776

Timestep Collection Time: 3.46959
Timestep Consumption Time: 4.01867
PPO Batch Consumption Time: 0.47953
Total Iteration Time: 7.48826

Cumulative Model Updates: 978
Cumulative Timesteps: 8,202,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 8202770...
Checkpoint 8202770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00619
Policy Entropy: 4.45776
Value Function Loss: 0.06126

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.03907
Policy Update Magnitude: 0.97528
Value Function Update Magnitude: 0.50713

Collected Steps per Second: 14,417.46921
Overall Steps per Second: 6,653.88571

Timestep Collection Time: 3.46912
Timestep Consumption Time: 4.04769
PPO Batch Consumption Time: 0.48149
Total Iteration Time: 7.51681

Cumulative Model Updates: 984
Cumulative Timesteps: 8,252,786

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00663
Policy Entropy: 4.45727
Value Function Loss: 0.07722

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.04831
Policy Update Magnitude: 1.04970
Value Function Update Magnitude: 0.49335

Collected Steps per Second: 14,704.94167
Overall Steps per Second: 6,731.96747

Timestep Collection Time: 3.40022
Timestep Consumption Time: 4.02703
PPO Batch Consumption Time: 0.48067
Total Iteration Time: 7.42725

Cumulative Model Updates: 990
Cumulative Timesteps: 8,302,786

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 8302786...
Checkpoint 8302786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01021
Policy Entropy: 4.45499
Value Function Loss: 0.06488

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05154
Policy Update Magnitude: 1.08662
Value Function Update Magnitude: 0.48690

Collected Steps per Second: 14,322.45221
Overall Steps per Second: 6,713.06084

Timestep Collection Time: 3.49172
Timestep Consumption Time: 3.95794
PPO Batch Consumption Time: 0.47441
Total Iteration Time: 7.44966

Cumulative Model Updates: 996
Cumulative Timesteps: 8,352,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00603
Policy Entropy: 4.45525
Value Function Loss: 0.05990

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.04869
Policy Update Magnitude: 1.02377
Value Function Update Magnitude: 0.45360

Collected Steps per Second: 14,746.81075
Overall Steps per Second: 6,862.63325

Timestep Collection Time: 3.39287
Timestep Consumption Time: 3.89792
PPO Batch Consumption Time: 0.47107
Total Iteration Time: 7.29079

Cumulative Model Updates: 1,002
Cumulative Timesteps: 8,402,830

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 8402830...
Checkpoint 8402830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01181
Policy Entropy: 4.45670
Value Function Loss: 0.03547

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04589
Policy Update Magnitude: 0.94923
Value Function Update Magnitude: 0.41586

Collected Steps per Second: 14,209.71442
Overall Steps per Second: 6,633.77846

Timestep Collection Time: 3.51942
Timestep Consumption Time: 4.01927
PPO Batch Consumption Time: 0.47973
Total Iteration Time: 7.53869

Cumulative Model Updates: 1,008
Cumulative Timesteps: 8,452,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10574
Policy Entropy: 4.45591
Value Function Loss: 0.03161

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.03813
Policy Update Magnitude: 0.83462
Value Function Update Magnitude: 0.34999

Collected Steps per Second: 14,372.46653
Overall Steps per Second: 6,724.41997

Timestep Collection Time: 3.47915
Timestep Consumption Time: 3.95703
PPO Batch Consumption Time: 0.46670
Total Iteration Time: 7.43618

Cumulative Model Updates: 1,014
Cumulative Timesteps: 8,502,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 8502844...
Checkpoint 8502844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02482
Policy Entropy: 4.46066
Value Function Loss: 0.02856

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03414
Policy Update Magnitude: 0.81977
Value Function Update Magnitude: 0.28737

Collected Steps per Second: 14,666.28941
Overall Steps per Second: 6,751.15239

Timestep Collection Time: 3.40918
Timestep Consumption Time: 3.99696
PPO Batch Consumption Time: 0.47677
Total Iteration Time: 7.40614

Cumulative Model Updates: 1,020
Cumulative Timesteps: 8,552,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01145
Policy Entropy: 4.46011
Value Function Loss: 0.03219

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03531
Policy Update Magnitude: 0.84721
Value Function Update Magnitude: 0.32795

Collected Steps per Second: 14,543.24270
Overall Steps per Second: 6,773.82249

Timestep Collection Time: 3.43802
Timestep Consumption Time: 3.94333
PPO Batch Consumption Time: 0.46279
Total Iteration Time: 7.38136

Cumulative Model Updates: 1,026
Cumulative Timesteps: 8,602,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 8602844...
Checkpoint 8602844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12750
Policy Entropy: 4.45857
Value Function Loss: 0.05197

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03152
Policy Update Magnitude: 0.89534
Value Function Update Magnitude: 0.37736

Collected Steps per Second: 14,058.62172
Overall Steps per Second: 6,600.11707

Timestep Collection Time: 3.55767
Timestep Consumption Time: 4.02037
PPO Batch Consumption Time: 0.48864
Total Iteration Time: 7.57805

Cumulative Model Updates: 1,032
Cumulative Timesteps: 8,652,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03002
Policy Entropy: 4.46143
Value Function Loss: 0.03770

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.03471
Policy Update Magnitude: 0.92563
Value Function Update Magnitude: 0.40133

Collected Steps per Second: 14,109.85109
Overall Steps per Second: 6,680.46038

Timestep Collection Time: 3.54518
Timestep Consumption Time: 3.94262
PPO Batch Consumption Time: 0.46794
Total Iteration Time: 7.48781

Cumulative Model Updates: 1,038
Cumulative Timesteps: 8,702,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 8702882...
Checkpoint 8702882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13414
Policy Entropy: 4.45761
Value Function Loss: 0.04409

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03739
Policy Update Magnitude: 0.91142
Value Function Update Magnitude: 0.36624

Collected Steps per Second: 14,385.03983
Overall Steps per Second: 6,756.55991

Timestep Collection Time: 3.47764
Timestep Consumption Time: 3.92642
PPO Batch Consumption Time: 0.46866
Total Iteration Time: 7.40406

Cumulative Model Updates: 1,044
Cumulative Timesteps: 8,752,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00077
Policy Entropy: 4.46307
Value Function Loss: 0.04577

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03315
Policy Update Magnitude: 0.97199
Value Function Update Magnitude: 0.41855

Collected Steps per Second: 14,549.35559
Overall Steps per Second: 6,786.36019

Timestep Collection Time: 3.43740
Timestep Consumption Time: 3.93208
PPO Batch Consumption Time: 0.46402
Total Iteration Time: 7.36949

Cumulative Model Updates: 1,050
Cumulative Timesteps: 8,802,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 8802920...
Checkpoint 8802920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03324
Policy Entropy: 4.45743
Value Function Loss: 0.05110

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04067
Policy Update Magnitude: 0.97846
Value Function Update Magnitude: 0.48348

Collected Steps per Second: 14,387.01661
Overall Steps per Second: 6,694.40207

Timestep Collection Time: 3.47744
Timestep Consumption Time: 3.99597
PPO Batch Consumption Time: 0.47308
Total Iteration Time: 7.47341

Cumulative Model Updates: 1,056
Cumulative Timesteps: 8,852,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00018
Policy Entropy: 4.45906
Value Function Loss: 0.05967

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.03562
Policy Update Magnitude: 1.03696
Value Function Update Magnitude: 0.48101

Collected Steps per Second: 14,614.40654
Overall Steps per Second: 6,785.15429

Timestep Collection Time: 3.42265
Timestep Consumption Time: 3.94933
PPO Batch Consumption Time: 0.46864
Total Iteration Time: 7.37198

Cumulative Model Updates: 1,062
Cumulative Timesteps: 8,902,970

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 8902970...
Checkpoint 8902970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02238
Policy Entropy: 4.46087
Value Function Loss: 0.05030

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.03861
Policy Update Magnitude: 1.03586
Value Function Update Magnitude: 0.47804

Collected Steps per Second: 14,479.57514
Overall Steps per Second: 6,746.09484

Timestep Collection Time: 3.45480
Timestep Consumption Time: 3.96046
PPO Batch Consumption Time: 0.46638
Total Iteration Time: 7.41525

Cumulative Model Updates: 1,068
Cumulative Timesteps: 8,952,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03122
Policy Entropy: 4.46014
Value Function Loss: 0.04740

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04341
Policy Update Magnitude: 0.95712
Value Function Update Magnitude: 0.46158

Collected Steps per Second: 14,447.13138
Overall Steps per Second: 6,781.95576

Timestep Collection Time: 3.46256
Timestep Consumption Time: 3.91349
PPO Batch Consumption Time: 0.46574
Total Iteration Time: 7.37604

Cumulative Model Updates: 1,074
Cumulative Timesteps: 9,003,018

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 9003018...
Checkpoint 9003018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01913
Policy Entropy: 4.46475
Value Function Loss: 0.03531

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 0.90612
Value Function Update Magnitude: 0.43020

Collected Steps per Second: 14,275.77010
Overall Steps per Second: 6,566.01516

Timestep Collection Time: 3.50370
Timestep Consumption Time: 4.11401
PPO Batch Consumption Time: 0.49624
Total Iteration Time: 7.61771

Cumulative Model Updates: 1,080
Cumulative Timesteps: 9,053,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03480
Policy Entropy: 4.46153
Value Function Loss: 0.03611

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.03777
Policy Update Magnitude: 0.86153
Value Function Update Magnitude: 0.43018

Collected Steps per Second: 14,283.75496
Overall Steps per Second: 6,754.75707

Timestep Collection Time: 3.50048
Timestep Consumption Time: 3.90171
PPO Batch Consumption Time: 0.46949
Total Iteration Time: 7.40219

Cumulative Model Updates: 1,086
Cumulative Timesteps: 9,103,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 9103036...
Checkpoint 9103036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05697
Policy Entropy: 4.46343
Value Function Loss: 0.04368

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02910
Policy Update Magnitude: 0.87279
Value Function Update Magnitude: 0.41082

Collected Steps per Second: 14,413.04548
Overall Steps per Second: 6,673.42647

Timestep Collection Time: 3.47005
Timestep Consumption Time: 4.02445
PPO Batch Consumption Time: 0.47933
Total Iteration Time: 7.49450

Cumulative Model Updates: 1,092
Cumulative Timesteps: 9,153,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00287
Policy Entropy: 4.46075
Value Function Loss: 0.05728

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03236
Policy Update Magnitude: 0.97059
Value Function Update Magnitude: 0.40462

Collected Steps per Second: 14,522.20854
Overall Steps per Second: 6,807.23503

Timestep Collection Time: 3.44452
Timestep Consumption Time: 3.90384
PPO Batch Consumption Time: 0.46986
Total Iteration Time: 7.34836

Cumulative Model Updates: 1,098
Cumulative Timesteps: 9,203,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 9203072...
Checkpoint 9203072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04230
Policy Entropy: 4.46086
Value Function Loss: 0.04630

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04358
Policy Update Magnitude: 0.98029
Value Function Update Magnitude: 0.41766

Collected Steps per Second: 14,551.56617
Overall Steps per Second: 6,766.62777

Timestep Collection Time: 3.43619
Timestep Consumption Time: 3.95331
PPO Batch Consumption Time: 0.46729
Total Iteration Time: 7.38950

Cumulative Model Updates: 1,104
Cumulative Timesteps: 9,253,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05172
Policy Entropy: 4.45963
Value Function Loss: 0.04327

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03356
Policy Update Magnitude: 0.90541
Value Function Update Magnitude: 0.42147

Collected Steps per Second: 14,321.24497
Overall Steps per Second: 6,721.04185

Timestep Collection Time: 3.49243
Timestep Consumption Time: 3.94927
PPO Batch Consumption Time: 0.47272
Total Iteration Time: 7.44170

Cumulative Model Updates: 1,110
Cumulative Timesteps: 9,303,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 9303090...
Checkpoint 9303090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04023
Policy Entropy: 4.46226
Value Function Loss: 0.04717

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02799
Policy Update Magnitude: 0.90359
Value Function Update Magnitude: 0.42478

Collected Steps per Second: 14,576.64164
Overall Steps per Second: 6,758.81247

Timestep Collection Time: 3.43056
Timestep Consumption Time: 3.96808
PPO Batch Consumption Time: 0.47106
Total Iteration Time: 7.39864

Cumulative Model Updates: 1,116
Cumulative Timesteps: 9,353,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07694
Policy Entropy: 4.45998
Value Function Loss: 0.06996

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.03647
Policy Update Magnitude: 0.94158
Value Function Update Magnitude: 0.43623

Collected Steps per Second: 14,536.97283
Overall Steps per Second: 6,770.66370

Timestep Collection Time: 3.44116
Timestep Consumption Time: 3.94719
PPO Batch Consumption Time: 0.46887
Total Iteration Time: 7.38835

Cumulative Model Updates: 1,122
Cumulative Timesteps: 9,403,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 9403120...
Checkpoint 9403120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04772
Policy Entropy: 4.45867
Value Function Loss: 0.06341

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.04769
Policy Update Magnitude: 0.97982
Value Function Update Magnitude: 0.48183

Collected Steps per Second: 14,681.42729
Overall Steps per Second: 6,781.02639

Timestep Collection Time: 3.40757
Timestep Consumption Time: 3.97007
PPO Batch Consumption Time: 0.46599
Total Iteration Time: 7.37764

Cumulative Model Updates: 1,128
Cumulative Timesteps: 9,453,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05038
Policy Entropy: 4.46136
Value Function Loss: 0.05597

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04196
Policy Update Magnitude: 0.93418
Value Function Update Magnitude: 0.39168

Collected Steps per Second: 14,335.92361
Overall Steps per Second: 6,584.63736

Timestep Collection Time: 3.48774
Timestep Consumption Time: 4.10569
PPO Batch Consumption Time: 0.49741
Total Iteration Time: 7.59343

Cumulative Model Updates: 1,134
Cumulative Timesteps: 9,503,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 9503148...
Checkpoint 9503148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00848
Policy Entropy: 4.46546
Value Function Loss: 0.02987

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.03618
Policy Update Magnitude: 0.85161
Value Function Update Magnitude: 0.35220

Collected Steps per Second: 14,414.73603
Overall Steps per Second: 6,761.93836

Timestep Collection Time: 3.46895
Timestep Consumption Time: 3.92597
PPO Batch Consumption Time: 0.47475
Total Iteration Time: 7.39492

Cumulative Model Updates: 1,140
Cumulative Timesteps: 9,553,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05684
Policy Entropy: 4.45813
Value Function Loss: 0.04447

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.03524
Policy Update Magnitude: 0.83718
Value Function Update Magnitude: 0.38217

Collected Steps per Second: 14,333.07070
Overall Steps per Second: 6,733.80460

Timestep Collection Time: 3.49025
Timestep Consumption Time: 3.93883
PPO Batch Consumption Time: 0.46681
Total Iteration Time: 7.42908

Cumulative Model Updates: 1,146
Cumulative Timesteps: 9,603,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 9603178...
Checkpoint 9603178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03833
Policy Entropy: 4.46188
Value Function Loss: 0.05714

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03581
Policy Update Magnitude: 0.90315
Value Function Update Magnitude: 0.41233

Collected Steps per Second: 14,327.44635
Overall Steps per Second: 6,741.79354

Timestep Collection Time: 3.49204
Timestep Consumption Time: 3.92913
PPO Batch Consumption Time: 0.46683
Total Iteration Time: 7.42117

Cumulative Model Updates: 1,152
Cumulative Timesteps: 9,653,210

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05225
Policy Entropy: 4.45860
Value Function Loss: 0.05588

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04269
Policy Update Magnitude: 0.89527
Value Function Update Magnitude: 0.43491

Collected Steps per Second: 14,343.42876
Overall Steps per Second: 6,787.49217

Timestep Collection Time: 3.48801
Timestep Consumption Time: 3.88290
PPO Batch Consumption Time: 0.46538
Total Iteration Time: 7.37091

Cumulative Model Updates: 1,158
Cumulative Timesteps: 9,703,240

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 9703240...
Checkpoint 9703240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01143
Policy Entropy: 4.45835
Value Function Loss: 0.05066

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.03720
Policy Update Magnitude: 0.84214
Value Function Update Magnitude: 0.42103

Collected Steps per Second: 14,420.24144
Overall Steps per Second: 6,709.09022

Timestep Collection Time: 3.46790
Timestep Consumption Time: 3.98586
PPO Batch Consumption Time: 0.47183
Total Iteration Time: 7.45377

Cumulative Model Updates: 1,164
Cumulative Timesteps: 9,753,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01515
Policy Entropy: 4.45474
Value Function Loss: 0.03748

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.03763
Policy Update Magnitude: 0.80991
Value Function Update Magnitude: 0.39163

Collected Steps per Second: 14,467.55661
Overall Steps per Second: 6,786.29937

Timestep Collection Time: 3.45739
Timestep Consumption Time: 3.91334
PPO Batch Consumption Time: 0.47032
Total Iteration Time: 7.37073

Cumulative Model Updates: 1,170
Cumulative Timesteps: 9,803,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 9803268...
Checkpoint 9803268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01350
Policy Entropy: 4.45425
Value Function Loss: 0.04690

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04058
Policy Update Magnitude: 0.81233
Value Function Update Magnitude: 0.38762

Collected Steps per Second: 14,242.72131
Overall Steps per Second: 6,733.10246

Timestep Collection Time: 3.51197
Timestep Consumption Time: 3.91700
PPO Batch Consumption Time: 0.46454
Total Iteration Time: 7.42897

Cumulative Model Updates: 1,176
Cumulative Timesteps: 9,853,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00804
Policy Entropy: 4.45128
Value Function Loss: 0.03834

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04267
Policy Update Magnitude: 0.79775
Value Function Update Magnitude: 0.40734

Collected Steps per Second: 14,401.95203
Overall Steps per Second: 6,715.04569

Timestep Collection Time: 3.47314
Timestep Consumption Time: 3.97580
PPO Batch Consumption Time: 0.47680
Total Iteration Time: 7.44894

Cumulative Model Updates: 1,182
Cumulative Timesteps: 9,903,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 9903308...
Checkpoint 9903308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01612
Policy Entropy: 4.45379
Value Function Loss: 0.03152

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 0.80640
Value Function Update Magnitude: 0.37444

Collected Steps per Second: 14,446.23057
Overall Steps per Second: 6,796.66559

Timestep Collection Time: 3.46180
Timestep Consumption Time: 3.89622
PPO Batch Consumption Time: 0.46652
Total Iteration Time: 7.35802

Cumulative Model Updates: 1,188
Cumulative Timesteps: 9,953,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02283
Policy Entropy: 4.45016
Value Function Loss: 0.02147

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03275
Policy Update Magnitude: 0.76696
Value Function Update Magnitude: 0.32415

Collected Steps per Second: 14,492.34202
Overall Steps per Second: 6,783.44093

Timestep Collection Time: 3.45065
Timestep Consumption Time: 3.92142
PPO Batch Consumption Time: 0.46584
Total Iteration Time: 7.37207

Cumulative Model Updates: 1,194
Cumulative Timesteps: 10,003,326

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 10003326...
Checkpoint 10003326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06446
Policy Entropy: 4.45285
Value Function Loss: 0.03606

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.03947
Policy Update Magnitude: 0.77848
Value Function Update Magnitude: 0.30156

Collected Steps per Second: 14,509.25068
Overall Steps per Second: 6,723.44662

Timestep Collection Time: 3.44690
Timestep Consumption Time: 3.99154
PPO Batch Consumption Time: 0.47203
Total Iteration Time: 7.43845

Cumulative Model Updates: 1,200
Cumulative Timesteps: 10,053,338

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00863
Policy Entropy: 4.45083
Value Function Loss: 0.03502

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04126
Policy Update Magnitude: 0.82082
Value Function Update Magnitude: 0.35582

Collected Steps per Second: 14,274.28664
Overall Steps per Second: 6,699.91664

Timestep Collection Time: 3.50378
Timestep Consumption Time: 3.96109
PPO Batch Consumption Time: 0.46751
Total Iteration Time: 7.46487

Cumulative Model Updates: 1,206
Cumulative Timesteps: 10,103,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 10103352...
Checkpoint 10103352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03482
Policy Entropy: 4.45361
Value Function Loss: 0.04200

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03145
Policy Update Magnitude: 0.80295
Value Function Update Magnitude: 0.37934

Collected Steps per Second: 14,772.07383
Overall Steps per Second: 6,813.47887

Timestep Collection Time: 3.38625
Timestep Consumption Time: 3.95537
PPO Batch Consumption Time: 0.46865
Total Iteration Time: 7.34162

Cumulative Model Updates: 1,212
Cumulative Timesteps: 10,153,374

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04499
Policy Entropy: 4.45263
Value Function Loss: 0.04074

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03230
Policy Update Magnitude: 0.80861
Value Function Update Magnitude: 0.48068

Collected Steps per Second: 14,519.47678
Overall Steps per Second: 6,731.72801

Timestep Collection Time: 3.44406
Timestep Consumption Time: 3.98434
PPO Batch Consumption Time: 0.47531
Total Iteration Time: 7.42840

Cumulative Model Updates: 1,218
Cumulative Timesteps: 10,203,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 10203380...
Checkpoint 10203380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00981
Policy Entropy: 4.45287
Value Function Loss: 0.04163

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03333
Policy Update Magnitude: 0.84845
Value Function Update Magnitude: 0.52675

Collected Steps per Second: 14,406.36159
Overall Steps per Second: 6,786.31823

Timestep Collection Time: 3.47194
Timestep Consumption Time: 3.89848
PPO Batch Consumption Time: 0.46715
Total Iteration Time: 7.37042

Cumulative Model Updates: 1,224
Cumulative Timesteps: 10,253,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01526
Policy Entropy: 4.44690
Value Function Loss: 0.02724

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03118
Policy Update Magnitude: 0.81925
Value Function Update Magnitude: 0.52017

Collected Steps per Second: 14,141.24116
Overall Steps per Second: 6,457.08930

Timestep Collection Time: 3.53745
Timestep Consumption Time: 4.20969
PPO Batch Consumption Time: 0.50949
Total Iteration Time: 7.74714

Cumulative Model Updates: 1,230
Cumulative Timesteps: 10,303,422

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 10303422...
Checkpoint 10303422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06547
Policy Entropy: 4.45235
Value Function Loss: 0.03343

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 0.78071
Value Function Update Magnitude: 0.45841

Collected Steps per Second: 14,413.61531
Overall Steps per Second: 6,692.95491

Timestep Collection Time: 3.46964
Timestep Consumption Time: 4.00240
PPO Batch Consumption Time: 0.47157
Total Iteration Time: 7.47204

Cumulative Model Updates: 1,236
Cumulative Timesteps: 10,353,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04537
Policy Entropy: 4.45406
Value Function Loss: 0.04225

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.03751
Policy Update Magnitude: 0.84590
Value Function Update Magnitude: 0.52441

Collected Steps per Second: 14,546.99367
Overall Steps per Second: 6,757.04713

Timestep Collection Time: 3.43714
Timestep Consumption Time: 3.96255
PPO Batch Consumption Time: 0.47574
Total Iteration Time: 7.39968

Cumulative Model Updates: 1,242
Cumulative Timesteps: 10,403,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 10403432...
Checkpoint 10403432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03920
Policy Entropy: 4.45779
Value Function Loss: 0.03878

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.04486
Policy Update Magnitude: 0.85014
Value Function Update Magnitude: 0.49245

Collected Steps per Second: 14,508.91054
Overall Steps per Second: 6,742.46839

Timestep Collection Time: 3.44726
Timestep Consumption Time: 3.97079
PPO Batch Consumption Time: 0.47096
Total Iteration Time: 7.41805

Cumulative Model Updates: 1,248
Cumulative Timesteps: 10,453,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03406
Policy Entropy: 4.45561
Value Function Loss: 0.03216

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.03633
Policy Update Magnitude: 0.80196
Value Function Update Magnitude: 0.45250

Collected Steps per Second: 14,325.81825
Overall Steps per Second: 6,774.86393

Timestep Collection Time: 3.49132
Timestep Consumption Time: 3.89126
PPO Batch Consumption Time: 0.46924
Total Iteration Time: 7.38258

Cumulative Model Updates: 1,254
Cumulative Timesteps: 10,503,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 10503464...
Checkpoint 10503464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03111
Policy Entropy: 4.46248
Value Function Loss: 0.02998

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03391
Policy Update Magnitude: 0.83071
Value Function Update Magnitude: 0.44085

Collected Steps per Second: 14,524.91122
Overall Steps per Second: 6,698.93439

Timestep Collection Time: 3.44319
Timestep Consumption Time: 4.02248
PPO Batch Consumption Time: 0.47890
Total Iteration Time: 7.46566

Cumulative Model Updates: 1,260
Cumulative Timesteps: 10,553,476

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01556
Policy Entropy: 4.46292
Value Function Loss: 0.03548

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02476
Policy Update Magnitude: 0.83620
Value Function Update Magnitude: 0.44109

Collected Steps per Second: 14,419.23979
Overall Steps per Second: 6,696.42056

Timestep Collection Time: 3.46801
Timestep Consumption Time: 3.99957
PPO Batch Consumption Time: 0.47991
Total Iteration Time: 7.46757

Cumulative Model Updates: 1,266
Cumulative Timesteps: 10,603,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 10603482...
Checkpoint 10603482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03645
Policy Entropy: 4.46026
Value Function Loss: 0.04317

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02962
Policy Update Magnitude: 0.83822
Value Function Update Magnitude: 0.40096

Collected Steps per Second: 14,640.84347
Overall Steps per Second: 6,733.28371

Timestep Collection Time: 3.41551
Timestep Consumption Time: 4.01117
PPO Batch Consumption Time: 0.47694
Total Iteration Time: 7.42669

Cumulative Model Updates: 1,272
Cumulative Timesteps: 10,653,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00478
Policy Entropy: 4.45738
Value Function Loss: 0.06075

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03403
Policy Update Magnitude: 0.90265
Value Function Update Magnitude: 0.44042

Collected Steps per Second: 14,567.10143
Overall Steps per Second: 6,692.13789

Timestep Collection Time: 3.43349
Timestep Consumption Time: 4.04035
PPO Batch Consumption Time: 0.47806
Total Iteration Time: 7.47384

Cumulative Model Updates: 1,278
Cumulative Timesteps: 10,703,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 10703504...
Checkpoint 10703504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06468
Policy Entropy: 4.46044
Value Function Loss: 0.04135

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02932
Policy Update Magnitude: 0.90041
Value Function Update Magnitude: 0.42585

Collected Steps per Second: 14,432.25085
Overall Steps per Second: 6,600.29964

Timestep Collection Time: 3.46488
Timestep Consumption Time: 4.11144
PPO Batch Consumption Time: 0.50219
Total Iteration Time: 7.57632

Cumulative Model Updates: 1,284
Cumulative Timesteps: 10,753,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02590
Policy Entropy: 4.45844
Value Function Loss: 0.03661

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02571
Policy Update Magnitude: 0.80544
Value Function Update Magnitude: 0.34050

Collected Steps per Second: 14,696.05274
Overall Steps per Second: 6,733.27161

Timestep Collection Time: 3.40418
Timestep Consumption Time: 4.02579
PPO Batch Consumption Time: 0.47459
Total Iteration Time: 7.42997

Cumulative Model Updates: 1,290
Cumulative Timesteps: 10,803,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 10803538...
Checkpoint 10803538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03763
Policy Entropy: 4.45999
Value Function Loss: 0.02626

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.77768
Value Function Update Magnitude: 0.33914

Collected Steps per Second: 14,328.75522
Overall Steps per Second: 6,742.50802

Timestep Collection Time: 3.49116
Timestep Consumption Time: 3.92804
PPO Batch Consumption Time: 0.46825
Total Iteration Time: 7.41920

Cumulative Model Updates: 1,296
Cumulative Timesteps: 10,853,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17066
Policy Entropy: 4.45819
Value Function Loss: 0.03505

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03149
Policy Update Magnitude: 0.79915
Value Function Update Magnitude: 0.33644

Collected Steps per Second: 14,857.18478
Overall Steps per Second: 6,780.15281

Timestep Collection Time: 3.36699
Timestep Consumption Time: 4.01101
PPO Batch Consumption Time: 0.47319
Total Iteration Time: 7.37800

Cumulative Model Updates: 1,302
Cumulative Timesteps: 10,903,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 10903586...
Checkpoint 10903586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13713
Policy Entropy: 4.45315
Value Function Loss: 0.04681

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03365
Policy Update Magnitude: 0.85410
Value Function Update Magnitude: 0.38217

Collected Steps per Second: 14,242.30588
Overall Steps per Second: 6,646.34231

Timestep Collection Time: 3.51291
Timestep Consumption Time: 4.01484
PPO Batch Consumption Time: 0.47662
Total Iteration Time: 7.52775

Cumulative Model Updates: 1,308
Cumulative Timesteps: 10,953,618

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11261
Policy Entropy: 4.45541
Value Function Loss: 0.03716

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.03669
Policy Update Magnitude: 0.86280
Value Function Update Magnitude: 0.36276

Collected Steps per Second: 14,567.60814
Overall Steps per Second: 6,769.63579

Timestep Collection Time: 3.43296
Timestep Consumption Time: 3.95444
PPO Batch Consumption Time: 0.48157
Total Iteration Time: 7.38740

Cumulative Model Updates: 1,314
Cumulative Timesteps: 11,003,628

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 11003628...
Checkpoint 11003628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04461
Policy Entropy: 4.45716
Value Function Loss: 0.03083

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03121
Policy Update Magnitude: 0.76879
Value Function Update Magnitude: 0.36035

Collected Steps per Second: 14,435.30546
Overall Steps per Second: 6,768.99294

Timestep Collection Time: 3.46553
Timestep Consumption Time: 3.92493
PPO Batch Consumption Time: 0.46431
Total Iteration Time: 7.39046

Cumulative Model Updates: 1,320
Cumulative Timesteps: 11,053,654

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00222
Policy Entropy: 4.45924
Value Function Loss: 0.04450

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.82818
Value Function Update Magnitude: 0.36081

Collected Steps per Second: 14,454.96838
Overall Steps per Second: 6,719.33752

Timestep Collection Time: 3.46109
Timestep Consumption Time: 3.98458
PPO Batch Consumption Time: 0.47396
Total Iteration Time: 7.44567

Cumulative Model Updates: 1,326
Cumulative Timesteps: 11,103,684

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 11103684...
Checkpoint 11103684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04697
Policy Entropy: 4.45642
Value Function Loss: 0.03838

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03716
Policy Update Magnitude: 0.88593
Value Function Update Magnitude: 0.38168

Collected Steps per Second: 14,523.01522
Overall Steps per Second: 6,771.71074

Timestep Collection Time: 3.44350
Timestep Consumption Time: 3.94164
PPO Batch Consumption Time: 0.48046
Total Iteration Time: 7.38514

Cumulative Model Updates: 1,332
Cumulative Timesteps: 11,153,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01989
Policy Entropy: 4.45549
Value Function Loss: 0.05883

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.03960
Policy Update Magnitude: 0.91010
Value Function Update Magnitude: 0.36080

Collected Steps per Second: 14,282.89651
Overall Steps per Second: 6,707.40567

Timestep Collection Time: 3.50377
Timestep Consumption Time: 3.95724
PPO Batch Consumption Time: 0.46684
Total Iteration Time: 7.46101

Cumulative Model Updates: 1,338
Cumulative Timesteps: 11,203,738

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 11203738...
Checkpoint 11203738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04650
Policy Entropy: 4.45188
Value Function Loss: 0.05563

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04254
Policy Update Magnitude: 0.89428
Value Function Update Magnitude: 0.40089

Collected Steps per Second: 14,615.85727
Overall Steps per Second: 6,813.13954

Timestep Collection Time: 3.42094
Timestep Consumption Time: 3.91782
PPO Batch Consumption Time: 0.47616
Total Iteration Time: 7.33876

Cumulative Model Updates: 1,344
Cumulative Timesteps: 11,253,738

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08787
Policy Entropy: 4.45315
Value Function Loss: 0.09922

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04148
Policy Update Magnitude: 0.92789
Value Function Update Magnitude: 0.40375

Collected Steps per Second: 14,676.40685
Overall Steps per Second: 6,758.11056

Timestep Collection Time: 3.40846
Timestep Consumption Time: 3.99361
PPO Batch Consumption Time: 0.47505
Total Iteration Time: 7.40207

Cumulative Model Updates: 1,350
Cumulative Timesteps: 11,303,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 11303762...
Checkpoint 11303762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10538
Policy Entropy: 4.44881
Value Function Loss: 0.09255

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04592
Policy Update Magnitude: 0.97397
Value Function Update Magnitude: 0.37252

Collected Steps per Second: 14,554.85199
Overall Steps per Second: 6,770.28105

Timestep Collection Time: 3.43707
Timestep Consumption Time: 3.95199
PPO Batch Consumption Time: 0.47686
Total Iteration Time: 7.38906

Cumulative Model Updates: 1,356
Cumulative Timesteps: 11,353,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00775
Policy Entropy: 4.45157
Value Function Loss: 0.08715

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04634
Policy Update Magnitude: 0.94454
Value Function Update Magnitude: 0.37567

Collected Steps per Second: 14,457.01603
Overall Steps per Second: 6,736.00164

Timestep Collection Time: 3.46033
Timestep Consumption Time: 3.96633
PPO Batch Consumption Time: 0.48069
Total Iteration Time: 7.42666

Cumulative Model Updates: 1,362
Cumulative Timesteps: 11,403,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 11403814...
Checkpoint 11403814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01598
Policy Entropy: 4.45312
Value Function Loss: 0.04591

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.03865
Policy Update Magnitude: 0.84507
Value Function Update Magnitude: 0.35546

Collected Steps per Second: 14,424.84791
Overall Steps per Second: 6,672.67368

Timestep Collection Time: 3.46721
Timestep Consumption Time: 4.02813
PPO Batch Consumption Time: 0.47634
Total Iteration Time: 7.49535

Cumulative Model Updates: 1,368
Cumulative Timesteps: 11,453,828

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02618
Policy Entropy: 4.45510
Value Function Loss: 0.03298

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.03743
Policy Update Magnitude: 0.72986
Value Function Update Magnitude: 0.33362

Collected Steps per Second: 14,627.11231
Overall Steps per Second: 6,755.79668

Timestep Collection Time: 3.41954
Timestep Consumption Time: 3.98418
PPO Batch Consumption Time: 0.48802
Total Iteration Time: 7.40372

Cumulative Model Updates: 1,374
Cumulative Timesteps: 11,503,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 11503846...
Checkpoint 11503846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01377
Policy Entropy: 4.45524
Value Function Loss: 0.04027

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 0.74046
Value Function Update Magnitude: 0.31075

Collected Steps per Second: 14,330.68048
Overall Steps per Second: 6,609.23436

Timestep Collection Time: 3.49097
Timestep Consumption Time: 4.07844
PPO Batch Consumption Time: 0.48954
Total Iteration Time: 7.56941

Cumulative Model Updates: 1,380
Cumulative Timesteps: 11,553,874

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01398
Policy Entropy: 4.45530
Value Function Loss: 0.04459

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03355
Policy Update Magnitude: 0.78563
Value Function Update Magnitude: 0.35481

Collected Steps per Second: 14,681.46441
Overall Steps per Second: 6,723.35539

Timestep Collection Time: 3.40661
Timestep Consumption Time: 4.03224
PPO Batch Consumption Time: 0.48050
Total Iteration Time: 7.43885

Cumulative Model Updates: 1,386
Cumulative Timesteps: 11,603,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 11603888...
Checkpoint 11603888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01428
Policy Entropy: 4.45595
Value Function Loss: 0.03932

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03319
Policy Update Magnitude: 0.78905
Value Function Update Magnitude: 0.32457

Collected Steps per Second: 14,706.98122
Overall Steps per Second: 6,684.47384

Timestep Collection Time: 3.40056
Timestep Consumption Time: 4.08125
PPO Batch Consumption Time: 0.48320
Total Iteration Time: 7.48182

Cumulative Model Updates: 1,392
Cumulative Timesteps: 11,653,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02592
Policy Entropy: 4.45538
Value Function Loss: 0.04425

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03647
Policy Update Magnitude: 0.79752
Value Function Update Magnitude: 0.34725

Collected Steps per Second: 14,573.38616
Overall Steps per Second: 6,766.68445

Timestep Collection Time: 3.43270
Timestep Consumption Time: 3.96029
PPO Batch Consumption Time: 0.47012
Total Iteration Time: 7.39299

Cumulative Model Updates: 1,398
Cumulative Timesteps: 11,703,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 11703926...
Checkpoint 11703926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00902
Policy Entropy: 4.45459
Value Function Loss: 0.04248

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03196
Policy Update Magnitude: 0.81159
Value Function Update Magnitude: 0.35966

Collected Steps per Second: 14,409.23934
Overall Steps per Second: 6,793.23781

Timestep Collection Time: 3.47111
Timestep Consumption Time: 3.89151
PPO Batch Consumption Time: 0.46868
Total Iteration Time: 7.36262

Cumulative Model Updates: 1,404
Cumulative Timesteps: 11,753,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04003
Policy Entropy: 4.45595
Value Function Loss: 0.06311

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.03577
Policy Update Magnitude: 0.84873
Value Function Update Magnitude: 0.37991

Collected Steps per Second: 14,537.12540
Overall Steps per Second: 6,805.49290

Timestep Collection Time: 3.44167
Timestep Consumption Time: 3.91004
PPO Batch Consumption Time: 0.46192
Total Iteration Time: 7.35171

Cumulative Model Updates: 1,410
Cumulative Timesteps: 11,803,974

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 11803974...
Checkpoint 11803974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02855
Policy Entropy: 4.45639
Value Function Loss: 0.05422

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.03618
Policy Update Magnitude: 0.89734
Value Function Update Magnitude: 0.44591

Collected Steps per Second: 14,645.99265
Overall Steps per Second: 6,820.88691

Timestep Collection Time: 3.41459
Timestep Consumption Time: 3.91731
PPO Batch Consumption Time: 0.46895
Total Iteration Time: 7.33189

Cumulative Model Updates: 1,416
Cumulative Timesteps: 11,853,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00136
Policy Entropy: 4.45375
Value Function Loss: 0.06745

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03706
Policy Update Magnitude: 0.92603
Value Function Update Magnitude: 0.47797

Collected Steps per Second: 14,607.20504
Overall Steps per Second: 6,710.85239

Timestep Collection Time: 3.42434
Timestep Consumption Time: 4.02926
PPO Batch Consumption Time: 0.48011
Total Iteration Time: 7.45360

Cumulative Model Updates: 1,422
Cumulative Timesteps: 11,904,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 11904004...
Checkpoint 11904004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02486
Policy Entropy: 4.45160
Value Function Loss: 0.05771

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.03949
Policy Update Magnitude: 0.90379
Value Function Update Magnitude: 0.41628

Collected Steps per Second: 14,343.95406
Overall Steps per Second: 6,611.29973

Timestep Collection Time: 3.48760
Timestep Consumption Time: 4.07914
PPO Batch Consumption Time: 0.48144
Total Iteration Time: 7.56674

Cumulative Model Updates: 1,428
Cumulative Timesteps: 11,954,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16461
Policy Entropy: 4.45161
Value Function Loss: 0.07272

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04437
Policy Update Magnitude: 0.91414
Value Function Update Magnitude: 0.38365

Collected Steps per Second: 14,377.81418
Overall Steps per Second: 6,637.58638

Timestep Collection Time: 3.47897
Timestep Consumption Time: 4.05690
PPO Batch Consumption Time: 0.49743
Total Iteration Time: 7.53587

Cumulative Model Updates: 1,434
Cumulative Timesteps: 12,004,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 12004050...
Checkpoint 12004050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06380
Policy Entropy: 4.44819
Value Function Loss: 0.07540

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04308
Policy Update Magnitude: 0.97866
Value Function Update Magnitude: 0.49665

Collected Steps per Second: 14,452.50067
Overall Steps per Second: 6,713.22355

Timestep Collection Time: 3.46141
Timestep Consumption Time: 3.99045
PPO Batch Consumption Time: 0.47571
Total Iteration Time: 7.45186

Cumulative Model Updates: 1,440
Cumulative Timesteps: 12,054,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01027
Policy Entropy: 4.44522
Value Function Loss: 0.06905

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05317
Policy Update Magnitude: 0.96182
Value Function Update Magnitude: 0.50356

Collected Steps per Second: 14,421.99936
Overall Steps per Second: 6,787.11010

Timestep Collection Time: 3.46804
Timestep Consumption Time: 3.90123
PPO Batch Consumption Time: 0.47281
Total Iteration Time: 7.36926

Cumulative Model Updates: 1,446
Cumulative Timesteps: 12,104,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 12104092...
Checkpoint 12104092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01714
Policy Entropy: 4.44465
Value Function Loss: 0.05706

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.04905
Policy Update Magnitude: 0.88579
Value Function Update Magnitude: 0.44703

Collected Steps per Second: 14,491.59429
Overall Steps per Second: 6,764.98660

Timestep Collection Time: 3.45152
Timestep Consumption Time: 3.94214
PPO Batch Consumption Time: 0.46877
Total Iteration Time: 7.39366

Cumulative Model Updates: 1,452
Cumulative Timesteps: 12,154,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02744
Policy Entropy: 4.44485
Value Function Loss: 0.05870

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04098
Policy Update Magnitude: 0.86574
Value Function Update Magnitude: 0.41287

Collected Steps per Second: 14,523.27203
Overall Steps per Second: 6,745.15948

Timestep Collection Time: 3.44468
Timestep Consumption Time: 3.97220
PPO Batch Consumption Time: 0.47452
Total Iteration Time: 7.41687

Cumulative Model Updates: 1,458
Cumulative Timesteps: 12,204,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 12204138...
Checkpoint 12204138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00832
Policy Entropy: 4.44549
Value Function Loss: 0.05635

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.04777
Policy Update Magnitude: 0.88536
Value Function Update Magnitude: 0.42438

Collected Steps per Second: 14,788.19607
Overall Steps per Second: 6,899.44478

Timestep Collection Time: 3.38202
Timestep Consumption Time: 3.86697
PPO Batch Consumption Time: 0.46669
Total Iteration Time: 7.24899

Cumulative Model Updates: 1,464
Cumulative Timesteps: 12,254,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01547
Policy Entropy: 4.44640
Value Function Loss: 0.06425

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04170
Policy Update Magnitude: 0.84342
Value Function Update Magnitude: 0.38964

Collected Steps per Second: 14,543.62640
Overall Steps per Second: 6,707.61200

Timestep Collection Time: 3.43876
Timestep Consumption Time: 4.01725
PPO Batch Consumption Time: 0.47654
Total Iteration Time: 7.45601

Cumulative Model Updates: 1,470
Cumulative Timesteps: 12,304,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 12304164...
Checkpoint 12304164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03731
Policy Entropy: 4.44949
Value Function Loss: 0.05163

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.03670
Policy Update Magnitude: 0.84458
Value Function Update Magnitude: 0.40932

Collected Steps per Second: 14,715.17052
Overall Steps per Second: 6,824.60056

Timestep Collection Time: 3.39948
Timestep Consumption Time: 3.93047
PPO Batch Consumption Time: 0.47604
Total Iteration Time: 7.32995

Cumulative Model Updates: 1,476
Cumulative Timesteps: 12,354,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02095
Policy Entropy: 4.44460
Value Function Loss: 0.05560

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04519
Policy Update Magnitude: 0.83631
Value Function Update Magnitude: 0.37774

Collected Steps per Second: 14,437.90569
Overall Steps per Second: 6,575.00994

Timestep Collection Time: 3.46338
Timestep Consumption Time: 4.14178
PPO Batch Consumption Time: 0.50257
Total Iteration Time: 7.60516

Cumulative Model Updates: 1,482
Cumulative Timesteps: 12,404,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 12404192...
Checkpoint 12404192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04041
Policy Entropy: 4.44280
Value Function Loss: 0.03899

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04829
Policy Update Magnitude: 0.78263
Value Function Update Magnitude: 0.32682

Collected Steps per Second: 14,218.51686
Overall Steps per Second: 6,678.59850

Timestep Collection Time: 3.51682
Timestep Consumption Time: 3.97038
PPO Batch Consumption Time: 0.47699
Total Iteration Time: 7.48720

Cumulative Model Updates: 1,488
Cumulative Timesteps: 12,454,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00770
Policy Entropy: 4.44506
Value Function Loss: 0.03791

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03534
Policy Update Magnitude: 0.71681
Value Function Update Magnitude: 0.33197

Collected Steps per Second: 14,797.10679
Overall Steps per Second: 6,814.70408

Timestep Collection Time: 3.38093
Timestep Consumption Time: 3.96025
PPO Batch Consumption Time: 0.46897
Total Iteration Time: 7.34118

Cumulative Model Updates: 1,494
Cumulative Timesteps: 12,504,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 12504224...
Checkpoint 12504224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03957
Policy Entropy: 4.45194
Value Function Loss: 0.03501

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.03899
Policy Update Magnitude: 0.72613
Value Function Update Magnitude: 0.38824

Collected Steps per Second: 14,595.46619
Overall Steps per Second: 6,739.33729

Timestep Collection Time: 3.42695
Timestep Consumption Time: 3.99484
PPO Batch Consumption Time: 0.47895
Total Iteration Time: 7.42180

Cumulative Model Updates: 1,500
Cumulative Timesteps: 12,554,242

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01491
Policy Entropy: 4.45391
Value Function Loss: 0.04096

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04217
Policy Update Magnitude: 0.75443
Value Function Update Magnitude: 0.36096

Collected Steps per Second: 14,637.09948
Overall Steps per Second: 6,774.17120

Timestep Collection Time: 3.41762
Timestep Consumption Time: 3.96690
PPO Batch Consumption Time: 0.48188
Total Iteration Time: 7.38452

Cumulative Model Updates: 1,506
Cumulative Timesteps: 12,604,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 12604266...
Checkpoint 12604266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02129
Policy Entropy: 4.45426
Value Function Loss: 0.05036

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04070
Policy Update Magnitude: 0.77324
Value Function Update Magnitude: 0.39399

Collected Steps per Second: 14,685.42437
Overall Steps per Second: 6,790.38083

Timestep Collection Time: 3.40569
Timestep Consumption Time: 3.95973
PPO Batch Consumption Time: 0.47153
Total Iteration Time: 7.36542

Cumulative Model Updates: 1,512
Cumulative Timesteps: 12,654,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00013
Policy Entropy: 4.45611
Value Function Loss: 0.05281

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03553
Policy Update Magnitude: 0.80872
Value Function Update Magnitude: 0.40446

Collected Steps per Second: 14,602.26245
Overall Steps per Second: 6,759.69473

Timestep Collection Time: 3.42618
Timestep Consumption Time: 3.97504
PPO Batch Consumption Time: 0.47433
Total Iteration Time: 7.40122

Cumulative Model Updates: 1,518
Cumulative Timesteps: 12,704,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 12704310...
Checkpoint 12704310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04356
Policy Entropy: 4.45306
Value Function Loss: 0.07446

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.03857
Policy Update Magnitude: 0.88586
Value Function Update Magnitude: 0.46998

Collected Steps per Second: 14,687.17121
Overall Steps per Second: 6,767.56632

Timestep Collection Time: 3.40447
Timestep Consumption Time: 3.98401
PPO Batch Consumption Time: 0.47084
Total Iteration Time: 7.38848

Cumulative Model Updates: 1,524
Cumulative Timesteps: 12,754,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12792
Policy Entropy: 4.45092
Value Function Loss: 0.05912

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05190
Policy Update Magnitude: 0.91251
Value Function Update Magnitude: 0.49196

Collected Steps per Second: 14,631.62556
Overall Steps per Second: 6,738.27776

Timestep Collection Time: 3.41726
Timestep Consumption Time: 4.00304
PPO Batch Consumption Time: 0.47521
Total Iteration Time: 7.42029

Cumulative Model Updates: 1,530
Cumulative Timesteps: 12,804,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 12804312...
Checkpoint 12804312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02218
Policy Entropy: 4.45244
Value Function Loss: 0.05143

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.03943
Policy Update Magnitude: 0.82850
Value Function Update Magnitude: 0.46437

Collected Steps per Second: 14,437.39516
Overall Steps per Second: 6,662.18888

Timestep Collection Time: 3.46364
Timestep Consumption Time: 4.04230
PPO Batch Consumption Time: 0.49216
Total Iteration Time: 7.50594

Cumulative Model Updates: 1,536
Cumulative Timesteps: 12,854,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02448
Policy Entropy: 4.45458
Value Function Loss: 0.04323

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03177
Policy Update Magnitude: 0.78871
Value Function Update Magnitude: 0.46412

Collected Steps per Second: 14,840.96942
Overall Steps per Second: 6,791.01558

Timestep Collection Time: 3.37067
Timestep Consumption Time: 3.99553
PPO Batch Consumption Time: 0.47737
Total Iteration Time: 7.36620

Cumulative Model Updates: 1,542
Cumulative Timesteps: 12,904,342

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 12904342...
Checkpoint 12904342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00278
Policy Entropy: 4.45253
Value Function Loss: 0.05299

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.03617
Policy Update Magnitude: 0.82012
Value Function Update Magnitude: 0.42519

Collected Steps per Second: 14,417.95084
Overall Steps per Second: 6,784.13150

Timestep Collection Time: 3.46887
Timestep Consumption Time: 3.90333
PPO Batch Consumption Time: 0.47471
Total Iteration Time: 7.37220

Cumulative Model Updates: 1,548
Cumulative Timesteps: 12,954,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01634
Policy Entropy: 4.45546
Value Function Loss: 0.06297

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 0.86884
Value Function Update Magnitude: 0.46448

Collected Steps per Second: 14,538.30784
Overall Steps per Second: 6,755.56290

Timestep Collection Time: 3.43960
Timestep Consumption Time: 3.96259
PPO Batch Consumption Time: 0.47068
Total Iteration Time: 7.40220

Cumulative Model Updates: 1,554
Cumulative Timesteps: 13,004,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 13004362...
Checkpoint 13004362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02439
Policy Entropy: 4.45283
Value Function Loss: 0.05281

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04128
Policy Update Magnitude: 0.85078
Value Function Update Magnitude: 0.48607

Collected Steps per Second: 14,483.73617
Overall Steps per Second: 6,708.85754

Timestep Collection Time: 3.45256
Timestep Consumption Time: 4.00117
PPO Batch Consumption Time: 0.48430
Total Iteration Time: 7.45373

Cumulative Model Updates: 1,560
Cumulative Timesteps: 13,054,368

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01879
Policy Entropy: 4.45113
Value Function Loss: 0.05219

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.03781
Policy Update Magnitude: 0.83257
Value Function Update Magnitude: 0.46287

Collected Steps per Second: 14,592.27360
Overall Steps per Second: 6,844.31161

Timestep Collection Time: 3.42661
Timestep Consumption Time: 3.87902
PPO Batch Consumption Time: 0.46997
Total Iteration Time: 7.30563

Cumulative Model Updates: 1,566
Cumulative Timesteps: 13,104,370

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 13104370...
Checkpoint 13104370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05784
Policy Entropy: 4.45218
Value Function Loss: 0.07870

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 0.90738
Value Function Update Magnitude: 0.46057

Collected Steps per Second: 14,331.47007
Overall Steps per Second: 6,720.17548

Timestep Collection Time: 3.49008
Timestep Consumption Time: 3.95288
PPO Batch Consumption Time: 0.47105
Total Iteration Time: 7.44296

Cumulative Model Updates: 1,572
Cumulative Timesteps: 13,154,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02194
Policy Entropy: 4.44705
Value Function Loss: 0.08851

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04616
Policy Update Magnitude: 0.95991
Value Function Update Magnitude: 0.50446

Collected Steps per Second: 14,527.87766
Overall Steps per Second: 6,763.06387

Timestep Collection Time: 3.44345
Timestep Consumption Time: 3.95349
PPO Batch Consumption Time: 0.47948
Total Iteration Time: 7.39694

Cumulative Model Updates: 1,578
Cumulative Timesteps: 13,204,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 13204414...
Checkpoint 13204414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07165
Policy Entropy: 4.44394
Value Function Loss: 0.07355

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.04598
Policy Update Magnitude: 0.95217
Value Function Update Magnitude: 0.46605

Collected Steps per Second: 14,563.88660
Overall Steps per Second: 6,777.18677

Timestep Collection Time: 3.43315
Timestep Consumption Time: 3.94454
PPO Batch Consumption Time: 0.46520
Total Iteration Time: 7.37769

Cumulative Model Updates: 1,584
Cumulative Timesteps: 13,254,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05646
Policy Entropy: 4.44565
Value Function Loss: 0.06836

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.04918
Policy Update Magnitude: 0.90199
Value Function Update Magnitude: 0.39313

Collected Steps per Second: 14,624.94789
Overall Steps per Second: 6,744.67531

Timestep Collection Time: 3.41882
Timestep Consumption Time: 3.99444
PPO Batch Consumption Time: 0.47499
Total Iteration Time: 7.41326

Cumulative Model Updates: 1,590
Cumulative Timesteps: 13,304,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 13304414...
Checkpoint 13304414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01702
Policy Entropy: 4.44805
Value Function Loss: 0.07148

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.04760
Policy Update Magnitude: 0.88197
Value Function Update Magnitude: 0.42503

Collected Steps per Second: 14,790.76261
Overall Steps per Second: 6,748.98958

Timestep Collection Time: 3.38116
Timestep Consumption Time: 4.02883
PPO Batch Consumption Time: 0.47505
Total Iteration Time: 7.41000

Cumulative Model Updates: 1,596
Cumulative Timesteps: 13,354,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03703
Policy Entropy: 4.44988
Value Function Loss: 0.05614

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04304
Policy Update Magnitude: 0.81982
Value Function Update Magnitude: 0.42541

Collected Steps per Second: 14,675.79837
Overall Steps per Second: 6,784.37516

Timestep Collection Time: 3.40874
Timestep Consumption Time: 3.96497
PPO Batch Consumption Time: 0.46823
Total Iteration Time: 7.37371

Cumulative Model Updates: 1,602
Cumulative Timesteps: 13,404,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 13404450...
Checkpoint 13404450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03218
Policy Entropy: 4.45089
Value Function Loss: 0.05407

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04015
Policy Update Magnitude: 0.83000
Value Function Update Magnitude: 0.38600

Collected Steps per Second: 14,620.49452
Overall Steps per Second: 6,757.66782

Timestep Collection Time: 3.42136
Timestep Consumption Time: 3.98090
PPO Batch Consumption Time: 0.48713
Total Iteration Time: 7.40226

Cumulative Model Updates: 1,608
Cumulative Timesteps: 13,454,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05654
Policy Entropy: 4.44678
Value Function Loss: 0.05947

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.04413
Policy Update Magnitude: 0.85425
Value Function Update Magnitude: 0.47689

Collected Steps per Second: 14,246.35822
Overall Steps per Second: 6,677.52072

Timestep Collection Time: 3.51149
Timestep Consumption Time: 3.98021
PPO Batch Consumption Time: 0.47363
Total Iteration Time: 7.49170

Cumulative Model Updates: 1,614
Cumulative Timesteps: 13,504,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 13504498...
Checkpoint 13504498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06203
Policy Entropy: 4.44990
Value Function Loss: 0.05236

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04104
Policy Update Magnitude: 0.84320
Value Function Update Magnitude: 0.46879

Collected Steps per Second: 14,290.29584
Overall Steps per Second: 6,709.13532

Timestep Collection Time: 3.49944
Timestep Consumption Time: 3.95428
PPO Batch Consumption Time: 0.47679
Total Iteration Time: 7.45372

Cumulative Model Updates: 1,620
Cumulative Timesteps: 13,554,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01930
Policy Entropy: 4.44789
Value Function Loss: 0.06550

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02953
Policy Update Magnitude: 0.82439
Value Function Update Magnitude: 0.44795

Collected Steps per Second: 14,495.48314
Overall Steps per Second: 6,691.46612

Timestep Collection Time: 3.45073
Timestep Consumption Time: 4.02446
PPO Batch Consumption Time: 0.47267
Total Iteration Time: 7.47519

Cumulative Model Updates: 1,626
Cumulative Timesteps: 13,604,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 13604526...
Checkpoint 13604526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03876
Policy Entropy: 4.44959
Value Function Loss: 0.04782

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03553
Policy Update Magnitude: 0.84880
Value Function Update Magnitude: 0.44464

Collected Steps per Second: 14,459.41041
Overall Steps per Second: 6,550.82343

Timestep Collection Time: 3.45906
Timestep Consumption Time: 4.17601
PPO Batch Consumption Time: 0.50691
Total Iteration Time: 7.63507

Cumulative Model Updates: 1,632
Cumulative Timesteps: 13,654,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06785
Policy Entropy: 4.44960
Value Function Loss: 0.04710

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.03965
Policy Update Magnitude: 0.79391
Value Function Update Magnitude: 0.42614

Collected Steps per Second: 14,820.20306
Overall Steps per Second: 6,771.53418

Timestep Collection Time: 3.37580
Timestep Consumption Time: 4.01248
PPO Batch Consumption Time: 0.47076
Total Iteration Time: 7.38828

Cumulative Model Updates: 1,638
Cumulative Timesteps: 13,704,572

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 13704572...
Checkpoint 13704572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00824
Policy Entropy: 4.45279
Value Function Loss: 0.04011

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.72951
Value Function Update Magnitude: 0.43415

Collected Steps per Second: 14,327.86423
Overall Steps per Second: 6,748.94869

Timestep Collection Time: 3.49138
Timestep Consumption Time: 3.92074
PPO Batch Consumption Time: 0.46760
Total Iteration Time: 7.41212

Cumulative Model Updates: 1,644
Cumulative Timesteps: 13,754,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04364
Policy Entropy: 4.45053
Value Function Loss: 0.05306

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 0.82463
Value Function Update Magnitude: 0.44645

Collected Steps per Second: 14,681.12061
Overall Steps per Second: 6,785.91281

Timestep Collection Time: 3.40819
Timestep Consumption Time: 3.96532
PPO Batch Consumption Time: 0.47076
Total Iteration Time: 7.37351

Cumulative Model Updates: 1,650
Cumulative Timesteps: 13,804,632

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 13804632...
Checkpoint 13804632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00237
Policy Entropy: 4.44916
Value Function Loss: 0.05920

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03042
Policy Update Magnitude: 0.86328
Value Function Update Magnitude: 0.47161

Collected Steps per Second: 14,338.73642
Overall Steps per Second: 6,669.45965

Timestep Collection Time: 3.48873
Timestep Consumption Time: 4.01173
PPO Batch Consumption Time: 0.47774
Total Iteration Time: 7.50046

Cumulative Model Updates: 1,656
Cumulative Timesteps: 13,854,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00906
Policy Entropy: 4.44576
Value Function Loss: 0.07106

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02990
Policy Update Magnitude: 0.89112
Value Function Update Magnitude: 0.51587

Collected Steps per Second: 14,858.55368
Overall Steps per Second: 6,769.64580

Timestep Collection Time: 3.36655
Timestep Consumption Time: 4.02261
PPO Batch Consumption Time: 0.48056
Total Iteration Time: 7.38916

Cumulative Model Updates: 1,662
Cumulative Timesteps: 13,904,678

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 13904678...
Checkpoint 13904678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03025
Policy Entropy: 4.44366
Value Function Loss: 0.07687

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04485
Policy Update Magnitude: 0.94316
Value Function Update Magnitude: 0.48151

Collected Steps per Second: 14,380.01492
Overall Steps per Second: 6,598.57721

Timestep Collection Time: 3.47900
Timestep Consumption Time: 4.10264
PPO Batch Consumption Time: 0.48936
Total Iteration Time: 7.58163

Cumulative Model Updates: 1,668
Cumulative Timesteps: 13,954,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01912
Policy Entropy: 4.44464
Value Function Loss: 0.07689

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.04857
Policy Update Magnitude: 0.94693
Value Function Update Magnitude: 0.50850

Collected Steps per Second: 14,527.25192
Overall Steps per Second: 6,717.77690

Timestep Collection Time: 3.44222
Timestep Consumption Time: 4.00161
PPO Batch Consumption Time: 0.48362
Total Iteration Time: 7.44383

Cumulative Model Updates: 1,674
Cumulative Timesteps: 14,004,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 14004712...
Checkpoint 14004712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01163
Policy Entropy: 4.44603
Value Function Loss: 0.08058

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04127
Policy Update Magnitude: 0.90712
Value Function Update Magnitude: 0.56047

Collected Steps per Second: 14,386.52261
Overall Steps per Second: 6,668.85210

Timestep Collection Time: 3.47603
Timestep Consumption Time: 4.02271
PPO Batch Consumption Time: 0.47963
Total Iteration Time: 7.49874

Cumulative Model Updates: 1,680
Cumulative Timesteps: 14,054,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05906
Policy Entropy: 4.44592
Value Function Loss: 0.04842

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04550
Policy Update Magnitude: 0.86686
Value Function Update Magnitude: 0.51474

Collected Steps per Second: 14,353.57796
Overall Steps per Second: 6,570.29714

Timestep Collection Time: 3.48415
Timestep Consumption Time: 4.12738
PPO Batch Consumption Time: 0.49962
Total Iteration Time: 7.61153

Cumulative Model Updates: 1,686
Cumulative Timesteps: 14,104,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 14104730...
Checkpoint 14104730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06396
Policy Entropy: 4.44437
Value Function Loss: 0.04120

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03679
Policy Update Magnitude: 0.77932
Value Function Update Magnitude: 0.44603

Collected Steps per Second: 14,538.31239
Overall Steps per Second: 6,720.78087

Timestep Collection Time: 3.44098
Timestep Consumption Time: 4.00250
PPO Batch Consumption Time: 0.48910
Total Iteration Time: 7.44348

Cumulative Model Updates: 1,692
Cumulative Timesteps: 14,154,756

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01939
Policy Entropy: 4.44256
Value Function Loss: 0.03420

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02705
Policy Update Magnitude: 0.71793
Value Function Update Magnitude: 0.38078

Collected Steps per Second: 14,452.32411
Overall Steps per Second: 6,709.63625

Timestep Collection Time: 3.46034
Timestep Consumption Time: 3.99312
PPO Batch Consumption Time: 0.47606
Total Iteration Time: 7.45346

Cumulative Model Updates: 1,698
Cumulative Timesteps: 14,204,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 14204766...
Checkpoint 14204766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05957
Policy Entropy: 4.44508
Value Function Loss: 0.05092

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02901
Policy Update Magnitude: 0.77545
Value Function Update Magnitude: 0.45907

Collected Steps per Second: 14,478.67423
Overall Steps per Second: 6,833.82076

Timestep Collection Time: 3.45474
Timestep Consumption Time: 3.86474
PPO Batch Consumption Time: 0.47473
Total Iteration Time: 7.31948

Cumulative Model Updates: 1,704
Cumulative Timesteps: 14,254,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02428
Policy Entropy: 4.44324
Value Function Loss: 0.04786

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02976
Policy Update Magnitude: 0.82449
Value Function Update Magnitude: 0.47153

Collected Steps per Second: 14,410.32946
Overall Steps per Second: 6,693.11231

Timestep Collection Time: 3.46973
Timestep Consumption Time: 4.00063
PPO Batch Consumption Time: 0.47009
Total Iteration Time: 7.47037

Cumulative Model Updates: 1,710
Cumulative Timesteps: 14,304,786

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 14304786...
Checkpoint 14304786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04535
Policy Entropy: 4.43896
Value Function Loss: 0.05823

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.88408
Value Function Update Magnitude: 0.47275

Collected Steps per Second: 14,407.36612
Overall Steps per Second: 6,706.44342

Timestep Collection Time: 3.47072
Timestep Consumption Time: 3.98539
PPO Batch Consumption Time: 0.47405
Total Iteration Time: 7.45611

Cumulative Model Updates: 1,716
Cumulative Timesteps: 14,354,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02568
Policy Entropy: 4.44240
Value Function Loss: 0.05610

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03554
Policy Update Magnitude: 0.86972
Value Function Update Magnitude: 0.42312

Collected Steps per Second: 14,889.30634
Overall Steps per Second: 6,743.15380

Timestep Collection Time: 3.35865
Timestep Consumption Time: 4.05746
PPO Batch Consumption Time: 0.47755
Total Iteration Time: 7.41611

Cumulative Model Updates: 1,722
Cumulative Timesteps: 14,404,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 14404798...
Checkpoint 14404798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08108
Policy Entropy: 4.43719
Value Function Loss: 0.10680

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04406
Policy Update Magnitude: 0.94818
Value Function Update Magnitude: 0.36680

Collected Steps per Second: 14,471.81898
Overall Steps per Second: 6,686.58201

Timestep Collection Time: 3.45568
Timestep Consumption Time: 4.02348
PPO Batch Consumption Time: 0.47774
Total Iteration Time: 7.47916

Cumulative Model Updates: 1,728
Cumulative Timesteps: 14,454,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00791
Policy Entropy: 4.43097
Value Function Loss: 0.10834

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.05987
Policy Update Magnitude: 0.99630
Value Function Update Magnitude: 0.39376

Collected Steps per Second: 14,529.81898
Overall Steps per Second: 6,645.47681

Timestep Collection Time: 3.44120
Timestep Consumption Time: 4.08272
PPO Batch Consumption Time: 0.49667
Total Iteration Time: 7.52391

Cumulative Model Updates: 1,734
Cumulative Timesteps: 14,504,808

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 14504808...
Checkpoint 14504808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08079
Policy Entropy: 4.43126
Value Function Loss: 0.11310

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05809
Policy Update Magnitude: 0.96583
Value Function Update Magnitude: 0.39047

Collected Steps per Second: 14,313.39803
Overall Steps per Second: 6,647.34850

Timestep Collection Time: 3.49323
Timestep Consumption Time: 4.02857
PPO Batch Consumption Time: 0.48025
Total Iteration Time: 7.52180

Cumulative Model Updates: 1,740
Cumulative Timesteps: 14,554,808

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06515
Policy Entropy: 4.43984
Value Function Loss: 0.08928

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04493
Policy Update Magnitude: 0.94521
Value Function Update Magnitude: 0.44443

Collected Steps per Second: 14,593.38298
Overall Steps per Second: 6,739.90341

Timestep Collection Time: 3.42744
Timestep Consumption Time: 3.99373
PPO Batch Consumption Time: 0.48105
Total Iteration Time: 7.42117

Cumulative Model Updates: 1,746
Cumulative Timesteps: 14,604,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 14604826...
Checkpoint 14604826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00247
Policy Entropy: 4.43422
Value Function Loss: 0.07982

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04258
Policy Update Magnitude: 0.93679
Value Function Update Magnitude: 0.47449

Collected Steps per Second: 14,598.75789
Overall Steps per Second: 6,692.61366

Timestep Collection Time: 3.42604
Timestep Consumption Time: 4.04727
PPO Batch Consumption Time: 0.48611
Total Iteration Time: 7.47331

Cumulative Model Updates: 1,752
Cumulative Timesteps: 14,654,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10729
Policy Entropy: 4.43597
Value Function Loss: 0.06534

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04131
Policy Update Magnitude: 0.91405
Value Function Update Magnitude: 0.46795

Collected Steps per Second: 14,603.99796
Overall Steps per Second: 6,759.24840

Timestep Collection Time: 3.42454
Timestep Consumption Time: 3.97451
PPO Batch Consumption Time: 0.46654
Total Iteration Time: 7.39905

Cumulative Model Updates: 1,758
Cumulative Timesteps: 14,704,854

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 14704854...
Checkpoint 14704854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03706
Policy Entropy: 4.43589
Value Function Loss: 0.04862

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.03922
Policy Update Magnitude: 0.87746
Value Function Update Magnitude: 0.43783

Collected Steps per Second: 14,515.95180
Overall Steps per Second: 6,779.40869

Timestep Collection Time: 3.44449
Timestep Consumption Time: 3.93079
PPO Batch Consumption Time: 0.47837
Total Iteration Time: 7.37527

Cumulative Model Updates: 1,764
Cumulative Timesteps: 14,754,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02560
Policy Entropy: 4.43931
Value Function Loss: 0.03362

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.81775
Value Function Update Magnitude: 0.38535

Collected Steps per Second: 14,532.82140
Overall Steps per Second: 6,668.48630

Timestep Collection Time: 3.44145
Timestep Consumption Time: 4.05860
PPO Batch Consumption Time: 0.47769
Total Iteration Time: 7.50005

Cumulative Model Updates: 1,770
Cumulative Timesteps: 14,804,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 14804868...
Checkpoint 14804868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03802
Policy Entropy: 4.44037
Value Function Loss: 0.03867

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02831
Policy Update Magnitude: 0.81214
Value Function Update Magnitude: 0.38497

Collected Steps per Second: 14,249.56628
Overall Steps per Second: 6,745.95024

Timestep Collection Time: 3.51084
Timestep Consumption Time: 3.90516
PPO Batch Consumption Time: 0.47081
Total Iteration Time: 7.41600

Cumulative Model Updates: 1,776
Cumulative Timesteps: 14,854,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16435
Policy Entropy: 4.43574
Value Function Loss: 0.03958

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03455
Policy Update Magnitude: 0.83157
Value Function Update Magnitude: 0.36436

Collected Steps per Second: 14,614.67706
Overall Steps per Second: 6,714.49999

Timestep Collection Time: 3.42218
Timestep Consumption Time: 4.02648
PPO Batch Consumption Time: 0.48279
Total Iteration Time: 7.44866

Cumulative Model Updates: 1,782
Cumulative Timesteps: 14,904,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 14904910...
Checkpoint 14904910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03502
Policy Entropy: 4.43935
Value Function Loss: 0.04662

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03464
Policy Update Magnitude: 0.82438
Value Function Update Magnitude: 0.31413

Collected Steps per Second: 14,371.30608
Overall Steps per Second: 6,645.10253

Timestep Collection Time: 3.47957
Timestep Consumption Time: 4.04567
PPO Batch Consumption Time: 0.48064
Total Iteration Time: 7.52524

Cumulative Model Updates: 1,788
Cumulative Timesteps: 14,954,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02289
Policy Entropy: 4.43827
Value Function Loss: 0.05575

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03241
Policy Update Magnitude: 0.81023
Value Function Update Magnitude: 0.29880

Collected Steps per Second: 14,773.76378
Overall Steps per Second: 6,826.14941

Timestep Collection Time: 3.38505
Timestep Consumption Time: 3.94118
PPO Batch Consumption Time: 0.48024
Total Iteration Time: 7.32624

Cumulative Model Updates: 1,794
Cumulative Timesteps: 15,004,926

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 15004926...
Checkpoint 15004926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04889
Policy Entropy: 4.43792
Value Function Loss: 0.05748

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04168
Policy Update Magnitude: 0.78236
Value Function Update Magnitude: 0.32267

Collected Steps per Second: 14,497.38164
Overall Steps per Second: 6,669.75466

Timestep Collection Time: 3.45000
Timestep Consumption Time: 4.04892
PPO Batch Consumption Time: 0.48750
Total Iteration Time: 7.49893

Cumulative Model Updates: 1,800
Cumulative Timesteps: 15,054,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02706
Policy Entropy: 4.43708
Value Function Loss: 0.05299

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04711
Policy Update Magnitude: 0.75498
Value Function Update Magnitude: 0.32041

Collected Steps per Second: 14,636.62761
Overall Steps per Second: 6,729.57880

Timestep Collection Time: 3.41622
Timestep Consumption Time: 4.01396
PPO Batch Consumption Time: 0.48396
Total Iteration Time: 7.43018

Cumulative Model Updates: 1,806
Cumulative Timesteps: 15,104,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 15104944...
Checkpoint 15104944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03942
Policy Entropy: 4.43754
Value Function Loss: 0.05384

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04291
Policy Update Magnitude: 0.78079
Value Function Update Magnitude: 0.33111

Collected Steps per Second: 14,380.64929
Overall Steps per Second: 6,711.35275

Timestep Collection Time: 3.47787
Timestep Consumption Time: 3.97428
PPO Batch Consumption Time: 0.47693
Total Iteration Time: 7.45215

Cumulative Model Updates: 1,812
Cumulative Timesteps: 15,154,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05098
Policy Entropy: 4.44272
Value Function Loss: 0.05899

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03739
Policy Update Magnitude: 0.82689
Value Function Update Magnitude: 0.35816

Collected Steps per Second: 14,331.71562
Overall Steps per Second: 6,690.95853

Timestep Collection Time: 3.48918
Timestep Consumption Time: 3.98448
PPO Batch Consumption Time: 0.47727
Total Iteration Time: 7.47367

Cumulative Model Updates: 1,818
Cumulative Timesteps: 15,204,964

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 15204964...
Checkpoint 15204964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05522
Policy Entropy: 4.44005
Value Function Loss: 0.05781

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04398
Policy Update Magnitude: 0.80731
Value Function Update Magnitude: 0.32303

Collected Steps per Second: 14,634.40897
Overall Steps per Second: 6,748.62657

Timestep Collection Time: 3.41948
Timestep Consumption Time: 3.99566
PPO Batch Consumption Time: 0.47699
Total Iteration Time: 7.41514

Cumulative Model Updates: 1,824
Cumulative Timesteps: 15,255,006

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01488
Policy Entropy: 4.43935
Value Function Loss: 0.06257

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03892
Policy Update Magnitude: 0.79107
Value Function Update Magnitude: 0.30354

Collected Steps per Second: 14,500.31010
Overall Steps per Second: 6,619.99741

Timestep Collection Time: 3.44958
Timestep Consumption Time: 4.10631
PPO Batch Consumption Time: 0.48784
Total Iteration Time: 7.55589

Cumulative Model Updates: 1,830
Cumulative Timesteps: 15,305,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 15305026...
Checkpoint 15305026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02269
Policy Entropy: 4.43942
Value Function Loss: 0.05670

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03427
Policy Update Magnitude: 0.80447
Value Function Update Magnitude: 0.33485

Collected Steps per Second: 14,732.02491
Overall Steps per Second: 6,663.83819

Timestep Collection Time: 3.39451
Timestep Consumption Time: 4.10987
PPO Batch Consumption Time: 0.50076
Total Iteration Time: 7.50438

Cumulative Model Updates: 1,836
Cumulative Timesteps: 15,355,034

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15025
Policy Entropy: 4.43901
Value Function Loss: 0.05673

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03282
Policy Update Magnitude: 0.75243
Value Function Update Magnitude: 0.36357

Collected Steps per Second: 14,513.30613
Overall Steps per Second: 6,721.15022

Timestep Collection Time: 3.44801
Timestep Consumption Time: 3.99744
PPO Batch Consumption Time: 0.47334
Total Iteration Time: 7.44545

Cumulative Model Updates: 1,842
Cumulative Timesteps: 15,405,076

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 15405076...
Checkpoint 15405076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10513
Policy Entropy: 4.43883
Value Function Loss: 0.05438

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03436
Policy Update Magnitude: 0.79686
Value Function Update Magnitude: 0.35709

Collected Steps per Second: 14,542.06985
Overall Steps per Second: 6,737.67883

Timestep Collection Time: 3.44009
Timestep Consumption Time: 3.98472
PPO Batch Consumption Time: 0.48106
Total Iteration Time: 7.42481

Cumulative Model Updates: 1,848
Cumulative Timesteps: 15,455,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05036
Policy Entropy: 4.43595
Value Function Loss: 0.05729

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04609
Policy Update Magnitude: 0.83160
Value Function Update Magnitude: 0.35753

Collected Steps per Second: 14,409.24598
Overall Steps per Second: 6,653.87275

Timestep Collection Time: 3.47138
Timestep Consumption Time: 4.04604
PPO Batch Consumption Time: 0.47247
Total Iteration Time: 7.51743

Cumulative Model Updates: 1,854
Cumulative Timesteps: 15,505,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 15505122...
Checkpoint 15505122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00288
Policy Entropy: 4.43902
Value Function Loss: 0.06221

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04114
Policy Update Magnitude: 0.86714
Value Function Update Magnitude: 0.34007

Collected Steps per Second: 14,379.57064
Overall Steps per Second: 6,728.57063

Timestep Collection Time: 3.47799
Timestep Consumption Time: 3.95479
PPO Batch Consumption Time: 0.47039
Total Iteration Time: 7.43278

Cumulative Model Updates: 1,860
Cumulative Timesteps: 15,555,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06751
Policy Entropy: 4.43823
Value Function Loss: 0.08565

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04209
Policy Update Magnitude: 0.89798
Value Function Update Magnitude: 0.34564

Collected Steps per Second: 14,533.27423
Overall Steps per Second: 6,752.45717

Timestep Collection Time: 3.44162
Timestep Consumption Time: 3.96576
PPO Batch Consumption Time: 0.47469
Total Iteration Time: 7.40738

Cumulative Model Updates: 1,866
Cumulative Timesteps: 15,605,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 15605152...
Checkpoint 15605152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01062
Policy Entropy: 4.43774
Value Function Loss: 0.08589

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.04954
Policy Update Magnitude: 0.90768
Value Function Update Magnitude: 0.38211

Collected Steps per Second: 14,373.04076
Overall Steps per Second: 6,715.37178

Timestep Collection Time: 3.47957
Timestep Consumption Time: 3.96782
PPO Batch Consumption Time: 0.47362
Total Iteration Time: 7.44739

Cumulative Model Updates: 1,872
Cumulative Timesteps: 15,655,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04915
Policy Entropy: 4.43632
Value Function Loss: 0.06634

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04118
Policy Update Magnitude: 0.86477
Value Function Update Magnitude: 0.35882

Collected Steps per Second: 14,461.21687
Overall Steps per Second: 6,749.30753

Timestep Collection Time: 3.45808
Timestep Consumption Time: 3.95128
PPO Batch Consumption Time: 0.47964
Total Iteration Time: 7.40935

Cumulative Model Updates: 1,878
Cumulative Timesteps: 15,705,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 15705172...
Checkpoint 15705172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02093
Policy Entropy: 4.43618
Value Function Loss: 0.06723

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03269
Policy Update Magnitude: 0.84075
Value Function Update Magnitude: 0.35682

Collected Steps per Second: 14,515.38699
Overall Steps per Second: 6,636.70435

Timestep Collection Time: 3.44669
Timestep Consumption Time: 4.09169
PPO Batch Consumption Time: 0.49474
Total Iteration Time: 7.53838

Cumulative Model Updates: 1,884
Cumulative Timesteps: 15,755,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02516
Policy Entropy: 4.43589
Value Function Loss: 0.07877

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04547
Policy Update Magnitude: 0.93510
Value Function Update Magnitude: 0.38869

Collected Steps per Second: 14,335.54560
Overall Steps per Second: 6,732.53007

Timestep Collection Time: 3.48923
Timestep Consumption Time: 3.94037
PPO Batch Consumption Time: 0.47095
Total Iteration Time: 7.42960

Cumulative Model Updates: 1,890
Cumulative Timesteps: 15,805,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 15805222...
Checkpoint 15805222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01763
Policy Entropy: 4.43417
Value Function Loss: 0.10487

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.04919
Policy Update Magnitude: 0.96387
Value Function Update Magnitude: 0.39248

Collected Steps per Second: 14,647.52393
Overall Steps per Second: 6,707.03735

Timestep Collection Time: 3.41478
Timestep Consumption Time: 4.04277
PPO Batch Consumption Time: 0.47269
Total Iteration Time: 7.45754

Cumulative Model Updates: 1,896
Cumulative Timesteps: 15,855,240

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06847
Policy Entropy: 4.43277
Value Function Loss: 0.08958

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.04583
Policy Update Magnitude: 0.95118
Value Function Update Magnitude: 0.39411

Collected Steps per Second: 14,471.06685
Overall Steps per Second: 6,657.48161

Timestep Collection Time: 3.45572
Timestep Consumption Time: 4.05583
PPO Batch Consumption Time: 0.48426
Total Iteration Time: 7.51155

Cumulative Model Updates: 1,902
Cumulative Timesteps: 15,905,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 15905248...
Checkpoint 15905248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01013
Policy Entropy: 4.43437
Value Function Loss: 0.08043

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.04876
Policy Update Magnitude: 0.88429
Value Function Update Magnitude: 0.37317

Collected Steps per Second: 14,485.61768
Overall Steps per Second: 6,662.92109

Timestep Collection Time: 3.45363
Timestep Consumption Time: 4.05479
PPO Batch Consumption Time: 0.48275
Total Iteration Time: 7.50842

Cumulative Model Updates: 1,908
Cumulative Timesteps: 15,955,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08835
Policy Entropy: 4.43405
Value Function Loss: 0.07154

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03433
Policy Update Magnitude: 0.84436
Value Function Update Magnitude: 0.37187

Collected Steps per Second: 14,399.08694
Overall Steps per Second: 6,613.65164

Timestep Collection Time: 3.47244
Timestep Consumption Time: 4.08768
PPO Batch Consumption Time: 0.47809
Total Iteration Time: 7.56012

Cumulative Model Updates: 1,914
Cumulative Timesteps: 16,005,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 16005276...
Checkpoint 16005276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02719
Policy Entropy: 4.43347
Value Function Loss: 0.06381

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03454
Policy Update Magnitude: 0.82297
Value Function Update Magnitude: 0.42383

Collected Steps per Second: 14,330.50130
Overall Steps per Second: 6,737.37435

Timestep Collection Time: 3.49046
Timestep Consumption Time: 3.93380
PPO Batch Consumption Time: 0.47480
Total Iteration Time: 7.42426

Cumulative Model Updates: 1,920
Cumulative Timesteps: 16,055,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02287
Policy Entropy: 4.43323
Value Function Loss: 0.06612

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04055
Policy Update Magnitude: 0.80716
Value Function Update Magnitude: 0.37172

Collected Steps per Second: 14,390.89984
Overall Steps per Second: 6,659.84698

Timestep Collection Time: 3.47442
Timestep Consumption Time: 4.03326
PPO Batch Consumption Time: 0.47996
Total Iteration Time: 7.50768

Cumulative Model Updates: 1,926
Cumulative Timesteps: 16,105,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 16105296...
Checkpoint 16105296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04675
Policy Entropy: 4.43335
Value Function Loss: 0.06484

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04147
Policy Update Magnitude: 0.81652
Value Function Update Magnitude: 0.36611

Collected Steps per Second: 14,388.19039
Overall Steps per Second: 6,619.71994

Timestep Collection Time: 3.47646
Timestep Consumption Time: 4.07975
PPO Batch Consumption Time: 0.48678
Total Iteration Time: 7.55621

Cumulative Model Updates: 1,932
Cumulative Timesteps: 16,155,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01418
Policy Entropy: 4.43371
Value Function Loss: 0.07051

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04443
Policy Update Magnitude: 0.84097
Value Function Update Magnitude: 0.38619

Collected Steps per Second: 14,237.41092
Overall Steps per Second: 6,665.76663

Timestep Collection Time: 3.51230
Timestep Consumption Time: 3.98962
PPO Batch Consumption Time: 0.48208
Total Iteration Time: 7.50191

Cumulative Model Updates: 1,938
Cumulative Timesteps: 16,205,322

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 16205322...
Checkpoint 16205322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04995
Policy Entropy: 4.43653
Value Function Loss: 0.06649

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03880
Policy Update Magnitude: 0.82861
Value Function Update Magnitude: 0.43652

Collected Steps per Second: 14,481.69977
Overall Steps per Second: 6,701.22858

Timestep Collection Time: 3.45319
Timestep Consumption Time: 4.00933
PPO Batch Consumption Time: 0.47439
Total Iteration Time: 7.46251

Cumulative Model Updates: 1,944
Cumulative Timesteps: 16,255,330

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04915
Policy Entropy: 4.43797
Value Function Loss: 0.06500

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03436
Policy Update Magnitude: 0.80372
Value Function Update Magnitude: 0.45791

Collected Steps per Second: 14,608.07335
Overall Steps per Second: 6,696.38743

Timestep Collection Time: 3.42468
Timestep Consumption Time: 4.04621
PPO Batch Consumption Time: 0.49053
Total Iteration Time: 7.47089

Cumulative Model Updates: 1,950
Cumulative Timesteps: 16,305,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 16305358...
Checkpoint 16305358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09764
Policy Entropy: 4.43913
Value Function Loss: 0.05612

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.78865
Value Function Update Magnitude: 0.38065

Collected Steps per Second: 14,453.74382
Overall Steps per Second: 6,648.58230

Timestep Collection Time: 3.46056
Timestep Consumption Time: 4.06255
PPO Batch Consumption Time: 0.48175
Total Iteration Time: 7.52311

Cumulative Model Updates: 1,956
Cumulative Timesteps: 16,355,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05849
Policy Entropy: 4.43514
Value Function Loss: 0.05386

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03649
Policy Update Magnitude: 0.75441
Value Function Update Magnitude: 0.36362

Collected Steps per Second: 14,501.36689
Overall Steps per Second: 6,722.28711

Timestep Collection Time: 3.45002
Timestep Consumption Time: 3.99239
PPO Batch Consumption Time: 0.48010
Total Iteration Time: 7.44241

Cumulative Model Updates: 1,962
Cumulative Timesteps: 16,405,406

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 16405406...
Checkpoint 16405406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01632
Policy Entropy: 4.43120
Value Function Loss: 0.06079

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04210
Policy Update Magnitude: 0.79493
Value Function Update Magnitude: 0.35990

Collected Steps per Second: 14,600.93162
Overall Steps per Second: 6,764.80125

Timestep Collection Time: 3.42458
Timestep Consumption Time: 3.96692
PPO Batch Consumption Time: 0.47136
Total Iteration Time: 7.39150

Cumulative Model Updates: 1,968
Cumulative Timesteps: 16,455,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03861
Policy Entropy: 4.43607
Value Function Loss: 0.05297

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04410
Policy Update Magnitude: 0.80484
Value Function Update Magnitude: 0.33157

Collected Steps per Second: 14,485.83874
Overall Steps per Second: 6,699.13727

Timestep Collection Time: 3.45275
Timestep Consumption Time: 4.01328
PPO Batch Consumption Time: 0.47772
Total Iteration Time: 7.46604

Cumulative Model Updates: 1,974
Cumulative Timesteps: 16,505,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 16505424...
Checkpoint 16505424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07754
Policy Entropy: 4.43711
Value Function Loss: 0.04905

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03519
Policy Update Magnitude: 0.77011
Value Function Update Magnitude: 0.35379

Collected Steps per Second: 14,424.84209
Overall Steps per Second: 6,833.51474

Timestep Collection Time: 3.46694
Timestep Consumption Time: 3.85141
PPO Batch Consumption Time: 0.46880
Total Iteration Time: 7.31834

Cumulative Model Updates: 1,980
Cumulative Timesteps: 16,555,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00072
Policy Entropy: 4.43889
Value Function Loss: 0.03340

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03021
Policy Update Magnitude: 0.75334
Value Function Update Magnitude: 0.37555

Collected Steps per Second: 14,155.07149
Overall Steps per Second: 6,482.84800

Timestep Collection Time: 3.53400
Timestep Consumption Time: 4.18236
PPO Batch Consumption Time: 0.49899
Total Iteration Time: 7.71636

Cumulative Model Updates: 1,986
Cumulative Timesteps: 16,605,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 16605458...
Checkpoint 16605458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05531
Policy Entropy: 4.44100
Value Function Loss: 0.05150

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03419
Policy Update Magnitude: 0.75895
Value Function Update Magnitude: 0.45160

Collected Steps per Second: 14,442.49492
Overall Steps per Second: 6,700.35278

Timestep Collection Time: 3.46284
Timestep Consumption Time: 4.00125
PPO Batch Consumption Time: 0.47852
Total Iteration Time: 7.46408

Cumulative Model Updates: 1,992
Cumulative Timesteps: 16,655,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05431
Policy Entropy: 4.44129
Value Function Loss: 0.06079

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03859
Policy Update Magnitude: 0.77780
Value Function Update Magnitude: 0.49994

Collected Steps per Second: 14,498.79903
Overall Steps per Second: 6,720.78170

Timestep Collection Time: 3.45022
Timestep Consumption Time: 3.99297
PPO Batch Consumption Time: 0.47703
Total Iteration Time: 7.44318

Cumulative Model Updates: 1,998
Cumulative Timesteps: 16,705,494

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 16705494...
Checkpoint 16705494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02916
Policy Entropy: 4.44158
Value Function Loss: 0.05404

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03500
Policy Update Magnitude: 0.75294
Value Function Update Magnitude: 0.47564

Collected Steps per Second: 14,426.51057
Overall Steps per Second: 6,753.71542

Timestep Collection Time: 3.46598
Timestep Consumption Time: 3.93765
PPO Batch Consumption Time: 0.47495
Total Iteration Time: 7.40363

Cumulative Model Updates: 2,004
Cumulative Timesteps: 16,755,496

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07664
Policy Entropy: 4.43639
Value Function Loss: 0.07749

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02969
Policy Update Magnitude: 0.79053
Value Function Update Magnitude: 0.44740

Collected Steps per Second: 14,943.42794
Overall Steps per Second: 6,811.66867

Timestep Collection Time: 3.34702
Timestep Consumption Time: 3.99567
PPO Batch Consumption Time: 0.47202
Total Iteration Time: 7.34269

Cumulative Model Updates: 2,010
Cumulative Timesteps: 16,805,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 16805512...
Checkpoint 16805512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02348
Policy Entropy: 4.43105
Value Function Loss: 0.09385

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04943
Policy Update Magnitude: 0.90292
Value Function Update Magnitude: 0.48776

Collected Steps per Second: 14,560.74880
Overall Steps per Second: 6,685.93098

Timestep Collection Time: 3.43430
Timestep Consumption Time: 4.04499
PPO Batch Consumption Time: 0.47907
Total Iteration Time: 7.47929

Cumulative Model Updates: 2,016
Cumulative Timesteps: 16,855,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06884
Policy Entropy: 4.42978
Value Function Loss: 0.09254

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05639
Policy Update Magnitude: 0.89105
Value Function Update Magnitude: 0.48087

Collected Steps per Second: 14,708.84723
Overall Steps per Second: 6,838.47478

Timestep Collection Time: 3.40258
Timestep Consumption Time: 3.91601
PPO Batch Consumption Time: 0.46590
Total Iteration Time: 7.31859

Cumulative Model Updates: 2,022
Cumulative Timesteps: 16,905,566

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 16905566...
Checkpoint 16905566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02736
Policy Entropy: 4.43710
Value Function Loss: 0.07793

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04462
Policy Update Magnitude: 0.84199
Value Function Update Magnitude: 0.45944

Collected Steps per Second: 14,415.48195
Overall Steps per Second: 6,667.51303

Timestep Collection Time: 3.46946
Timestep Consumption Time: 4.03168
PPO Batch Consumption Time: 0.47868
Total Iteration Time: 7.50115

Cumulative Model Updates: 2,028
Cumulative Timesteps: 16,955,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10500
Policy Entropy: 4.43593
Value Function Loss: 0.06377

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03735
Policy Update Magnitude: 0.84607
Value Function Update Magnitude: 0.51026

Collected Steps per Second: 14,731.77190
Overall Steps per Second: 6,680.61025

Timestep Collection Time: 3.39457
Timestep Consumption Time: 4.09098
PPO Batch Consumption Time: 0.49395
Total Iteration Time: 7.48554

Cumulative Model Updates: 2,034
Cumulative Timesteps: 17,005,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 17005588...
Checkpoint 17005588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01909
Policy Entropy: 4.42778
Value Function Loss: 0.07340

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.04959
Policy Update Magnitude: 0.89895
Value Function Update Magnitude: 0.48525

Collected Steps per Second: 14,134.35273
Overall Steps per Second: 6,628.54801

Timestep Collection Time: 3.53748
Timestep Consumption Time: 4.00565
PPO Batch Consumption Time: 0.47982
Total Iteration Time: 7.54313

Cumulative Model Updates: 2,040
Cumulative Timesteps: 17,055,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03313
Policy Entropy: 4.42010
Value Function Loss: 0.08512

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.04720
Policy Update Magnitude: 0.91671
Value Function Update Magnitude: 0.53887

Collected Steps per Second: 14,914.40897
Overall Steps per Second: 6,820.26024

Timestep Collection Time: 3.35380
Timestep Consumption Time: 3.98023
PPO Batch Consumption Time: 0.47237
Total Iteration Time: 7.33403

Cumulative Model Updates: 2,046
Cumulative Timesteps: 17,105,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 17105608...
Checkpoint 17105608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00397
Policy Entropy: 4.42569
Value Function Loss: 0.07016

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05269
Policy Update Magnitude: 0.84738
Value Function Update Magnitude: 0.47452

Collected Steps per Second: 14,536.56638
Overall Steps per Second: 6,690.23794

Timestep Collection Time: 3.44139
Timestep Consumption Time: 4.03607
PPO Batch Consumption Time: 0.48074
Total Iteration Time: 7.47746

Cumulative Model Updates: 2,052
Cumulative Timesteps: 17,155,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08112
Policy Entropy: 4.42404
Value Function Loss: 0.07895

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05053
Policy Update Magnitude: 0.81678
Value Function Update Magnitude: 0.44490

Collected Steps per Second: 14,418.03582
Overall Steps per Second: 6,731.51938

Timestep Collection Time: 3.46927
Timestep Consumption Time: 3.96145
PPO Batch Consumption Time: 0.48208
Total Iteration Time: 7.43071

Cumulative Model Updates: 2,058
Cumulative Timesteps: 17,205,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 17205654...
Checkpoint 17205654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00441
Policy Entropy: 4.42187
Value Function Loss: 0.08952

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05165
Policy Update Magnitude: 0.84823
Value Function Update Magnitude: 0.39236

Collected Steps per Second: 14,235.40378
Overall Steps per Second: 6,676.80875

Timestep Collection Time: 3.51335
Timestep Consumption Time: 3.97735
PPO Batch Consumption Time: 0.47071
Total Iteration Time: 7.49070

Cumulative Model Updates: 2,064
Cumulative Timesteps: 17,255,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06480
Policy Entropy: 4.41771
Value Function Loss: 0.09592

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04703
Policy Update Magnitude: 0.87425
Value Function Update Magnitude: 0.40026

Collected Steps per Second: 14,628.23457
Overall Steps per Second: 6,693.88506

Timestep Collection Time: 3.41955
Timestep Consumption Time: 4.05324
PPO Batch Consumption Time: 0.48521
Total Iteration Time: 7.47279

Cumulative Model Updates: 2,070
Cumulative Timesteps: 17,305,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 17305690...
Checkpoint 17305690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02549
Policy Entropy: 4.41780
Value Function Loss: 0.08352

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.04896
Policy Update Magnitude: 0.83977
Value Function Update Magnitude: 0.39673

Collected Steps per Second: 14,612.77263
Overall Steps per Second: 6,790.52201

Timestep Collection Time: 3.42180
Timestep Consumption Time: 3.94170
PPO Batch Consumption Time: 0.47600
Total Iteration Time: 7.36350

Cumulative Model Updates: 2,076
Cumulative Timesteps: 17,355,692

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03946
Policy Entropy: 4.41968
Value Function Loss: 0.05798

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04709
Policy Update Magnitude: 0.78772
Value Function Update Magnitude: 0.40614

Collected Steps per Second: 14,424.77655
Overall Steps per Second: 6,589.93591

Timestep Collection Time: 3.46626
Timestep Consumption Time: 4.12107
PPO Batch Consumption Time: 0.49842
Total Iteration Time: 7.58733

Cumulative Model Updates: 2,082
Cumulative Timesteps: 17,405,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 17405692...
Checkpoint 17405692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00848
Policy Entropy: 4.42152
Value Function Loss: 0.06280

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04040
Policy Update Magnitude: 0.78871
Value Function Update Magnitude: 0.41619

Collected Steps per Second: 14,420.35936
Overall Steps per Second: 6,713.17178

Timestep Collection Time: 3.46871
Timestep Consumption Time: 3.98232
PPO Batch Consumption Time: 0.47694
Total Iteration Time: 7.45102

Cumulative Model Updates: 2,088
Cumulative Timesteps: 17,455,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00987
Policy Entropy: 4.42258
Value Function Loss: 0.06373

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04153
Policy Update Magnitude: 0.80740
Value Function Update Magnitude: 0.43407

Collected Steps per Second: 14,511.46631
Overall Steps per Second: 6,700.37361

Timestep Collection Time: 3.44624
Timestep Consumption Time: 4.01752
PPO Batch Consumption Time: 0.47898
Total Iteration Time: 7.46376

Cumulative Model Updates: 2,094
Cumulative Timesteps: 17,505,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 17505722...
Checkpoint 17505722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04425
Policy Entropy: 4.41720
Value Function Loss: 0.07613

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04308
Policy Update Magnitude: 0.83812
Value Function Update Magnitude: 0.40022

Collected Steps per Second: 14,533.32701
Overall Steps per Second: 6,726.92849

Timestep Collection Time: 3.44064
Timestep Consumption Time: 3.99276
PPO Batch Consumption Time: 0.47947
Total Iteration Time: 7.43341

Cumulative Model Updates: 2,100
Cumulative Timesteps: 17,555,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01649
Policy Entropy: 4.41601
Value Function Loss: 0.06178

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04076
Policy Update Magnitude: 0.83146
Value Function Update Magnitude: 0.38914

Collected Steps per Second: 14,878.17369
Overall Steps per Second: 6,771.46394

Timestep Collection Time: 3.36211
Timestep Consumption Time: 4.02507
PPO Batch Consumption Time: 0.48291
Total Iteration Time: 7.38718

Cumulative Model Updates: 2,106
Cumulative Timesteps: 17,605,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 17605748...
Checkpoint 17605748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06784
Policy Entropy: 4.41846
Value Function Loss: 0.06775

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.03930
Policy Update Magnitude: 0.84142
Value Function Update Magnitude: 0.40818

Collected Steps per Second: 14,376.51514
Overall Steps per Second: 6,694.60631

Timestep Collection Time: 3.47970
Timestep Consumption Time: 3.99288
PPO Batch Consumption Time: 0.47029
Total Iteration Time: 7.47258

Cumulative Model Updates: 2,112
Cumulative Timesteps: 17,655,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06985
Policy Entropy: 4.41541
Value Function Loss: 0.07307

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04437
Policy Update Magnitude: 0.86200
Value Function Update Magnitude: 0.41077

Collected Steps per Second: 14,524.64800
Overall Steps per Second: 6,738.17985

Timestep Collection Time: 3.44311
Timestep Consumption Time: 3.97877
PPO Batch Consumption Time: 0.47967
Total Iteration Time: 7.42189

Cumulative Model Updates: 2,118
Cumulative Timesteps: 17,705,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 17705784...
Checkpoint 17705784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03130
Policy Entropy: 4.42226
Value Function Loss: 0.06840

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03931
Policy Update Magnitude: 0.85185
Value Function Update Magnitude: 0.42666

Collected Steps per Second: 14,569.88182
Overall Steps per Second: 6,707.18075

Timestep Collection Time: 3.43366
Timestep Consumption Time: 4.02521
PPO Batch Consumption Time: 0.47962
Total Iteration Time: 7.45887

Cumulative Model Updates: 2,124
Cumulative Timesteps: 17,755,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09347
Policy Entropy: 4.42318
Value Function Loss: 0.08313

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04878
Policy Update Magnitude: 0.85584
Value Function Update Magnitude: 0.42352

Collected Steps per Second: 14,472.84038
Overall Steps per Second: 6,726.84721

Timestep Collection Time: 3.45571
Timestep Consumption Time: 3.97927
PPO Batch Consumption Time: 0.47735
Total Iteration Time: 7.43498

Cumulative Model Updates: 2,130
Cumulative Timesteps: 17,805,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 17805826...
Checkpoint 17805826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04776
Policy Entropy: 4.42359
Value Function Loss: 0.08863

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05617
Policy Update Magnitude: 0.88404
Value Function Update Magnitude: 0.48039

Collected Steps per Second: 14,522.56480
Overall Steps per Second: 6,610.73860

Timestep Collection Time: 3.44443
Timestep Consumption Time: 4.12235
PPO Batch Consumption Time: 0.49795
Total Iteration Time: 7.56678

Cumulative Model Updates: 2,136
Cumulative Timesteps: 17,855,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09876
Policy Entropy: 4.41936
Value Function Loss: 0.07835

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06385
Policy Update Magnitude: 0.85842
Value Function Update Magnitude: 0.45762

Collected Steps per Second: 14,530.23558
Overall Steps per Second: 6,642.66627

Timestep Collection Time: 3.44193
Timestep Consumption Time: 4.08698
PPO Batch Consumption Time: 0.49031
Total Iteration Time: 7.52890

Cumulative Model Updates: 2,142
Cumulative Timesteps: 17,905,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 17905860...
Checkpoint 17905860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06108
Policy Entropy: 4.42339
Value Function Loss: 0.06133

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04520
Policy Update Magnitude: 0.80606
Value Function Update Magnitude: 0.40008

Collected Steps per Second: 14,427.07755
Overall Steps per Second: 6,772.95447

Timestep Collection Time: 3.46737
Timestep Consumption Time: 3.91848
PPO Batch Consumption Time: 0.46901
Total Iteration Time: 7.38585

Cumulative Model Updates: 2,148
Cumulative Timesteps: 17,955,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07529
Policy Entropy: 4.42959
Value Function Loss: 0.04601

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04021
Policy Update Magnitude: 0.74940
Value Function Update Magnitude: 0.37222

Collected Steps per Second: 14,549.49184
Overall Steps per Second: 6,734.07548

Timestep Collection Time: 3.43668
Timestep Consumption Time: 3.98854
PPO Batch Consumption Time: 0.46887
Total Iteration Time: 7.42522

Cumulative Model Updates: 2,154
Cumulative Timesteps: 18,005,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 18005886...
Checkpoint 18005886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02267
Policy Entropy: 4.43284
Value Function Loss: 0.04047

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04113
Policy Update Magnitude: 0.68626
Value Function Update Magnitude: 0.33940

Collected Steps per Second: 14,450.44582
Overall Steps per Second: 6,711.86175

Timestep Collection Time: 3.46148
Timestep Consumption Time: 3.99099
PPO Batch Consumption Time: 0.47510
Total Iteration Time: 7.45248

Cumulative Model Updates: 2,160
Cumulative Timesteps: 18,055,906

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00098
Policy Entropy: 4.42915
Value Function Loss: 0.04777

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03064
Policy Update Magnitude: 0.68106
Value Function Update Magnitude: 0.33629

Collected Steps per Second: 14,884.59838
Overall Steps per Second: 6,763.52331

Timestep Collection Time: 3.35985
Timestep Consumption Time: 4.03423
PPO Batch Consumption Time: 0.47682
Total Iteration Time: 7.39408

Cumulative Model Updates: 2,166
Cumulative Timesteps: 18,105,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 18105916...
Checkpoint 18105916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00954
Policy Entropy: 4.42853
Value Function Loss: 0.06729

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03865
Policy Update Magnitude: 0.76234
Value Function Update Magnitude: 0.38916

Collected Steps per Second: 14,471.77626
Overall Steps per Second: 6,743.99053

Timestep Collection Time: 3.45583
Timestep Consumption Time: 3.95996
PPO Batch Consumption Time: 0.47393
Total Iteration Time: 7.41579

Cumulative Model Updates: 2,172
Cumulative Timesteps: 18,155,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00224
Policy Entropy: 4.43097
Value Function Loss: 0.07017

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04449
Policy Update Magnitude: 0.80420
Value Function Update Magnitude: 0.38115

Collected Steps per Second: 14,564.45935
Overall Steps per Second: 6,786.13649

Timestep Collection Time: 3.43507
Timestep Consumption Time: 3.93731
PPO Batch Consumption Time: 0.47373
Total Iteration Time: 7.37238

Cumulative Model Updates: 2,178
Cumulative Timesteps: 18,205,958

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 18205958...
Checkpoint 18205958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15513
Policy Entropy: 4.43091
Value Function Loss: 0.06656

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03487
Policy Update Magnitude: 0.76006
Value Function Update Magnitude: 0.41391

Collected Steps per Second: 14,252.26759
Overall Steps per Second: 6,473.36027

Timestep Collection Time: 3.50835
Timestep Consumption Time: 4.21592
PPO Batch Consumption Time: 0.51137
Total Iteration Time: 7.72427

Cumulative Model Updates: 2,184
Cumulative Timesteps: 18,255,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01398
Policy Entropy: 4.43847
Value Function Loss: 0.04196

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02755
Policy Update Magnitude: 0.74138
Value Function Update Magnitude: 0.39514

Collected Steps per Second: 14,275.84746
Overall Steps per Second: 6,615.14219

Timestep Collection Time: 3.50424
Timestep Consumption Time: 4.05811
PPO Batch Consumption Time: 0.48591
Total Iteration Time: 7.56235

Cumulative Model Updates: 2,190
Cumulative Timesteps: 18,305,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 18305986...
Checkpoint 18305986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00444
Policy Entropy: 4.43942
Value Function Loss: 0.04576

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02900
Policy Update Magnitude: 0.72325
Value Function Update Magnitude: 0.40101

Collected Steps per Second: 14,697.00413
Overall Steps per Second: 6,716.82122

Timestep Collection Time: 3.40423
Timestep Consumption Time: 4.04453
PPO Batch Consumption Time: 0.48563
Total Iteration Time: 7.44876

Cumulative Model Updates: 2,196
Cumulative Timesteps: 18,356,018

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08988
Policy Entropy: 4.43830
Value Function Loss: 0.03553

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.69740
Value Function Update Magnitude: 0.39684

Collected Steps per Second: 14,524.56317
Overall Steps per Second: 6,727.06572

Timestep Collection Time: 3.44368
Timestep Consumption Time: 3.99165
PPO Batch Consumption Time: 0.46531
Total Iteration Time: 7.43534

Cumulative Model Updates: 2,202
Cumulative Timesteps: 18,406,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 18406036...
Checkpoint 18406036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00036
Policy Entropy: 4.44160
Value Function Loss: 0.04012

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.68077
Value Function Update Magnitude: 0.36720

Collected Steps per Second: 14,398.07247
Overall Steps per Second: 6,745.17442

Timestep Collection Time: 3.47338
Timestep Consumption Time: 3.94081
PPO Batch Consumption Time: 0.47844
Total Iteration Time: 7.41419

Cumulative Model Updates: 2,208
Cumulative Timesteps: 18,456,046

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02012
Policy Entropy: 4.44119
Value Function Loss: 0.04025

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02082
Policy Update Magnitude: 0.71334
Value Function Update Magnitude: 0.38630

Collected Steps per Second: 14,524.32192
Overall Steps per Second: 6,687.93161

Timestep Collection Time: 3.44278
Timestep Consumption Time: 4.03397
PPO Batch Consumption Time: 0.47786
Total Iteration Time: 7.47675

Cumulative Model Updates: 2,214
Cumulative Timesteps: 18,506,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 18506050...
Checkpoint 18506050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04521
Policy Entropy: 4.44251
Value Function Loss: 0.04970

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.73565
Value Function Update Magnitude: 0.41864

Collected Steps per Second: 14,490.69779
Overall Steps per Second: 6,720.90767

Timestep Collection Time: 3.45077
Timestep Consumption Time: 3.98930
PPO Batch Consumption Time: 0.48130
Total Iteration Time: 7.44007

Cumulative Model Updates: 2,220
Cumulative Timesteps: 18,556,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03578
Policy Entropy: 4.43614
Value Function Loss: 0.05269

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.76291
Value Function Update Magnitude: 0.41392

Collected Steps per Second: 14,609.05741
Overall Steps per Second: 6,683.16685

Timestep Collection Time: 3.42294
Timestep Consumption Time: 4.05944
PPO Batch Consumption Time: 0.48446
Total Iteration Time: 7.48238

Cumulative Model Updates: 2,226
Cumulative Timesteps: 18,606,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 18606060...
Checkpoint 18606060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02678
Policy Entropy: 4.43389
Value Function Loss: 0.05176

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02633
Policy Update Magnitude: 0.77848
Value Function Update Magnitude: 0.39533

Collected Steps per Second: 14,630.81503
Overall Steps per Second: 6,621.70136

Timestep Collection Time: 3.41826
Timestep Consumption Time: 4.13448
PPO Batch Consumption Time: 0.50563
Total Iteration Time: 7.55274

Cumulative Model Updates: 2,232
Cumulative Timesteps: 18,656,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04349
Policy Entropy: 4.43155
Value Function Loss: 0.04396

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02991
Policy Update Magnitude: 0.74807
Value Function Update Magnitude: 0.37507

Collected Steps per Second: 14,952.51815
Overall Steps per Second: 6,699.43129

Timestep Collection Time: 3.34566
Timestep Consumption Time: 4.12154
PPO Batch Consumption Time: 0.49600
Total Iteration Time: 7.46720

Cumulative Model Updates: 2,238
Cumulative Timesteps: 18,706,098

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 18706098...
Checkpoint 18706098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04200
Policy Entropy: 4.43617
Value Function Loss: 0.04389

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02564
Policy Update Magnitude: 0.71457
Value Function Update Magnitude: 0.34500

Collected Steps per Second: 14,545.70589
Overall Steps per Second: 6,639.32357

Timestep Collection Time: 3.43758
Timestep Consumption Time: 4.09361
PPO Batch Consumption Time: 0.48281
Total Iteration Time: 7.53119

Cumulative Model Updates: 2,244
Cumulative Timesteps: 18,756,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06644
Policy Entropy: 4.43156
Value Function Loss: 0.06627

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03333
Policy Update Magnitude: 0.74254
Value Function Update Magnitude: 0.34024

Collected Steps per Second: 14,731.06776
Overall Steps per Second: 6,785.20125

Timestep Collection Time: 3.39582
Timestep Consumption Time: 3.97670
PPO Batch Consumption Time: 0.47533
Total Iteration Time: 7.37252

Cumulative Model Updates: 2,250
Cumulative Timesteps: 18,806,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 18806124...
Checkpoint 18806124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02110
Policy Entropy: 4.43380
Value Function Loss: 0.05889

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03597
Policy Update Magnitude: 0.80002
Value Function Update Magnitude: 0.36601

Collected Steps per Second: 14,449.59560
Overall Steps per Second: 6,706.92484

Timestep Collection Time: 3.46197
Timestep Consumption Time: 3.99659
PPO Batch Consumption Time: 0.48085
Total Iteration Time: 7.45856

Cumulative Model Updates: 2,256
Cumulative Timesteps: 18,856,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07744
Policy Entropy: 4.42942
Value Function Loss: 0.05038

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03374
Policy Update Magnitude: 0.75689
Value Function Update Magnitude: 0.34479

Collected Steps per Second: 14,950.74866
Overall Steps per Second: 6,824.16318

Timestep Collection Time: 3.34592
Timestep Consumption Time: 3.98450
PPO Batch Consumption Time: 0.47301
Total Iteration Time: 7.33042

Cumulative Model Updates: 2,262
Cumulative Timesteps: 18,906,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 18906172...
Checkpoint 18906172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05998
Policy Entropy: 4.43425
Value Function Loss: 0.03265

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02823
Policy Update Magnitude: 0.68989
Value Function Update Magnitude: 0.29717

Collected Steps per Second: 14,520.13876
Overall Steps per Second: 6,730.95635

Timestep Collection Time: 3.44501
Timestep Consumption Time: 3.98663
PPO Batch Consumption Time: 0.47357
Total Iteration Time: 7.43163

Cumulative Model Updates: 2,268
Cumulative Timesteps: 18,956,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04031
Policy Entropy: 4.43378
Value Function Loss: 0.03971

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02952
Policy Update Magnitude: 0.66747
Value Function Update Magnitude: 0.31506

Collected Steps per Second: 14,859.19537
Overall Steps per Second: 6,760.19970

Timestep Collection Time: 3.36707
Timestep Consumption Time: 4.03389
PPO Batch Consumption Time: 0.47843
Total Iteration Time: 7.40096

Cumulative Model Updates: 2,274
Cumulative Timesteps: 19,006,226

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 19006226...
Checkpoint 19006226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01375
Policy Entropy: 4.43047
Value Function Loss: 0.03891

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02772
Policy Update Magnitude: 0.68586
Value Function Update Magnitude: 0.34326

Collected Steps per Second: 14,415.15758
Overall Steps per Second: 6,667.04369

Timestep Collection Time: 3.46996
Timestep Consumption Time: 4.03262
PPO Batch Consumption Time: 0.48593
Total Iteration Time: 7.50258

Cumulative Model Updates: 2,280
Cumulative Timesteps: 19,056,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05854
Policy Entropy: 4.43514
Value Function Loss: 0.03387

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 0.71845
Value Function Update Magnitude: 0.35413

Collected Steps per Second: 14,620.29963
Overall Steps per Second: 6,690.34299

Timestep Collection Time: 3.42168
Timestep Consumption Time: 4.05566
PPO Batch Consumption Time: 0.48603
Total Iteration Time: 7.47734

Cumulative Model Updates: 2,286
Cumulative Timesteps: 19,106,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 19106272...
Checkpoint 19106272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02538
Policy Entropy: 4.43572
Value Function Loss: 0.02532

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02733
Policy Update Magnitude: 0.67104
Value Function Update Magnitude: 0.30584

Collected Steps per Second: 14,733.61707
Overall Steps per Second: 6,725.15346

Timestep Collection Time: 3.39482
Timestep Consumption Time: 4.04263
PPO Batch Consumption Time: 0.47830
Total Iteration Time: 7.43745

Cumulative Model Updates: 2,292
Cumulative Timesteps: 19,156,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02009
Policy Entropy: 4.44135
Value Function Loss: 0.01689

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02043
Policy Update Magnitude: 0.57836
Value Function Update Magnitude: 0.25286

Collected Steps per Second: 14,818.21882
Overall Steps per Second: 6,778.56534

Timestep Collection Time: 3.37598
Timestep Consumption Time: 4.00405
PPO Batch Consumption Time: 0.47498
Total Iteration Time: 7.38003

Cumulative Model Updates: 2,298
Cumulative Timesteps: 19,206,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 19206316...
Checkpoint 19206316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08170
Policy Entropy: 4.44714
Value Function Loss: 0.02030

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02081
Policy Update Magnitude: 0.52871
Value Function Update Magnitude: 0.23771

Collected Steps per Second: 14,482.26972
Overall Steps per Second: 6,757.33140

Timestep Collection Time: 3.45250
Timestep Consumption Time: 3.94687
PPO Batch Consumption Time: 0.46817
Total Iteration Time: 7.39937

Cumulative Model Updates: 2,304
Cumulative Timesteps: 19,256,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09338
Policy Entropy: 4.44609
Value Function Loss: 0.03775

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02003
Policy Update Magnitude: 0.62128
Value Function Update Magnitude: 0.28061

Collected Steps per Second: 14,702.59754
Overall Steps per Second: 6,775.20341

Timestep Collection Time: 3.40158
Timestep Consumption Time: 3.98005
PPO Batch Consumption Time: 0.47916
Total Iteration Time: 7.38162

Cumulative Model Updates: 2,310
Cumulative Timesteps: 19,306,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 19306328...
Checkpoint 19306328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00570
Policy Entropy: 4.44660
Value Function Loss: 0.04346

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02465
Policy Update Magnitude: 0.66589
Value Function Update Magnitude: 0.33464

Collected Steps per Second: 14,608.84532
Overall Steps per Second: 6,728.40710

Timestep Collection Time: 3.42327
Timestep Consumption Time: 4.00940
PPO Batch Consumption Time: 0.47395
Total Iteration Time: 7.43267

Cumulative Model Updates: 2,316
Cumulative Timesteps: 19,356,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04844
Policy Entropy: 4.44524
Value Function Loss: 0.03720

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.65971
Value Function Update Magnitude: 0.32485

Collected Steps per Second: 14,805.74176
Overall Steps per Second: 6,754.56971

Timestep Collection Time: 3.37801
Timestep Consumption Time: 4.02645
PPO Batch Consumption Time: 0.47796
Total Iteration Time: 7.40447

Cumulative Model Updates: 2,322
Cumulative Timesteps: 19,406,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 19406352...
Checkpoint 19406352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03649
Policy Entropy: 4.45062
Value Function Loss: 0.02411

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01781
Policy Update Magnitude: 0.63982
Value Function Update Magnitude: 0.33111

Collected Steps per Second: 14,492.15293
Overall Steps per Second: 6,734.22803

Timestep Collection Time: 3.45014
Timestep Consumption Time: 3.97461
PPO Batch Consumption Time: 0.47841
Total Iteration Time: 7.42476

Cumulative Model Updates: 2,328
Cumulative Timesteps: 19,456,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02742
Policy Entropy: 4.44768
Value Function Loss: 0.02982

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02025
Policy Update Magnitude: 0.63733
Value Function Update Magnitude: 0.32498

Collected Steps per Second: 14,719.20860
Overall Steps per Second: 6,615.23071

Timestep Collection Time: 3.39787
Timestep Consumption Time: 4.16256
PPO Batch Consumption Time: 0.50160
Total Iteration Time: 7.56043

Cumulative Model Updates: 2,334
Cumulative Timesteps: 19,506,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 19506366...
Checkpoint 19506366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03489
Policy Entropy: 4.44375
Value Function Loss: 0.03742

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02310
Policy Update Magnitude: 0.66971
Value Function Update Magnitude: 0.34063

Collected Steps per Second: 14,417.72677
Overall Steps per Second: 6,734.14060

Timestep Collection Time: 3.46809
Timestep Consumption Time: 3.95706
PPO Batch Consumption Time: 0.48219
Total Iteration Time: 7.42515

Cumulative Model Updates: 2,340
Cumulative Timesteps: 19,556,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02677
Policy Entropy: 4.44246
Value Function Loss: 0.04758

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.72222
Value Function Update Magnitude: 0.38347

Collected Steps per Second: 14,606.79830
Overall Steps per Second: 6,687.67738

Timestep Collection Time: 3.42471
Timestep Consumption Time: 4.05532
PPO Batch Consumption Time: 0.48375
Total Iteration Time: 7.48003

Cumulative Model Updates: 2,346
Cumulative Timesteps: 19,606,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 19606392...
Checkpoint 19606392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02760
Policy Entropy: 4.44190
Value Function Loss: 0.04583

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.72289
Value Function Update Magnitude: 0.42408

Collected Steps per Second: 14,420.29622
Overall Steps per Second: 6,711.95384

Timestep Collection Time: 3.46844
Timestep Consumption Time: 3.98333
PPO Batch Consumption Time: 0.47752
Total Iteration Time: 7.45178

Cumulative Model Updates: 2,352
Cumulative Timesteps: 19,656,408

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02917
Policy Entropy: 4.44407
Value Function Loss: 0.04477

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 0.73588
Value Function Update Magnitude: 0.39152

Collected Steps per Second: 15,047.08655
Overall Steps per Second: 6,833.26196

Timestep Collection Time: 3.32290
Timestep Consumption Time: 3.99425
PPO Batch Consumption Time: 0.47770
Total Iteration Time: 7.31715

Cumulative Model Updates: 2,358
Cumulative Timesteps: 19,706,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 19706408...
Checkpoint 19706408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05142
Policy Entropy: 4.43896
Value Function Loss: 0.03968

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03010
Policy Update Magnitude: 0.71792
Value Function Update Magnitude: 0.36122

Collected Steps per Second: 14,622.07693
Overall Steps per Second: 6,759.93410

Timestep Collection Time: 3.42058
Timestep Consumption Time: 3.97831
PPO Batch Consumption Time: 0.47267
Total Iteration Time: 7.39889

Cumulative Model Updates: 2,364
Cumulative Timesteps: 19,756,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04023
Policy Entropy: 4.43668
Value Function Loss: 0.04063

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 0.70716
Value Function Update Magnitude: 0.38260

Collected Steps per Second: 14,350.33538
Overall Steps per Second: 6,708.32934

Timestep Collection Time: 3.48619
Timestep Consumption Time: 3.97140
PPO Batch Consumption Time: 0.48367
Total Iteration Time: 7.45759

Cumulative Model Updates: 2,370
Cumulative Timesteps: 19,806,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 19806452...
Checkpoint 19806452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00142
Policy Entropy: 4.44224
Value Function Loss: 0.03807

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03184
Policy Update Magnitude: 0.69354
Value Function Update Magnitude: 0.38665

Collected Steps per Second: 14,025.03075
Overall Steps per Second: 6,584.46774

Timestep Collection Time: 3.56691
Timestep Consumption Time: 4.03067
PPO Batch Consumption Time: 0.47794
Total Iteration Time: 7.59758

Cumulative Model Updates: 2,376
Cumulative Timesteps: 19,856,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06633
Policy Entropy: 4.43655
Value Function Loss: 0.03678

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03321
Policy Update Magnitude: 0.68635
Value Function Update Magnitude: 0.36419

Collected Steps per Second: 14,645.50095
Overall Steps per Second: 6,797.17186

Timestep Collection Time: 3.41484
Timestep Consumption Time: 3.94293
PPO Batch Consumption Time: 0.47293
Total Iteration Time: 7.35777

Cumulative Model Updates: 2,382
Cumulative Timesteps: 19,906,490

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 19906490...
Checkpoint 19906490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03001
Policy Entropy: 4.43833
Value Function Loss: 0.04771

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03182
Policy Update Magnitude: 0.72758
Value Function Update Magnitude: 0.32743

Collected Steps per Second: 14,711.48343
Overall Steps per Second: 6,632.80174

Timestep Collection Time: 3.40061
Timestep Consumption Time: 4.14191
PPO Batch Consumption Time: 0.49693
Total Iteration Time: 7.54251

Cumulative Model Updates: 2,388
Cumulative Timesteps: 19,956,518

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11473
Policy Entropy: 4.43887
Value Function Loss: 0.04778

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03443
Policy Update Magnitude: 0.77364
Value Function Update Magnitude: 0.33698

Collected Steps per Second: 14,456.62768
Overall Steps per Second: 6,681.47744

Timestep Collection Time: 3.46056
Timestep Consumption Time: 4.02701
PPO Batch Consumption Time: 0.47719
Total Iteration Time: 7.48757

Cumulative Model Updates: 2,394
Cumulative Timesteps: 20,006,546

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 20006546...
Checkpoint 20006546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03146
Policy Entropy: 4.43848
Value Function Loss: 0.05575

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03312
Policy Update Magnitude: 0.77306
Value Function Update Magnitude: 0.32575

Collected Steps per Second: 14,360.21506
Overall Steps per Second: 6,660.11762

Timestep Collection Time: 3.48240
Timestep Consumption Time: 4.02618
PPO Batch Consumption Time: 0.49029
Total Iteration Time: 7.50858

Cumulative Model Updates: 2,400
Cumulative Timesteps: 20,056,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05773
Policy Entropy: 4.43699
Value Function Loss: 0.06439

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03410
Policy Update Magnitude: 0.80545
Value Function Update Magnitude: 0.35041

Collected Steps per Second: 14,589.78221
Overall Steps per Second: 6,644.59865

Timestep Collection Time: 3.42980
Timestep Consumption Time: 4.10113
PPO Batch Consumption Time: 0.48747
Total Iteration Time: 7.53093

Cumulative Model Updates: 2,406
Cumulative Timesteps: 20,106,594

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 20106594...
Checkpoint 20106594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05649
Policy Entropy: 4.43595
Value Function Loss: 0.06135

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03936
Policy Update Magnitude: 0.81672
Value Function Update Magnitude: 0.39725

Collected Steps per Second: 14,510.22225
Overall Steps per Second: 6,720.25108

Timestep Collection Time: 3.44585
Timestep Consumption Time: 3.99435
PPO Batch Consumption Time: 0.48618
Total Iteration Time: 7.44020

Cumulative Model Updates: 2,412
Cumulative Timesteps: 20,156,594

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01540
Policy Entropy: 4.43477
Value Function Loss: 0.05915

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03485
Policy Update Magnitude: 0.77828
Value Function Update Magnitude: 0.37054

Collected Steps per Second: 14,123.21711
Overall Steps per Second: 6,579.61332

Timestep Collection Time: 3.54197
Timestep Consumption Time: 4.06091
PPO Batch Consumption Time: 0.48654
Total Iteration Time: 7.60288

Cumulative Model Updates: 2,418
Cumulative Timesteps: 20,206,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 20206618...
Checkpoint 20206618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.20870
Policy Entropy: 4.43790
Value Function Loss: 0.05192

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02994
Policy Update Magnitude: 0.75720
Value Function Update Magnitude: 0.38376

Collected Steps per Second: 14,000.65713
Overall Steps per Second: 6,630.58332

Timestep Collection Time: 3.57312
Timestep Consumption Time: 3.97162
PPO Batch Consumption Time: 0.47374
Total Iteration Time: 7.54474

Cumulative Model Updates: 2,424
Cumulative Timesteps: 20,256,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01941
Policy Entropy: 4.42754
Value Function Loss: 0.05692

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03654
Policy Update Magnitude: 0.77754
Value Function Update Magnitude: 0.36816

Collected Steps per Second: 14,530.40729
Overall Steps per Second: 6,785.57190

Timestep Collection Time: 3.44147
Timestep Consumption Time: 3.92799
PPO Batch Consumption Time: 0.47293
Total Iteration Time: 7.36946

Cumulative Model Updates: 2,430
Cumulative Timesteps: 20,306,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 20306650...
Checkpoint 20306650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05469
Policy Entropy: 4.42830
Value Function Loss: 0.05186

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04134
Policy Update Magnitude: 0.80949
Value Function Update Magnitude: 0.37764

Collected Steps per Second: 14,211.28518
Overall Steps per Second: 6,574.61323

Timestep Collection Time: 3.51903
Timestep Consumption Time: 4.08750
PPO Batch Consumption Time: 0.49157
Total Iteration Time: 7.60653

Cumulative Model Updates: 2,436
Cumulative Timesteps: 20,356,660

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00003
Policy Entropy: 4.43016
Value Function Loss: 0.05846

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03973
Policy Update Magnitude: 0.80050
Value Function Update Magnitude: 0.40628

Collected Steps per Second: 14,570.47465
Overall Steps per Second: 6,744.84891

Timestep Collection Time: 3.43160
Timestep Consumption Time: 3.98147
PPO Batch Consumption Time: 0.47905
Total Iteration Time: 7.41306

Cumulative Model Updates: 2,442
Cumulative Timesteps: 20,406,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 20406660...
Checkpoint 20406660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02002
Policy Entropy: 4.43725
Value Function Loss: 0.04520

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 0.77609
Value Function Update Magnitude: 0.36430

Collected Steps per Second: 14,266.00679
Overall Steps per Second: 6,616.39798

Timestep Collection Time: 3.50708
Timestep Consumption Time: 4.05474
PPO Batch Consumption Time: 0.48559
Total Iteration Time: 7.56182

Cumulative Model Updates: 2,448
Cumulative Timesteps: 20,456,692

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05168
Policy Entropy: 4.43240
Value Function Loss: 0.05419

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03285
Policy Update Magnitude: 0.74363
Value Function Update Magnitude: 0.35132

Collected Steps per Second: 14,578.71711
Overall Steps per Second: 6,684.88505

Timestep Collection Time: 3.43021
Timestep Consumption Time: 4.05055
PPO Batch Consumption Time: 0.48282
Total Iteration Time: 7.48076

Cumulative Model Updates: 2,454
Cumulative Timesteps: 20,506,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 20506700...
Checkpoint 20506700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06343
Policy Entropy: 4.42796
Value Function Loss: 0.07901

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03848
Policy Update Magnitude: 0.86040
Value Function Update Magnitude: 0.39696

Collected Steps per Second: 14,794.44727
Overall Steps per Second: 6,773.13962

Timestep Collection Time: 3.38127
Timestep Consumption Time: 4.00438
PPO Batch Consumption Time: 0.47425
Total Iteration Time: 7.38564

Cumulative Model Updates: 2,460
Cumulative Timesteps: 20,556,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03489
Policy Entropy: 4.42976
Value Function Loss: 0.08366

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05040
Policy Update Magnitude: 0.93915
Value Function Update Magnitude: 0.45288

Collected Steps per Second: 14,517.14679
Overall Steps per Second: 6,752.86112

Timestep Collection Time: 3.44448
Timestep Consumption Time: 3.96038
PPO Batch Consumption Time: 0.47226
Total Iteration Time: 7.40486

Cumulative Model Updates: 2,466
Cumulative Timesteps: 20,606,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 20606728...
Checkpoint 20606728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04705
Policy Entropy: 4.43255
Value Function Loss: 0.07040

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04044
Policy Update Magnitude: 0.85710
Value Function Update Magnitude: 0.47034

Collected Steps per Second: 14,452.69741
Overall Steps per Second: 6,735.66640

Timestep Collection Time: 3.46122
Timestep Consumption Time: 3.96551
PPO Batch Consumption Time: 0.47707
Total Iteration Time: 7.42673

Cumulative Model Updates: 2,472
Cumulative Timesteps: 20,656,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04351
Policy Entropy: 4.42596
Value Function Loss: 0.05087

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03455
Policy Update Magnitude: 0.77174
Value Function Update Magnitude: 0.43480

Collected Steps per Second: 14,609.56188
Overall Steps per Second: 6,671.99959

Timestep Collection Time: 3.42296
Timestep Consumption Time: 4.07224
PPO Batch Consumption Time: 0.48759
Total Iteration Time: 7.49520

Cumulative Model Updates: 2,478
Cumulative Timesteps: 20,706,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 20706760...
Checkpoint 20706760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04012
Policy Entropy: 4.42649
Value Function Loss: 0.04754

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03642
Policy Update Magnitude: 0.75007
Value Function Update Magnitude: 0.39308

Collected Steps per Second: 14,500.83591
Overall Steps per Second: 6,732.12937

Timestep Collection Time: 3.44877
Timestep Consumption Time: 3.97979
PPO Batch Consumption Time: 0.49270
Total Iteration Time: 7.42856

Cumulative Model Updates: 2,484
Cumulative Timesteps: 20,756,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05453
Policy Entropy: 4.42715
Value Function Loss: 0.05850

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 0.78557
Value Function Update Magnitude: 0.40578

Collected Steps per Second: 14,472.90534
Overall Steps per Second: 6,698.08691

Timestep Collection Time: 3.45556
Timestep Consumption Time: 4.01105
PPO Batch Consumption Time: 0.47688
Total Iteration Time: 7.46661

Cumulative Model Updates: 2,490
Cumulative Timesteps: 20,806,782

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 20806782...
Checkpoint 20806782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21568
Policy Entropy: 4.42407
Value Function Loss: 0.06395

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04063
Policy Update Magnitude: 0.84104
Value Function Update Magnitude: 0.51530

Collected Steps per Second: 14,528.44319
Overall Steps per Second: 6,683.06179

Timestep Collection Time: 3.44318
Timestep Consumption Time: 4.04202
PPO Batch Consumption Time: 0.48589
Total Iteration Time: 7.48519

Cumulative Model Updates: 2,496
Cumulative Timesteps: 20,856,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09638
Policy Entropy: 4.42271
Value Function Loss: 0.06584

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04697
Policy Update Magnitude: 0.84096
Value Function Update Magnitude: 0.44849

Collected Steps per Second: 14,727.96127
Overall Steps per Second: 6,785.20595

Timestep Collection Time: 3.39517
Timestep Consumption Time: 3.97439
PPO Batch Consumption Time: 0.48276
Total Iteration Time: 7.36956

Cumulative Model Updates: 2,502
Cumulative Timesteps: 20,906,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 20906810...
Checkpoint 20906810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06440
Policy Entropy: 4.41986
Value Function Loss: 0.06971

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04226
Policy Update Magnitude: 0.85688
Value Function Update Magnitude: 0.36293

Collected Steps per Second: 14,532.05310
Overall Steps per Second: 6,632.92246

Timestep Collection Time: 3.44191
Timestep Consumption Time: 4.09896
PPO Batch Consumption Time: 0.49232
Total Iteration Time: 7.54087

Cumulative Model Updates: 2,508
Cumulative Timesteps: 20,956,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00720
Policy Entropy: 4.42128
Value Function Loss: 0.06664

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03773
Policy Update Magnitude: 0.85229
Value Function Update Magnitude: 0.32147

Collected Steps per Second: 14,553.97690
Overall Steps per Second: 6,726.02653

Timestep Collection Time: 3.43755
Timestep Consumption Time: 4.00072
PPO Batch Consumption Time: 0.48197
Total Iteration Time: 7.43827

Cumulative Model Updates: 2,514
Cumulative Timesteps: 21,006,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 21006858...
Checkpoint 21006858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04686
Policy Entropy: 4.41846
Value Function Loss: 0.06133

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.03964
Policy Update Magnitude: 0.84630
Value Function Update Magnitude: 0.32673

Collected Steps per Second: 14,418.84722
Overall Steps per Second: 6,710.87202

Timestep Collection Time: 3.46963
Timestep Consumption Time: 3.98514
PPO Batch Consumption Time: 0.48099
Total Iteration Time: 7.45477

Cumulative Model Updates: 2,520
Cumulative Timesteps: 21,056,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10011
Policy Entropy: 4.41247
Value Function Loss: 0.05767

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04238
Policy Update Magnitude: 0.81720
Value Function Update Magnitude: 0.33216

Collected Steps per Second: 14,411.14011
Overall Steps per Second: 6,762.91856

Timestep Collection Time: 3.47120
Timestep Consumption Time: 3.92560
PPO Batch Consumption Time: 0.46553
Total Iteration Time: 7.39681

Cumulative Model Updates: 2,526
Cumulative Timesteps: 21,106,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 21106910...
Checkpoint 21106910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05433
Policy Entropy: 4.41428
Value Function Loss: 0.05608

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04396
Policy Update Magnitude: 0.79543
Value Function Update Magnitude: 0.33136

Collected Steps per Second: 14,372.60777
Overall Steps per Second: 6,748.80624

Timestep Collection Time: 3.48065
Timestep Consumption Time: 3.93192
PPO Batch Consumption Time: 0.48198
Total Iteration Time: 7.41257

Cumulative Model Updates: 2,532
Cumulative Timesteps: 21,156,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09854
Policy Entropy: 4.41588
Value Function Loss: 0.05415

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03851
Policy Update Magnitude: 0.77731
Value Function Update Magnitude: 0.33991

Collected Steps per Second: 14,296.96709
Overall Steps per Second: 6,524.22368

Timestep Collection Time: 3.49906
Timestep Consumption Time: 4.16867
PPO Batch Consumption Time: 0.49859
Total Iteration Time: 7.66773

Cumulative Model Updates: 2,538
Cumulative Timesteps: 21,206,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 21206962...
Checkpoint 21206962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01262
Policy Entropy: 4.42017
Value Function Loss: 0.04807

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03317
Policy Update Magnitude: 0.76801
Value Function Update Magnitude: 0.34520

Collected Steps per Second: 14,437.26219
Overall Steps per Second: 6,671.94078

Timestep Collection Time: 3.46368
Timestep Consumption Time: 4.03129
PPO Batch Consumption Time: 0.49187
Total Iteration Time: 7.49497

Cumulative Model Updates: 2,544
Cumulative Timesteps: 21,256,968

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06018
Policy Entropy: 4.41789
Value Function Loss: 0.04539

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03792
Policy Update Magnitude: 0.74415
Value Function Update Magnitude: 0.34796

Collected Steps per Second: 14,577.77423
Overall Steps per Second: 6,731.65873

Timestep Collection Time: 3.43221
Timestep Consumption Time: 4.00043
PPO Batch Consumption Time: 0.48083
Total Iteration Time: 7.43264

Cumulative Model Updates: 2,550
Cumulative Timesteps: 21,307,002

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 21307002...
Checkpoint 21307002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00367
Policy Entropy: 4.42096
Value Function Loss: 0.04526

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03842
Policy Update Magnitude: 0.72370
Value Function Update Magnitude: 0.32644

Collected Steps per Second: 14,359.74568
Overall Steps per Second: 6,661.41664

Timestep Collection Time: 3.48335
Timestep Consumption Time: 4.02556
PPO Batch Consumption Time: 0.48621
Total Iteration Time: 7.50891

Cumulative Model Updates: 2,556
Cumulative Timesteps: 21,357,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00447
Policy Entropy: 4.42651
Value Function Loss: 0.04701

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03370
Policy Update Magnitude: 0.72756
Value Function Update Magnitude: 0.33856

Collected Steps per Second: 14,830.70303
Overall Steps per Second: 6,741.72277

Timestep Collection Time: 3.37152
Timestep Consumption Time: 4.04528
PPO Batch Consumption Time: 0.48435
Total Iteration Time: 7.41680

Cumulative Model Updates: 2,562
Cumulative Timesteps: 21,407,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 21407024...
Checkpoint 21407024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01888
Policy Entropy: 4.42122
Value Function Loss: 0.04752

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03273
Policy Update Magnitude: 0.75802
Value Function Update Magnitude: 0.34327

Collected Steps per Second: 14,285.40782
Overall Steps per Second: 6,651.60760

Timestep Collection Time: 3.50078
Timestep Consumption Time: 4.01771
PPO Batch Consumption Time: 0.48251
Total Iteration Time: 7.51848

Cumulative Model Updates: 2,568
Cumulative Timesteps: 21,457,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03246
Policy Entropy: 4.41985
Value Function Loss: 0.05297

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03132
Policy Update Magnitude: 0.77630
Value Function Update Magnitude: 0.35683

Collected Steps per Second: 14,675.14633
Overall Steps per Second: 6,674.39137

Timestep Collection Time: 3.40848
Timestep Consumption Time: 4.08583
PPO Batch Consumption Time: 0.49005
Total Iteration Time: 7.49432

Cumulative Model Updates: 2,574
Cumulative Timesteps: 21,507,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 21507054...
Checkpoint 21507054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02406
Policy Entropy: 4.42101
Value Function Loss: 0.05354

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03391
Policy Update Magnitude: 0.76682
Value Function Update Magnitude: 0.37556

Collected Steps per Second: 14,348.89377
Overall Steps per Second: 6,769.26406

Timestep Collection Time: 3.48612
Timestep Consumption Time: 3.90345
PPO Batch Consumption Time: 0.46205
Total Iteration Time: 7.38958

Cumulative Model Updates: 2,580
Cumulative Timesteps: 21,557,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05495
Policy Entropy: 4.41791
Value Function Loss: 0.04316

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03435
Policy Update Magnitude: 0.72542
Value Function Update Magnitude: 0.33714

Collected Steps per Second: 14,754.60688
Overall Steps per Second: 6,735.20861

Timestep Collection Time: 3.39013
Timestep Consumption Time: 4.03652
PPO Batch Consumption Time: 0.47725
Total Iteration Time: 7.42664

Cumulative Model Updates: 2,586
Cumulative Timesteps: 21,607,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 21607096...
Checkpoint 21607096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03621
Policy Entropy: 4.42459
Value Function Loss: 0.03884

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03462
Policy Update Magnitude: 0.69278
Value Function Update Magnitude: 0.33087

Collected Steps per Second: 14,478.82329
Overall Steps per Second: 6,702.03985

Timestep Collection Time: 3.45498
Timestep Consumption Time: 4.00902
PPO Batch Consumption Time: 0.47763
Total Iteration Time: 7.46400

Cumulative Model Updates: 2,592
Cumulative Timesteps: 21,657,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00237
Policy Entropy: 4.42880
Value Function Loss: 0.03140

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02711
Policy Update Magnitude: 0.67280
Value Function Update Magnitude: 0.33486

Collected Steps per Second: 14,909.96195
Overall Steps per Second: 6,716.17507

Timestep Collection Time: 3.35480
Timestep Consumption Time: 4.09289
PPO Batch Consumption Time: 0.48895
Total Iteration Time: 7.44769

Cumulative Model Updates: 2,598
Cumulative Timesteps: 21,707,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 21707140...
Checkpoint 21707140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04154
Policy Entropy: 4.43054
Value Function Loss: 0.03289

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02311
Policy Update Magnitude: 0.67684
Value Function Update Magnitude: 0.32131

Collected Steps per Second: 14,543.60413
Overall Steps per Second: 6,654.13075

Timestep Collection Time: 3.43904
Timestep Consumption Time: 4.07750
PPO Batch Consumption Time: 0.49209
Total Iteration Time: 7.51653

Cumulative Model Updates: 2,604
Cumulative Timesteps: 21,757,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02462
Policy Entropy: 4.42689
Value Function Loss: 0.03904

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03021
Policy Update Magnitude: 0.69480
Value Function Update Magnitude: 0.34214

Collected Steps per Second: 14,618.27164
Overall Steps per Second: 6,769.60901

Timestep Collection Time: 3.42133
Timestep Consumption Time: 3.96668
PPO Batch Consumption Time: 0.47402
Total Iteration Time: 7.38802

Cumulative Model Updates: 2,610
Cumulative Timesteps: 21,807,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 21807170...
Checkpoint 21807170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01636
Policy Entropy: 4.42665
Value Function Loss: 0.05317

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03517
Policy Update Magnitude: 0.75645
Value Function Update Magnitude: 0.36829

Collected Steps per Second: 14,574.32159
Overall Steps per Second: 6,763.67745

Timestep Collection Time: 3.43110
Timestep Consumption Time: 3.96221
PPO Batch Consumption Time: 0.46751
Total Iteration Time: 7.39332

Cumulative Model Updates: 2,616
Cumulative Timesteps: 21,857,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00365
Policy Entropy: 4.42500
Value Function Loss: 0.06191

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03756
Policy Update Magnitude: 0.79537
Value Function Update Magnitude: 0.41239

Collected Steps per Second: 14,445.12831
Overall Steps per Second: 6,838.98262

Timestep Collection Time: 3.46317
Timestep Consumption Time: 3.85166
PPO Batch Consumption Time: 0.47539
Total Iteration Time: 7.31483

Cumulative Model Updates: 2,622
Cumulative Timesteps: 21,907,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 21907202...
Checkpoint 21907202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00683
Policy Entropy: 4.42834
Value Function Loss: 0.06302

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03731
Policy Update Magnitude: 0.83768
Value Function Update Magnitude: 0.42328

Collected Steps per Second: 14,128.38229
Overall Steps per Second: 6,820.54361

Timestep Collection Time: 3.53997
Timestep Consumption Time: 3.79288
PPO Batch Consumption Time: 0.47241
Total Iteration Time: 7.33285

Cumulative Model Updates: 2,628
Cumulative Timesteps: 21,957,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02402
Policy Entropy: 4.43016
Value Function Loss: 0.06214

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03755
Policy Update Magnitude: 0.83627
Value Function Update Magnitude: 0.40468

Collected Steps per Second: 14,549.45199
Overall Steps per Second: 6,757.26283

Timestep Collection Time: 3.43711
Timestep Consumption Time: 3.96352
PPO Batch Consumption Time: 0.49596
Total Iteration Time: 7.40063

Cumulative Model Updates: 2,634
Cumulative Timesteps: 22,007,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 22007224...
Checkpoint 22007224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07436
Policy Entropy: 4.42760
Value Function Loss: 0.05723

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04019
Policy Update Magnitude: 0.81322
Value Function Update Magnitude: 0.36163

Collected Steps per Second: 14,239.30856
Overall Steps per Second: 6,824.90711

Timestep Collection Time: 3.51351
Timestep Consumption Time: 3.81699
PPO Batch Consumption Time: 0.48256
Total Iteration Time: 7.33050

Cumulative Model Updates: 2,640
Cumulative Timesteps: 22,057,254

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02398
Policy Entropy: 4.42819
Value Function Loss: 0.04530

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04035
Policy Update Magnitude: 0.73648
Value Function Update Magnitude: 0.30014

Collected Steps per Second: 14,679.11885
Overall Steps per Second: 6,793.96091

Timestep Collection Time: 3.40647
Timestep Consumption Time: 3.95359
PPO Batch Consumption Time: 0.48380
Total Iteration Time: 7.36007

Cumulative Model Updates: 2,646
Cumulative Timesteps: 22,107,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 22107258...
Checkpoint 22107258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07877
Policy Entropy: 4.43468
Value Function Loss: 0.04697

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03476
Policy Update Magnitude: 0.70251
Value Function Update Magnitude: 0.28869

Collected Steps per Second: 14,498.52286
Overall Steps per Second: 6,750.87904

Timestep Collection Time: 3.45083
Timestep Consumption Time: 3.96035
PPO Batch Consumption Time: 0.49591
Total Iteration Time: 7.41118

Cumulative Model Updates: 2,652
Cumulative Timesteps: 22,157,290

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00053
Policy Entropy: 4.44054
Value Function Loss: 0.04747

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02961
Policy Update Magnitude: 0.69524
Value Function Update Magnitude: 0.28804

Collected Steps per Second: 14,876.40106
Overall Steps per Second: 6,930.87920

Timestep Collection Time: 3.36278
Timestep Consumption Time: 3.85507
PPO Batch Consumption Time: 0.48026
Total Iteration Time: 7.21784

Cumulative Model Updates: 2,658
Cumulative Timesteps: 22,207,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 22207316...
Checkpoint 22207316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08113
Policy Entropy: 4.43549
Value Function Loss: 0.03907

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03018
Policy Update Magnitude: 0.66413
Value Function Update Magnitude: 0.30740

Collected Steps per Second: 14,245.74804
Overall Steps per Second: 6,808.11293

Timestep Collection Time: 3.50982
Timestep Consumption Time: 3.83436
PPO Batch Consumption Time: 0.46640
Total Iteration Time: 7.34418

Cumulative Model Updates: 2,664
Cumulative Timesteps: 22,257,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05887
Policy Entropy: 4.43758
Value Function Loss: 0.03663

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.62833
Value Function Update Magnitude: 0.30695

Collected Steps per Second: 14,275.56353
Overall Steps per Second: 6,798.92169

Timestep Collection Time: 3.50347
Timestep Consumption Time: 3.85270
PPO Batch Consumption Time: 0.48552
Total Iteration Time: 7.35617

Cumulative Model Updates: 2,670
Cumulative Timesteps: 22,307,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 22307330...
Checkpoint 22307330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00804
Policy Entropy: 4.43738
Value Function Loss: 0.03696

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02306
Policy Update Magnitude: 0.67114
Value Function Update Magnitude: 0.38459

Collected Steps per Second: 14,562.22719
Overall Steps per Second: 6,848.49990

Timestep Collection Time: 3.43546
Timestep Consumption Time: 3.86949
PPO Batch Consumption Time: 0.47714
Total Iteration Time: 7.30496

Cumulative Model Updates: 2,676
Cumulative Timesteps: 22,357,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02832
Policy Entropy: 4.43774
Value Function Loss: 0.04360

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02706
Policy Update Magnitude: 0.70321
Value Function Update Magnitude: 0.39882

Collected Steps per Second: 14,505.16393
Overall Steps per Second: 6,888.57684

Timestep Collection Time: 3.44898
Timestep Consumption Time: 3.81348
PPO Batch Consumption Time: 0.48206
Total Iteration Time: 7.26246

Cumulative Model Updates: 2,682
Cumulative Timesteps: 22,407,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 22407386...
Checkpoint 22407386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00273
Policy Entropy: 4.43818
Value Function Loss: 0.04437

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.71279
Value Function Update Magnitude: 0.39354

Collected Steps per Second: 14,330.14168
Overall Steps per Second: 6,731.33625

Timestep Collection Time: 3.48929
Timestep Consumption Time: 3.93895
PPO Batch Consumption Time: 0.49116
Total Iteration Time: 7.42824

Cumulative Model Updates: 2,688
Cumulative Timesteps: 22,457,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02111
Policy Entropy: 4.43651
Value Function Loss: 0.04975

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.74420
Value Function Update Magnitude: 0.39510

Collected Steps per Second: 14,347.36817
Overall Steps per Second: 6,845.22657

Timestep Collection Time: 3.48566
Timestep Consumption Time: 3.82016
PPO Batch Consumption Time: 0.47710
Total Iteration Time: 7.30582

Cumulative Model Updates: 2,694
Cumulative Timesteps: 22,507,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 22507398...
Checkpoint 22507398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01626
Policy Entropy: 4.43885
Value Function Loss: 0.05152

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02919
Policy Update Magnitude: 0.76002
Value Function Update Magnitude: 0.36889

Collected Steps per Second: 14,628.44136
Overall Steps per Second: 6,810.51503

Timestep Collection Time: 3.41978
Timestep Consumption Time: 3.92563
PPO Batch Consumption Time: 0.49002
Total Iteration Time: 7.34541

Cumulative Model Updates: 2,700
Cumulative Timesteps: 22,557,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11847
Policy Entropy: 4.43807
Value Function Loss: 0.04654

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02946
Policy Update Magnitude: 0.72480
Value Function Update Magnitude: 0.36502

Collected Steps per Second: 14,638.42705
Overall Steps per Second: 6,807.66435

Timestep Collection Time: 3.41703
Timestep Consumption Time: 3.93057
PPO Batch Consumption Time: 0.48455
Total Iteration Time: 7.34760

Cumulative Model Updates: 2,706
Cumulative Timesteps: 22,607,444

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 22607444...
Checkpoint 22607444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00237
Policy Entropy: 4.43671
Value Function Loss: 0.03310

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02913
Policy Update Magnitude: 0.69990
Value Function Update Magnitude: 0.33086

Collected Steps per Second: 14,581.74048
Overall Steps per Second: 6,854.72882

Timestep Collection Time: 3.42977
Timestep Consumption Time: 3.86622
PPO Batch Consumption Time: 0.47409
Total Iteration Time: 7.29599

Cumulative Model Updates: 2,712
Cumulative Timesteps: 22,657,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02378
Policy Entropy: 4.43232
Value Function Loss: 0.04444

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.68437
Value Function Update Magnitude: 0.27425

Collected Steps per Second: 14,692.07104
Overall Steps per Second: 6,784.97533

Timestep Collection Time: 3.40429
Timestep Consumption Time: 3.96730
PPO Batch Consumption Time: 0.49296
Total Iteration Time: 7.37158

Cumulative Model Updates: 2,718
Cumulative Timesteps: 22,707,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 22707472...
Checkpoint 22707472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01716
Policy Entropy: 4.43028
Value Function Loss: 0.05587

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03142
Policy Update Magnitude: 0.74420
Value Function Update Magnitude: 0.32403

Collected Steps per Second: 14,602.16303
Overall Steps per Second: 6,898.05270

Timestep Collection Time: 3.42511
Timestep Consumption Time: 3.82534
PPO Batch Consumption Time: 0.47736
Total Iteration Time: 7.25045

Cumulative Model Updates: 2,724
Cumulative Timesteps: 22,757,486

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10001
Policy Entropy: 4.42835
Value Function Loss: 0.05879

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03766
Policy Update Magnitude: 0.77451
Value Function Update Magnitude: 0.33738

Collected Steps per Second: 14,593.44227
Overall Steps per Second: 6,761.69003

Timestep Collection Time: 3.42894
Timestep Consumption Time: 3.97158
PPO Batch Consumption Time: 0.49214
Total Iteration Time: 7.40052

Cumulative Model Updates: 2,730
Cumulative Timesteps: 22,807,526

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 22807526...
Checkpoint 22807526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01886
Policy Entropy: 4.42631
Value Function Loss: 0.04856

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03271
Policy Update Magnitude: 0.73332
Value Function Update Magnitude: 0.31824

Collected Steps per Second: 14,207.55589
Overall Steps per Second: 6,645.85150

Timestep Collection Time: 3.51996
Timestep Consumption Time: 4.00504
PPO Batch Consumption Time: 0.49584
Total Iteration Time: 7.52500

Cumulative Model Updates: 2,736
Cumulative Timesteps: 22,857,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00505
Policy Entropy: 4.42958
Value Function Loss: 0.05037

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03022
Policy Update Magnitude: 0.70407
Value Function Update Magnitude: 0.28520

Collected Steps per Second: 14,515.47346
Overall Steps per Second: 6,903.81390

Timestep Collection Time: 3.44639
Timestep Consumption Time: 3.79975
PPO Batch Consumption Time: 0.47258
Total Iteration Time: 7.24614

Cumulative Model Updates: 2,742
Cumulative Timesteps: 22,907,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 22907562...
Checkpoint 22907562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04310
Policy Entropy: 4.42793
Value Function Loss: 0.06338

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03383
Policy Update Magnitude: 0.75307
Value Function Update Magnitude: 0.28730

Collected Steps per Second: 14,403.64270
Overall Steps per Second: 6,748.44674

Timestep Collection Time: 3.47343
Timestep Consumption Time: 3.94013
PPO Batch Consumption Time: 0.48910
Total Iteration Time: 7.41356

Cumulative Model Updates: 2,748
Cumulative Timesteps: 22,957,592

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21177
Policy Entropy: 4.43040
Value Function Loss: 0.06244

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03574
Policy Update Magnitude: 0.77226
Value Function Update Magnitude: 0.34037

Collected Steps per Second: 14,599.68809
Overall Steps per Second: 6,958.77759

Timestep Collection Time: 3.42473
Timestep Consumption Time: 3.76044
PPO Batch Consumption Time: 0.46823
Total Iteration Time: 7.18517

Cumulative Model Updates: 2,754
Cumulative Timesteps: 23,007,592

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 23007592...
Checkpoint 23007592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16560
Policy Entropy: 4.42595
Value Function Loss: 0.05876

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03688
Policy Update Magnitude: 0.73560
Value Function Update Magnitude: 0.32901

Collected Steps per Second: 14,154.55628
Overall Steps per Second: 6,749.57107

Timestep Collection Time: 3.53582
Timestep Consumption Time: 3.87917
PPO Batch Consumption Time: 0.47198
Total Iteration Time: 7.41499

Cumulative Model Updates: 2,760
Cumulative Timesteps: 23,057,640

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13247
Policy Entropy: 4.42759
Value Function Loss: 0.05254

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03319
Policy Update Magnitude: 0.71777
Value Function Update Magnitude: 0.25416

Collected Steps per Second: 14,345.41609
Overall Steps per Second: 6,749.92884

Timestep Collection Time: 3.48599
Timestep Consumption Time: 3.92268
PPO Batch Consumption Time: 0.48965
Total Iteration Time: 7.40867

Cumulative Model Updates: 2,766
Cumulative Timesteps: 23,107,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 23107648...
Checkpoint 23107648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02852
Policy Entropy: 4.42535
Value Function Loss: 0.04521

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03504
Policy Update Magnitude: 0.70151
Value Function Update Magnitude: 0.25588

Collected Steps per Second: 14,732.78032
Overall Steps per Second: 6,870.46179

Timestep Collection Time: 3.39420
Timestep Consumption Time: 3.88420
PPO Batch Consumption Time: 0.48124
Total Iteration Time: 7.27840

Cumulative Model Updates: 2,772
Cumulative Timesteps: 23,157,654

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16470
Policy Entropy: 4.42844
Value Function Loss: 0.05757

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02899
Policy Update Magnitude: 0.72311
Value Function Update Magnitude: 0.32650

Collected Steps per Second: 14,466.56326
Overall Steps per Second: 6,827.80686

Timestep Collection Time: 3.45790
Timestep Consumption Time: 3.86861
PPO Batch Consumption Time: 0.47224
Total Iteration Time: 7.32651

Cumulative Model Updates: 2,778
Cumulative Timesteps: 23,207,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 23207678...
Checkpoint 23207678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03197
Policy Entropy: 4.42614
Value Function Loss: 0.04778

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03555
Policy Update Magnitude: 0.76077
Value Function Update Magnitude: 0.35255

Collected Steps per Second: 14,749.21860
Overall Steps per Second: 6,894.13422

Timestep Collection Time: 3.39028
Timestep Consumption Time: 3.86284
PPO Batch Consumption Time: 0.47516
Total Iteration Time: 7.25312

Cumulative Model Updates: 2,784
Cumulative Timesteps: 23,257,682

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06445
Policy Entropy: 4.42245
Value Function Loss: 0.07551

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.03909
Policy Update Magnitude: 0.81010
Value Function Update Magnitude: 0.38108

Collected Steps per Second: 14,483.34440
Overall Steps per Second: 6,664.67462

Timestep Collection Time: 3.45252
Timestep Consumption Time: 4.05032
PPO Batch Consumption Time: 0.50130
Total Iteration Time: 7.50284

Cumulative Model Updates: 2,790
Cumulative Timesteps: 23,307,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 23307686...
Checkpoint 23307686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04348
Policy Entropy: 4.41854
Value Function Loss: 0.06020

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.03995
Policy Update Magnitude: 0.84263
Value Function Update Magnitude: 0.38903

Collected Steps per Second: 14,633.59131
Overall Steps per Second: 6,842.85649

Timestep Collection Time: 3.41707
Timestep Consumption Time: 3.89041
PPO Batch Consumption Time: 0.47622
Total Iteration Time: 7.30747

Cumulative Model Updates: 2,796
Cumulative Timesteps: 23,357,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00703
Policy Entropy: 4.41863
Value Function Loss: 0.06896

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04032
Policy Update Magnitude: 0.82128
Value Function Update Magnitude: 0.36681

Collected Steps per Second: 14,194.85582
Overall Steps per Second: 6,817.86732

Timestep Collection Time: 3.52268
Timestep Consumption Time: 3.81157
PPO Batch Consumption Time: 0.46463
Total Iteration Time: 7.33426

Cumulative Model Updates: 2,802
Cumulative Timesteps: 23,407,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 23407694...
Checkpoint 23407694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07729
Policy Entropy: 4.41994
Value Function Loss: 0.06181

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04006
Policy Update Magnitude: 0.81217
Value Function Update Magnitude: 0.34337

Collected Steps per Second: 14,108.46120
Overall Steps per Second: 6,808.54832

Timestep Collection Time: 3.54468
Timestep Consumption Time: 3.80050
PPO Batch Consumption Time: 0.47988
Total Iteration Time: 7.34518

Cumulative Model Updates: 2,808
Cumulative Timesteps: 23,457,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14004
Policy Entropy: 4.41864
Value Function Loss: 0.07921

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04736
Policy Update Magnitude: 0.81850
Value Function Update Magnitude: 0.34887

Collected Steps per Second: 14,759.47122
Overall Steps per Second: 6,876.27010

Timestep Collection Time: 3.38901
Timestep Consumption Time: 3.88528
PPO Batch Consumption Time: 0.47867
Total Iteration Time: 7.27429

Cumulative Model Updates: 2,814
Cumulative Timesteps: 23,507,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 23507724...
Checkpoint 23507724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00711
Policy Entropy: 4.41635
Value Function Loss: 0.07608

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04297
Policy Update Magnitude: 0.82275
Value Function Update Magnitude: 0.36824

Collected Steps per Second: 14,147.23337
Overall Steps per Second: 6,684.56284

Timestep Collection Time: 3.53440
Timestep Consumption Time: 3.94582
PPO Batch Consumption Time: 0.49022
Total Iteration Time: 7.48022

Cumulative Model Updates: 2,820
Cumulative Timesteps: 23,557,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05153
Policy Entropy: 4.41940
Value Function Loss: 0.07384

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03960
Policy Update Magnitude: 0.83766
Value Function Update Magnitude: 0.35849

Collected Steps per Second: 14,241.61668
Overall Steps per Second: 6,838.73542

Timestep Collection Time: 3.51182
Timestep Consumption Time: 3.80152
PPO Batch Consumption Time: 0.47102
Total Iteration Time: 7.31334

Cumulative Model Updates: 2,826
Cumulative Timesteps: 23,607,740

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 23607740...
Checkpoint 23607740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15880
Policy Entropy: 4.41744
Value Function Loss: 0.05668

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04121
Policy Update Magnitude: 0.79634
Value Function Update Magnitude: 0.34829

Collected Steps per Second: 14,217.51069
Overall Steps per Second: 6,726.88029

Timestep Collection Time: 3.51749
Timestep Consumption Time: 3.91686
PPO Batch Consumption Time: 0.48030
Total Iteration Time: 7.43435

Cumulative Model Updates: 2,832
Cumulative Timesteps: 23,657,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07344
Policy Entropy: 4.41752
Value Function Loss: 0.05719

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03457
Policy Update Magnitude: 0.75774
Value Function Update Magnitude: 0.32694

Collected Steps per Second: 14,090.49775
Overall Steps per Second: 6,598.04955

Timestep Collection Time: 3.55034
Timestep Consumption Time: 4.03160
PPO Batch Consumption Time: 0.51230
Total Iteration Time: 7.58194

Cumulative Model Updates: 2,838
Cumulative Timesteps: 23,707,776

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 23707776...
Checkpoint 23707776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14691
Policy Entropy: 4.41700
Value Function Loss: 0.04043

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03371
Policy Update Magnitude: 0.72848
Value Function Update Magnitude: 0.35387

Collected Steps per Second: 13,876.40101
Overall Steps per Second: 6,587.39745

Timestep Collection Time: 3.60338
Timestep Consumption Time: 3.98717
PPO Batch Consumption Time: 0.49229
Total Iteration Time: 7.59055

Cumulative Model Updates: 2,844
Cumulative Timesteps: 23,757,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04050
Policy Entropy: 4.41525
Value Function Loss: 0.05339

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03398
Policy Update Magnitude: 0.71597
Value Function Update Magnitude: 0.32148

Collected Steps per Second: 14,079.97765
Overall Steps per Second: 6,759.76028

Timestep Collection Time: 3.55114
Timestep Consumption Time: 3.84557
PPO Batch Consumption Time: 0.46589
Total Iteration Time: 7.39671

Cumulative Model Updates: 2,850
Cumulative Timesteps: 23,807,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 23807778...
Checkpoint 23807778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05447
Policy Entropy: 4.41915
Value Function Loss: 0.05146

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03627
Policy Update Magnitude: 0.73401
Value Function Update Magnitude: 0.32137

Collected Steps per Second: 14,140.31840
Overall Steps per Second: 6,716.16126

Timestep Collection Time: 3.53896
Timestep Consumption Time: 3.91202
PPO Batch Consumption Time: 0.48149
Total Iteration Time: 7.45098

Cumulative Model Updates: 2,856
Cumulative Timesteps: 23,857,820

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05932
Policy Entropy: 4.42306
Value Function Loss: 0.05330

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03551
Policy Update Magnitude: 0.72988
Value Function Update Magnitude: 0.30988

Collected Steps per Second: 13,960.37859
Overall Steps per Second: 6,728.16418

Timestep Collection Time: 3.58486
Timestep Consumption Time: 3.85342
PPO Batch Consumption Time: 0.47275
Total Iteration Time: 7.43828

Cumulative Model Updates: 2,862
Cumulative Timesteps: 23,907,866

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 23907866...
Checkpoint 23907866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04678
Policy Entropy: 4.42581
Value Function Loss: 0.05618

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02987
Policy Update Magnitude: 0.73674
Value Function Update Magnitude: 0.29644

Collected Steps per Second: 14,340.53855
Overall Steps per Second: 6,880.13295

Timestep Collection Time: 3.48704
Timestep Consumption Time: 3.78114
PPO Batch Consumption Time: 0.48073
Total Iteration Time: 7.26817

Cumulative Model Updates: 2,868
Cumulative Timesteps: 23,957,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03016
Policy Entropy: 4.42863
Value Function Loss: 0.06112

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02879
Policy Update Magnitude: 0.76197
Value Function Update Magnitude: 0.30663

Collected Steps per Second: 14,512.41732
Overall Steps per Second: 6,821.04539

Timestep Collection Time: 3.44533
Timestep Consumption Time: 3.88493
PPO Batch Consumption Time: 0.47386
Total Iteration Time: 7.33025

Cumulative Model Updates: 2,874
Cumulative Timesteps: 24,007,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 24007872...
Checkpoint 24007872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00624
Policy Entropy: 4.42270
Value Function Loss: 0.05716

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03136
Policy Update Magnitude: 0.77145
Value Function Update Magnitude: 0.31422

Collected Steps per Second: 14,265.97321
Overall Steps per Second: 6,810.92822

Timestep Collection Time: 3.50610
Timestep Consumption Time: 3.83768
PPO Batch Consumption Time: 0.48276
Total Iteration Time: 7.34379

Cumulative Model Updates: 2,880
Cumulative Timesteps: 24,057,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00822
Policy Entropy: 4.42563
Value Function Loss: 0.04631

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.70919
Value Function Update Magnitude: 0.30738

Collected Steps per Second: 14,709.59531
Overall Steps per Second: 6,898.34819

Timestep Collection Time: 3.40105
Timestep Consumption Time: 3.85113
PPO Batch Consumption Time: 0.47091
Total Iteration Time: 7.25217

Cumulative Model Updates: 2,886
Cumulative Timesteps: 24,107,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 24107918...
Checkpoint 24107918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04407
Policy Entropy: 4.42741
Value Function Loss: 0.04585

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02714
Policy Update Magnitude: 0.71134
Value Function Update Magnitude: 0.30184

Collected Steps per Second: 14,372.72473
Overall Steps per Second: 6,727.10433

Timestep Collection Time: 3.47909
Timestep Consumption Time: 3.95412
PPO Batch Consumption Time: 0.50405
Total Iteration Time: 7.43321

Cumulative Model Updates: 2,892
Cumulative Timesteps: 24,157,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00290
Policy Entropy: 4.42083
Value Function Loss: 0.06414

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03567
Policy Update Magnitude: 0.76500
Value Function Update Magnitude: 0.33937

Collected Steps per Second: 14,582.40379
Overall Steps per Second: 6,775.19612

Timestep Collection Time: 3.43044
Timestep Consumption Time: 3.95297
PPO Batch Consumption Time: 0.48839
Total Iteration Time: 7.38340

Cumulative Model Updates: 2,898
Cumulative Timesteps: 24,207,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 24207946...
Checkpoint 24207946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02782
Policy Entropy: 4.42015
Value Function Loss: 0.06102

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03543
Policy Update Magnitude: 0.78109
Value Function Update Magnitude: 0.39415

Collected Steps per Second: 14,273.04458
Overall Steps per Second: 6,713.65969

Timestep Collection Time: 3.50465
Timestep Consumption Time: 3.94613
PPO Batch Consumption Time: 0.48625
Total Iteration Time: 7.45078

Cumulative Model Updates: 2,904
Cumulative Timesteps: 24,257,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12685
Policy Entropy: 4.41661
Value Function Loss: 0.06583

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03436
Policy Update Magnitude: 0.77725
Value Function Update Magnitude: 0.40593

Collected Steps per Second: 14,761.87322
Overall Steps per Second: 6,861.50398

Timestep Collection Time: 3.38805
Timestep Consumption Time: 3.90102
PPO Batch Consumption Time: 0.48380
Total Iteration Time: 7.28907

Cumulative Model Updates: 2,910
Cumulative Timesteps: 24,307,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 24307982...
Checkpoint 24307982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01233
Policy Entropy: 4.42008
Value Function Loss: 0.07219

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.03838
Policy Update Magnitude: 0.79908
Value Function Update Magnitude: 0.36928

Collected Steps per Second: 14,514.71488
Overall Steps per Second: 6,896.95312

Timestep Collection Time: 3.44685
Timestep Consumption Time: 3.80708
PPO Batch Consumption Time: 0.46447
Total Iteration Time: 7.25393

Cumulative Model Updates: 2,916
Cumulative Timesteps: 24,358,012

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08451
Policy Entropy: 4.41448
Value Function Loss: 0.08622

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04216
Policy Update Magnitude: 0.87448
Value Function Update Magnitude: 0.40356

Collected Steps per Second: 14,672.58900
Overall Steps per Second: 6,947.50236

Timestep Collection Time: 3.40949
Timestep Consumption Time: 3.79109
PPO Batch Consumption Time: 0.46878
Total Iteration Time: 7.20057

Cumulative Model Updates: 2,922
Cumulative Timesteps: 24,408,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 24408038...
Checkpoint 24408038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12010
Policy Entropy: 4.41394
Value Function Loss: 0.08179

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04082
Policy Update Magnitude: 0.89496
Value Function Update Magnitude: 0.41148

Collected Steps per Second: 14,196.56110
Overall Steps per Second: 6,779.49849

Timestep Collection Time: 3.52198
Timestep Consumption Time: 3.85320
PPO Batch Consumption Time: 0.47104
Total Iteration Time: 7.37518

Cumulative Model Updates: 2,928
Cumulative Timesteps: 24,458,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02666
Policy Entropy: 4.41637
Value Function Loss: 0.08395

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.03745
Policy Update Magnitude: 0.89891
Value Function Update Magnitude: 0.35212

Collected Steps per Second: 14,937.40457
Overall Steps per Second: 6,886.37578

Timestep Collection Time: 3.34931
Timestep Consumption Time: 3.91576
PPO Batch Consumption Time: 0.47847
Total Iteration Time: 7.26507

Cumulative Model Updates: 2,934
Cumulative Timesteps: 24,508,068

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 24508068...
Checkpoint 24508068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04882
Policy Entropy: 4.41574
Value Function Loss: 0.06834

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.03712
Policy Update Magnitude: 0.87579
Value Function Update Magnitude: 0.34570

Collected Steps per Second: 14,334.35238
Overall Steps per Second: 6,762.10649

Timestep Collection Time: 3.48980
Timestep Consumption Time: 3.90790
PPO Batch Consumption Time: 0.47446
Total Iteration Time: 7.39769

Cumulative Model Updates: 2,940
Cumulative Timesteps: 24,558,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06597
Policy Entropy: 4.41780
Value Function Loss: 0.06968

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03973
Policy Update Magnitude: 0.81475
Value Function Update Magnitude: 0.37268

Collected Steps per Second: 14,678.60986
Overall Steps per Second: 6,921.09836

Timestep Collection Time: 3.40809
Timestep Consumption Time: 3.81996
PPO Batch Consumption Time: 0.47421
Total Iteration Time: 7.22804

Cumulative Model Updates: 2,946
Cumulative Timesteps: 24,608,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 24608118...
Checkpoint 24608118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12500
Policy Entropy: 4.41948
Value Function Loss: 0.06140

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03823
Policy Update Magnitude: 0.77527
Value Function Update Magnitude: 0.38363

Collected Steps per Second: 14,125.46448
Overall Steps per Second: 6,750.10434

Timestep Collection Time: 3.53985
Timestep Consumption Time: 3.86774
PPO Batch Consumption Time: 0.47508
Total Iteration Time: 7.40759

Cumulative Model Updates: 2,952
Cumulative Timesteps: 24,658,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03646
Policy Entropy: 4.41885
Value Function Loss: 0.06195

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.03914
Policy Update Magnitude: 0.76694
Value Function Update Magnitude: 0.34385

Collected Steps per Second: 14,478.24406
Overall Steps per Second: 6,944.29706

Timestep Collection Time: 3.45539
Timestep Consumption Time: 3.74879
PPO Batch Consumption Time: 0.47382
Total Iteration Time: 7.20418

Cumulative Model Updates: 2,958
Cumulative Timesteps: 24,708,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 24708148...
Checkpoint 24708148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06053
Policy Entropy: 4.42150
Value Function Loss: 0.04714

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03309
Policy Update Magnitude: 0.71938
Value Function Update Magnitude: 0.31050

Collected Steps per Second: 14,343.71196
Overall Steps per Second: 6,834.58346

Timestep Collection Time: 3.48780
Timestep Consumption Time: 3.83203
PPO Batch Consumption Time: 0.46462
Total Iteration Time: 7.31983

Cumulative Model Updates: 2,964
Cumulative Timesteps: 24,758,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02052
Policy Entropy: 4.42257
Value Function Loss: 0.05977

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03123
Policy Update Magnitude: 0.73936
Value Function Update Magnitude: 0.29602

Collected Steps per Second: 14,460.07962
Overall Steps per Second: 6,907.22856

Timestep Collection Time: 3.45987
Timestep Consumption Time: 3.78327
PPO Batch Consumption Time: 0.46715
Total Iteration Time: 7.24314

Cumulative Model Updates: 2,970
Cumulative Timesteps: 24,808,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 24808206...
Checkpoint 24808206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01929
Policy Entropy: 4.41514
Value Function Loss: 0.04905

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04318
Policy Update Magnitude: 0.72802
Value Function Update Magnitude: 0.28752

Collected Steps per Second: 14,227.20917
Overall Steps per Second: 6,876.57000

Timestep Collection Time: 3.51495
Timestep Consumption Time: 3.75728
PPO Batch Consumption Time: 0.47546
Total Iteration Time: 7.27223

Cumulative Model Updates: 2,976
Cumulative Timesteps: 24,858,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03490
Policy Entropy: 4.41599
Value Function Loss: 0.05528

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.03901
Policy Update Magnitude: 0.68289
Value Function Update Magnitude: 0.30984

Collected Steps per Second: 14,485.79258
Overall Steps per Second: 6,801.67169

Timestep Collection Time: 3.45442
Timestep Consumption Time: 3.90260
PPO Batch Consumption Time: 0.47745
Total Iteration Time: 7.35701

Cumulative Model Updates: 2,982
Cumulative Timesteps: 24,908,254

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 24908254...
Checkpoint 24908254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03973
Policy Entropy: 4.42591
Value Function Loss: 0.04216

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03826
Policy Update Magnitude: 0.68571
Value Function Update Magnitude: 0.31359

Collected Steps per Second: 14,342.70713
Overall Steps per Second: 6,885.83813

Timestep Collection Time: 3.48693
Timestep Consumption Time: 3.77609
PPO Batch Consumption Time: 0.47594
Total Iteration Time: 7.26302

Cumulative Model Updates: 2,988
Cumulative Timesteps: 24,958,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06078
Policy Entropy: 4.41990
Value Function Loss: 0.05787

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03572
Policy Update Magnitude: 0.72978
Value Function Update Magnitude: 0.34426

Collected Steps per Second: 14,488.09891
Overall Steps per Second: 6,693.12148

Timestep Collection Time: 3.45138
Timestep Consumption Time: 4.01957
PPO Batch Consumption Time: 0.49615
Total Iteration Time: 7.47095

Cumulative Model Updates: 2,994
Cumulative Timesteps: 25,008,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 25008270...
Checkpoint 25008270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08655
Policy Entropy: 4.41649
Value Function Loss: 0.06643

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.03836
Policy Update Magnitude: 0.77069
Value Function Update Magnitude: 0.34328

Collected Steps per Second: 14,180.81141
Overall Steps per Second: 6,827.04677

Timestep Collection Time: 3.52815
Timestep Consumption Time: 3.80035
PPO Batch Consumption Time: 0.47486
Total Iteration Time: 7.32850

Cumulative Model Updates: 3,000
Cumulative Timesteps: 25,058,302

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03141
Policy Entropy: 4.41578
Value Function Loss: 0.07270

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04173
Policy Update Magnitude: 0.81387
Value Function Update Magnitude: 0.37068

Collected Steps per Second: 14,789.55506
Overall Steps per Second: 6,902.13578

Timestep Collection Time: 3.38158
Timestep Consumption Time: 3.86430
PPO Batch Consumption Time: 0.47914
Total Iteration Time: 7.24587

Cumulative Model Updates: 3,006
Cumulative Timesteps: 25,108,314

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 25108314...
Checkpoint 25108314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18904
Policy Entropy: 4.42303
Value Function Loss: 0.06427

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03533
Policy Update Magnitude: 0.82546
Value Function Update Magnitude: 0.37701

Collected Steps per Second: 14,543.71296
Overall Steps per Second: 6,811.04434

Timestep Collection Time: 3.43846
Timestep Consumption Time: 3.90373
PPO Batch Consumption Time: 0.47691
Total Iteration Time: 7.34219

Cumulative Model Updates: 3,012
Cumulative Timesteps: 25,158,322

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08188
Policy Entropy: 4.42289
Value Function Loss: 0.05382

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03375
Policy Update Magnitude: 0.78045
Value Function Update Magnitude: 0.36134

Collected Steps per Second: 14,320.63454
Overall Steps per Second: 6,776.95997

Timestep Collection Time: 3.49147
Timestep Consumption Time: 3.88647
PPO Batch Consumption Time: 0.48904
Total Iteration Time: 7.37794

Cumulative Model Updates: 3,018
Cumulative Timesteps: 25,208,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 25208322...
Checkpoint 25208322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06515
Policy Entropy: 4.42322
Value Function Loss: 0.05413

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03262
Policy Update Magnitude: 0.73264
Value Function Update Magnitude: 0.33240

Collected Steps per Second: 14,190.33363
Overall Steps per Second: 6,728.69149

Timestep Collection Time: 3.52479
Timestep Consumption Time: 3.90875
PPO Batch Consumption Time: 0.47721
Total Iteration Time: 7.43354

Cumulative Model Updates: 3,024
Cumulative Timesteps: 25,258,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02581
Policy Entropy: 4.42232
Value Function Loss: 0.04811

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03248
Policy Update Magnitude: 0.72039
Value Function Update Magnitude: 0.33495

Collected Steps per Second: 14,401.81389
Overall Steps per Second: 6,912.69354

Timestep Collection Time: 3.47276
Timestep Consumption Time: 3.76234
PPO Batch Consumption Time: 0.47863
Total Iteration Time: 7.23510

Cumulative Model Updates: 3,030
Cumulative Timesteps: 25,308,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 25308354...
Checkpoint 25308354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00548
Policy Entropy: 4.42171
Value Function Loss: 0.05673

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03058
Policy Update Magnitude: 0.72515
Value Function Update Magnitude: 0.33799

Collected Steps per Second: 14,634.29118
Overall Steps per Second: 6,819.95260

Timestep Collection Time: 3.41841
Timestep Consumption Time: 3.91683
PPO Batch Consumption Time: 0.48815
Total Iteration Time: 7.33524

Cumulative Model Updates: 3,036
Cumulative Timesteps: 25,358,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07295
Policy Entropy: 4.42261
Value Function Loss: 0.05427

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03516
Policy Update Magnitude: 0.76378
Value Function Update Magnitude: 0.36104

Collected Steps per Second: 14,466.45614
Overall Steps per Second: 6,763.68193

Timestep Collection Time: 3.45710
Timestep Consumption Time: 3.93710
PPO Batch Consumption Time: 0.48712
Total Iteration Time: 7.39420

Cumulative Model Updates: 3,042
Cumulative Timesteps: 25,408,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 25408392...
Checkpoint 25408392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11747
Policy Entropy: 4.41341
Value Function Loss: 0.06763

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04055
Policy Update Magnitude: 0.79382
Value Function Update Magnitude: 0.33818

Collected Steps per Second: 14,437.22221
Overall Steps per Second: 6,890.96519

Timestep Collection Time: 3.46327
Timestep Consumption Time: 3.79261
PPO Batch Consumption Time: 0.47021
Total Iteration Time: 7.25588

Cumulative Model Updates: 3,048
Cumulative Timesteps: 25,458,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01142
Policy Entropy: 4.41455
Value Function Loss: 0.06628

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03785
Policy Update Magnitude: 0.80357
Value Function Update Magnitude: 0.34984

Collected Steps per Second: 14,430.23047
Overall Steps per Second: 6,808.88401

Timestep Collection Time: 3.46661
Timestep Consumption Time: 3.88026
PPO Batch Consumption Time: 0.47141
Total Iteration Time: 7.34687

Cumulative Model Updates: 3,054
Cumulative Timesteps: 25,508,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 25508416...
Checkpoint 25508416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06186
Policy Entropy: 4.41106
Value Function Loss: 0.07443

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03623
Policy Update Magnitude: 0.83213
Value Function Update Magnitude: 0.36363

Collected Steps per Second: 14,421.56447
Overall Steps per Second: 6,926.36554

Timestep Collection Time: 3.46800
Timestep Consumption Time: 3.75281
PPO Batch Consumption Time: 0.46695
Total Iteration Time: 7.22081

Cumulative Model Updates: 3,060
Cumulative Timesteps: 25,558,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06426
Policy Entropy: 4.41387
Value Function Loss: 0.06984

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03860
Policy Update Magnitude: 0.83288
Value Function Update Magnitude: 0.38842

Collected Steps per Second: 14,432.15878
Overall Steps per Second: 6,753.71773

Timestep Collection Time: 3.46559
Timestep Consumption Time: 3.94011
PPO Batch Consumption Time: 0.49050
Total Iteration Time: 7.40570

Cumulative Model Updates: 3,066
Cumulative Timesteps: 25,608,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 25608446...
Checkpoint 25608446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03331
Policy Entropy: 4.40936
Value Function Loss: 0.06401

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03897
Policy Update Magnitude: 0.79322
Value Function Update Magnitude: 0.33158

Collected Steps per Second: 14,348.32250
Overall Steps per Second: 6,771.44460

Timestep Collection Time: 3.48626
Timestep Consumption Time: 3.90094
PPO Batch Consumption Time: 0.48458
Total Iteration Time: 7.38720

Cumulative Model Updates: 3,072
Cumulative Timesteps: 25,658,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13457
Policy Entropy: 4.40699
Value Function Loss: 0.07906

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03841
Policy Update Magnitude: 0.81409
Value Function Update Magnitude: 0.29208

Collected Steps per Second: 14,844.34674
Overall Steps per Second: 6,865.54064

Timestep Collection Time: 3.36896
Timestep Consumption Time: 3.91524
PPO Batch Consumption Time: 0.48100
Total Iteration Time: 7.28420

Cumulative Model Updates: 3,078
Cumulative Timesteps: 25,708,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 25708478...
Checkpoint 25708478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04619
Policy Entropy: 4.40693
Value Function Loss: 0.07345

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04177
Policy Update Magnitude: 0.86832
Value Function Update Magnitude: 0.36730

Collected Steps per Second: 14,441.98795
Overall Steps per Second: 6,842.10834

Timestep Collection Time: 3.46351
Timestep Consumption Time: 3.84710
PPO Batch Consumption Time: 0.47005
Total Iteration Time: 7.31061

Cumulative Model Updates: 3,084
Cumulative Timesteps: 25,758,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05832
Policy Entropy: 4.40752
Value Function Loss: 0.07346

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04659
Policy Update Magnitude: 0.84456
Value Function Update Magnitude: 0.39038

Collected Steps per Second: 14,542.33433
Overall Steps per Second: 6,897.69271

Timestep Collection Time: 3.43893
Timestep Consumption Time: 3.81133
PPO Batch Consumption Time: 0.47396
Total Iteration Time: 7.25025

Cumulative Model Updates: 3,090
Cumulative Timesteps: 25,808,508

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 25808508...
Checkpoint 25808508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08988
Policy Entropy: 4.40274
Value Function Loss: 0.07132

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04452
Policy Update Magnitude: 0.82834
Value Function Update Magnitude: 0.43237

Collected Steps per Second: 14,217.85145
Overall Steps per Second: 6,590.28649

Timestep Collection Time: 3.51783
Timestep Consumption Time: 4.07152
PPO Batch Consumption Time: 0.49906
Total Iteration Time: 7.58935

Cumulative Model Updates: 3,096
Cumulative Timesteps: 25,858,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01992
Policy Entropy: 4.39964
Value Function Loss: 0.07143

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05192
Policy Update Magnitude: 0.82785
Value Function Update Magnitude: 0.45317

Collected Steps per Second: 14,394.27829
Overall Steps per Second: 6,848.41099

Timestep Collection Time: 3.47541
Timestep Consumption Time: 3.82935
PPO Batch Consumption Time: 0.48365
Total Iteration Time: 7.30476

Cumulative Model Updates: 3,102
Cumulative Timesteps: 25,908,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 25908550...
Checkpoint 25908550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11601
Policy Entropy: 4.39515
Value Function Loss: 0.06994

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.04618
Policy Update Magnitude: 0.83710
Value Function Update Magnitude: 0.44499

Collected Steps per Second: 14,370.83225
Overall Steps per Second: 6,791.65588

Timestep Collection Time: 3.47983
Timestep Consumption Time: 3.88333
PPO Batch Consumption Time: 0.47698
Total Iteration Time: 7.36315

Cumulative Model Updates: 3,108
Cumulative Timesteps: 25,958,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09496
Policy Entropy: 4.39891
Value Function Loss: 0.05138

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.04884
Policy Update Magnitude: 0.80278
Value Function Update Magnitude: 0.40476

Collected Steps per Second: 14,340.94504
Overall Steps per Second: 6,785.88485

Timestep Collection Time: 3.48680
Timestep Consumption Time: 3.88203
PPO Batch Consumption Time: 0.47655
Total Iteration Time: 7.36883

Cumulative Model Updates: 3,114
Cumulative Timesteps: 26,008,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 26008562...
Checkpoint 26008562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05399
Policy Entropy: 4.39155
Value Function Loss: 0.06255

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.04758
Policy Update Magnitude: 0.82110
Value Function Update Magnitude: 0.40038

Collected Steps per Second: 14,283.82134
Overall Steps per Second: 6,810.76398

Timestep Collection Time: 3.50172
Timestep Consumption Time: 3.84224
PPO Batch Consumption Time: 0.48457
Total Iteration Time: 7.34396

Cumulative Model Updates: 3,120
Cumulative Timesteps: 26,058,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03807
Policy Entropy: 4.38802
Value Function Loss: 0.06266

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04823
Policy Update Magnitude: 0.85282
Value Function Update Magnitude: 0.46743

Collected Steps per Second: 14,427.25532
Overall Steps per Second: 6,825.00489

Timestep Collection Time: 3.46746
Timestep Consumption Time: 3.86235
PPO Batch Consumption Time: 0.47616
Total Iteration Time: 7.32981

Cumulative Model Updates: 3,126
Cumulative Timesteps: 26,108,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 26108606...
Checkpoint 26108606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06561
Policy Entropy: 4.38858
Value Function Loss: 0.06669

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05279
Policy Update Magnitude: 0.82486
Value Function Update Magnitude: 0.44591

Collected Steps per Second: 14,508.48189
Overall Steps per Second: 6,957.18309

Timestep Collection Time: 3.44805
Timestep Consumption Time: 3.74250
PPO Batch Consumption Time: 0.47468
Total Iteration Time: 7.19055

Cumulative Model Updates: 3,132
Cumulative Timesteps: 26,158,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00133
Policy Entropy: 4.39973
Value Function Loss: 0.06456

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.04796
Policy Update Magnitude: 0.83149
Value Function Update Magnitude: 0.42836

Collected Steps per Second: 14,506.27221
Overall Steps per Second: 6,834.98583

Timestep Collection Time: 3.44775
Timestep Consumption Time: 3.86960
PPO Batch Consumption Time: 0.47123
Total Iteration Time: 7.31735

Cumulative Model Updates: 3,138
Cumulative Timesteps: 26,208,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 26208646...
Checkpoint 26208646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01212
Policy Entropy: 4.40209
Value Function Loss: 0.05744

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04191
Policy Update Magnitude: 0.82505
Value Function Update Magnitude: 0.43662

Collected Steps per Second: 14,371.25047
Overall Steps per Second: 6,839.50007

Timestep Collection Time: 3.48112
Timestep Consumption Time: 3.83345
PPO Batch Consumption Time: 0.47730
Total Iteration Time: 7.31457

Cumulative Model Updates: 3,144
Cumulative Timesteps: 26,258,674

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03948
Policy Entropy: 4.40390
Value Function Loss: 0.05859

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04399
Policy Update Magnitude: 0.80374
Value Function Update Magnitude: 0.39297

Collected Steps per Second: 14,595.96431
Overall Steps per Second: 6,855.36347

Timestep Collection Time: 3.42656
Timestep Consumption Time: 3.86904
PPO Batch Consumption Time: 0.48089
Total Iteration Time: 7.29560

Cumulative Model Updates: 3,150
Cumulative Timesteps: 26,308,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 26308688...
Checkpoint 26308688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02274
Policy Entropy: 4.39802
Value Function Loss: 0.04772

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04249
Policy Update Magnitude: 0.77755
Value Function Update Magnitude: 0.35767

Collected Steps per Second: 14,252.69800
Overall Steps per Second: 6,630.61433

Timestep Collection Time: 3.50853
Timestep Consumption Time: 4.03316
PPO Batch Consumption Time: 0.50156
Total Iteration Time: 7.54168

Cumulative Model Updates: 3,156
Cumulative Timesteps: 26,358,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02382
Policy Entropy: 4.39594
Value Function Loss: 0.07129

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03991
Policy Update Magnitude: 0.78680
Value Function Update Magnitude: 0.33476

Collected Steps per Second: 14,700.50758
Overall Steps per Second: 6,838.02707

Timestep Collection Time: 3.40206
Timestep Consumption Time: 3.91175
PPO Batch Consumption Time: 0.47527
Total Iteration Time: 7.31381

Cumulative Model Updates: 3,162
Cumulative Timesteps: 26,408,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 26408706...
Checkpoint 26408706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19167
Policy Entropy: 4.39421
Value Function Loss: 0.07491

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04436
Policy Update Magnitude: 0.85198
Value Function Update Magnitude: 0.38162

Collected Steps per Second: 14,225.09244
Overall Steps per Second: 6,772.05596

Timestep Collection Time: 3.51688
Timestep Consumption Time: 3.87053
PPO Batch Consumption Time: 0.46879
Total Iteration Time: 7.38742

Cumulative Model Updates: 3,168
Cumulative Timesteps: 26,458,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04322
Policy Entropy: 4.39625
Value Function Loss: 0.07054

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04839
Policy Update Magnitude: 0.85207
Value Function Update Magnitude: 0.44627

Collected Steps per Second: 14,708.88645
Overall Steps per Second: 6,915.76875

Timestep Collection Time: 3.40026
Timestep Consumption Time: 3.83162
PPO Batch Consumption Time: 0.47269
Total Iteration Time: 7.23188

Cumulative Model Updates: 3,174
Cumulative Timesteps: 26,508,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 26508748...
Checkpoint 26508748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03165
Policy Entropy: 4.40092
Value Function Loss: 0.05097

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04282
Policy Update Magnitude: 0.79269
Value Function Update Magnitude: 0.39366

Collected Steps per Second: 14,415.95282
Overall Steps per Second: 6,725.10431

Timestep Collection Time: 3.46866
Timestep Consumption Time: 3.96677
PPO Batch Consumption Time: 0.49392
Total Iteration Time: 7.43542

Cumulative Model Updates: 3,180
Cumulative Timesteps: 26,558,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02536
Policy Entropy: 4.39951
Value Function Loss: 0.05673

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04358
Policy Update Magnitude: 0.79170
Value Function Update Magnitude: 0.37825

Collected Steps per Second: 14,446.14968
Overall Steps per Second: 6,772.13310

Timestep Collection Time: 3.46279
Timestep Consumption Time: 3.92395
PPO Batch Consumption Time: 0.49595
Total Iteration Time: 7.38674

Cumulative Model Updates: 3,186
Cumulative Timesteps: 26,608,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 26608776...
Checkpoint 26608776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07341
Policy Entropy: 4.40128
Value Function Loss: 0.05769

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04333
Policy Update Magnitude: 0.83567
Value Function Update Magnitude: 0.38705

Collected Steps per Second: 14,268.70532
Overall Steps per Second: 6,676.91835

Timestep Collection Time: 3.50571
Timestep Consumption Time: 3.98607
PPO Batch Consumption Time: 0.49162
Total Iteration Time: 7.49178

Cumulative Model Updates: 3,192
Cumulative Timesteps: 26,658,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14088
Policy Entropy: 4.39842
Value Function Loss: 0.06914

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04487
Policy Update Magnitude: 0.84029
Value Function Update Magnitude: 0.37506

Collected Steps per Second: 14,484.90952
Overall Steps per Second: 6,761.61027

Timestep Collection Time: 3.45242
Timestep Consumption Time: 3.94345
PPO Batch Consumption Time: 0.48842
Total Iteration Time: 7.39587

Cumulative Model Updates: 3,198
Cumulative Timesteps: 26,708,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 26708806...
Checkpoint 26708806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03013
Policy Entropy: 4.40451
Value Function Loss: 0.04736

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04213
Policy Update Magnitude: 0.79011
Value Function Update Magnitude: 0.34346

Collected Steps per Second: 14,094.12655
Overall Steps per Second: 6,843.13309

Timestep Collection Time: 3.54956
Timestep Consumption Time: 3.76112
PPO Batch Consumption Time: 0.46996
Total Iteration Time: 7.31069

Cumulative Model Updates: 3,204
Cumulative Timesteps: 26,758,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07051
Policy Entropy: 4.41343
Value Function Loss: 0.04560

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03912
Policy Update Magnitude: 0.70747
Value Function Update Magnitude: 0.29200

Collected Steps per Second: 14,433.77441
Overall Steps per Second: 6,806.54773

Timestep Collection Time: 3.46437
Timestep Consumption Time: 3.88208
PPO Batch Consumption Time: 0.47467
Total Iteration Time: 7.34646

Cumulative Model Updates: 3,210
Cumulative Timesteps: 26,808,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 26808838...
Checkpoint 26808838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06934
Policy Entropy: 4.41101
Value Function Loss: 0.04441

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03552
Policy Update Magnitude: 0.71872
Value Function Update Magnitude: 0.33041

Collected Steps per Second: 14,339.68709
Overall Steps per Second: 6,803.65823

Timestep Collection Time: 3.48752
Timestep Consumption Time: 3.86293
PPO Batch Consumption Time: 0.48687
Total Iteration Time: 7.35046

Cumulative Model Updates: 3,216
Cumulative Timesteps: 26,858,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02283
Policy Entropy: 4.40962
Value Function Loss: 0.05460

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04035
Policy Update Magnitude: 0.78041
Value Function Update Magnitude: 0.37327

Collected Steps per Second: 14,585.12209
Overall Steps per Second: 6,823.38862

Timestep Collection Time: 3.42952
Timestep Consumption Time: 3.90115
PPO Batch Consumption Time: 0.47699
Total Iteration Time: 7.33067

Cumulative Model Updates: 3,222
Cumulative Timesteps: 26,908,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 26908868...
Checkpoint 26908868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14880
Policy Entropy: 4.41011
Value Function Loss: 0.07079

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04127
Policy Update Magnitude: 0.81824
Value Function Update Magnitude: 0.40016

Collected Steps per Second: 14,226.78993
Overall Steps per Second: 6,695.71760

Timestep Collection Time: 3.51492
Timestep Consumption Time: 3.95344
PPO Batch Consumption Time: 0.48664
Total Iteration Time: 7.46836

Cumulative Model Updates: 3,228
Cumulative Timesteps: 26,958,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02109
Policy Entropy: 4.40639
Value Function Loss: 0.07360

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04600
Policy Update Magnitude: 0.85796
Value Function Update Magnitude: 0.37855

Collected Steps per Second: 14,959.89358
Overall Steps per Second: 6,930.38365

Timestep Collection Time: 3.34321
Timestep Consumption Time: 3.87342
PPO Batch Consumption Time: 0.47865
Total Iteration Time: 7.21663

Cumulative Model Updates: 3,234
Cumulative Timesteps: 27,008,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 27008888...
Checkpoint 27008888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08811
Policy Entropy: 4.40493
Value Function Loss: 0.07364

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04466
Policy Update Magnitude: 0.82472
Value Function Update Magnitude: 0.35793

Collected Steps per Second: 14,266.11997
Overall Steps per Second: 6,765.18390

Timestep Collection Time: 3.50663
Timestep Consumption Time: 3.88800
PPO Batch Consumption Time: 0.48269
Total Iteration Time: 7.39463

Cumulative Model Updates: 3,240
Cumulative Timesteps: 27,058,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00877
Policy Entropy: 4.40281
Value Function Loss: 0.06911

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04243
Policy Update Magnitude: 0.82038
Value Function Update Magnitude: 0.37786

Collected Steps per Second: 14,515.67780
Overall Steps per Second: 6,846.19680

Timestep Collection Time: 3.44469
Timestep Consumption Time: 3.85893
PPO Batch Consumption Time: 0.48727
Total Iteration Time: 7.30362

Cumulative Model Updates: 3,246
Cumulative Timesteps: 27,108,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 27108916...
Checkpoint 27108916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01351
Policy Entropy: 4.40047
Value Function Loss: 0.07177

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04696
Policy Update Magnitude: 0.84481
Value Function Update Magnitude: 0.40321

Collected Steps per Second: 14,352.95198
Overall Steps per Second: 6,760.19422

Timestep Collection Time: 3.48444
Timestep Consumption Time: 3.91357
PPO Batch Consumption Time: 0.48544
Total Iteration Time: 7.39801

Cumulative Model Updates: 3,252
Cumulative Timesteps: 27,158,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02952
Policy Entropy: 4.40419
Value Function Loss: 0.05458

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04137
Policy Update Magnitude: 0.79984
Value Function Update Magnitude: 0.38331

Collected Steps per Second: 14,470.73730
Overall Steps per Second: 6,879.94543

Timestep Collection Time: 3.45580
Timestep Consumption Time: 3.81286
PPO Batch Consumption Time: 0.47644
Total Iteration Time: 7.26866

Cumulative Model Updates: 3,258
Cumulative Timesteps: 27,208,936

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 27208936...
Checkpoint 27208936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06855
Policy Entropy: 4.40279
Value Function Loss: 0.05245

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.03997
Policy Update Magnitude: 0.70894
Value Function Update Magnitude: 0.31667

Collected Steps per Second: 14,459.45222
Overall Steps per Second: 6,882.74480

Timestep Collection Time: 3.45905
Timestep Consumption Time: 3.80782
PPO Batch Consumption Time: 0.46510
Total Iteration Time: 7.26687

Cumulative Model Updates: 3,264
Cumulative Timesteps: 27,258,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02809
Policy Entropy: 4.39615
Value Function Loss: 0.04751

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.03802
Policy Update Magnitude: 0.72001
Value Function Update Magnitude: 0.29356

Collected Steps per Second: 14,373.23951
Overall Steps per Second: 6,788.96019

Timestep Collection Time: 3.47869
Timestep Consumption Time: 3.88621
PPO Batch Consumption Time: 0.48236
Total Iteration Time: 7.36490

Cumulative Model Updates: 3,270
Cumulative Timesteps: 27,308,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 27308952...
Checkpoint 27308952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05666
Policy Entropy: 4.39508
Value Function Loss: 0.06572

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04369
Policy Update Magnitude: 0.77547
Value Function Update Magnitude: 0.34496

Collected Steps per Second: 14,228.54096
Overall Steps per Second: 6,792.65921

Timestep Collection Time: 3.51463
Timestep Consumption Time: 3.84744
PPO Batch Consumption Time: 0.48377
Total Iteration Time: 7.36207

Cumulative Model Updates: 3,276
Cumulative Timesteps: 27,358,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03511
Policy Entropy: 4.39322
Value Function Loss: 0.06739

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05096
Policy Update Magnitude: 0.81235
Value Function Update Magnitude: 0.35281

Collected Steps per Second: 14,504.85685
Overall Steps per Second: 6,774.36421

Timestep Collection Time: 3.44740
Timestep Consumption Time: 3.93396
PPO Batch Consumption Time: 0.48829
Total Iteration Time: 7.38136

Cumulative Model Updates: 3,282
Cumulative Timesteps: 27,408,964

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 27408964...
Checkpoint 27408964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18174
Policy Entropy: 4.38738
Value Function Loss: 0.09050

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04820
Policy Update Magnitude: 0.85222
Value Function Update Magnitude: 0.37536

Collected Steps per Second: 14,306.06978
Overall Steps per Second: 6,896.72752

Timestep Collection Time: 3.49502
Timestep Consumption Time: 3.75480
PPO Batch Consumption Time: 0.47189
Total Iteration Time: 7.24982

Cumulative Model Updates: 3,288
Cumulative Timesteps: 27,458,964

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08611
Policy Entropy: 4.38980
Value Function Loss: 0.08232

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05251
Policy Update Magnitude: 0.89559
Value Function Update Magnitude: 0.38532

Collected Steps per Second: 14,695.81444
Overall Steps per Second: 6,717.44504

Timestep Collection Time: 3.40423
Timestep Consumption Time: 4.04324
PPO Batch Consumption Time: 0.50540
Total Iteration Time: 7.44747

Cumulative Model Updates: 3,294
Cumulative Timesteps: 27,508,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 27508992...
Checkpoint 27508992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05171
Policy Entropy: 4.39264
Value Function Loss: 0.08141

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04820
Policy Update Magnitude: 0.87880
Value Function Update Magnitude: 0.41841

Collected Steps per Second: 14,353.64393
Overall Steps per Second: 6,769.10223

Timestep Collection Time: 3.48344
Timestep Consumption Time: 3.90307
PPO Batch Consumption Time: 0.47990
Total Iteration Time: 7.38650

Cumulative Model Updates: 3,300
Cumulative Timesteps: 27,558,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07182
Policy Entropy: 4.39459
Value Function Loss: 0.07189

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04359
Policy Update Magnitude: 0.85526
Value Function Update Magnitude: 0.38453

Collected Steps per Second: 14,660.87435
Overall Steps per Second: 6,957.66615

Timestep Collection Time: 3.41126
Timestep Consumption Time: 3.77679
PPO Batch Consumption Time: 0.47669
Total Iteration Time: 7.18804

Cumulative Model Updates: 3,306
Cumulative Timesteps: 27,609,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 27609004...
Checkpoint 27609004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15535
Policy Entropy: 4.39088
Value Function Loss: 0.08618

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04546
Policy Update Magnitude: 0.87794
Value Function Update Magnitude: 0.42847

Collected Steps per Second: 14,217.60173
Overall Steps per Second: 6,679.94349

Timestep Collection Time: 3.51831
Timestep Consumption Time: 3.97007
PPO Batch Consumption Time: 0.48991
Total Iteration Time: 7.48839

Cumulative Model Updates: 3,312
Cumulative Timesteps: 27,659,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03693
Policy Entropy: 4.39152
Value Function Loss: 0.07591

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.04722
Policy Update Magnitude: 0.87544
Value Function Update Magnitude: 0.42387

Collected Steps per Second: 14,490.92903
Overall Steps per Second: 6,880.67843

Timestep Collection Time: 3.45043
Timestep Consumption Time: 3.81629
PPO Batch Consumption Time: 0.47563
Total Iteration Time: 7.26673

Cumulative Model Updates: 3,318
Cumulative Timesteps: 27,709,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 27709026...
Checkpoint 27709026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09423
Policy Entropy: 4.39369
Value Function Loss: 0.06245

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04124
Policy Update Magnitude: 0.82476
Value Function Update Magnitude: 0.41380

Collected Steps per Second: 14,106.43199
Overall Steps per Second: 6,725.61761

Timestep Collection Time: 3.54590
Timestep Consumption Time: 3.89133
PPO Batch Consumption Time: 0.47543
Total Iteration Time: 7.43724

Cumulative Model Updates: 3,324
Cumulative Timesteps: 27,759,046

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02459
Policy Entropy: 4.39568
Value Function Loss: 0.04983

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04276
Policy Update Magnitude: 0.78664
Value Function Update Magnitude: 0.38639

Collected Steps per Second: 14,345.61511
Overall Steps per Second: 6,804.91138

Timestep Collection Time: 3.48650
Timestep Consumption Time: 3.86348
PPO Batch Consumption Time: 0.47438
Total Iteration Time: 7.34999

Cumulative Model Updates: 3,330
Cumulative Timesteps: 27,809,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 27809062...
Checkpoint 27809062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08019
Policy Entropy: 4.39735
Value Function Loss: 0.05497

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.03971
Policy Update Magnitude: 0.75655
Value Function Update Magnitude: 0.32665

Collected Steps per Second: 14,557.05625
Overall Steps per Second: 6,865.23261

Timestep Collection Time: 3.43586
Timestep Consumption Time: 3.84955
PPO Batch Consumption Time: 0.47550
Total Iteration Time: 7.28541

Cumulative Model Updates: 3,336
Cumulative Timesteps: 27,859,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07854
Policy Entropy: 4.39468
Value Function Loss: 0.06293

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04194
Policy Update Magnitude: 0.76313
Value Function Update Magnitude: 0.31964

Collected Steps per Second: 14,442.64471
Overall Steps per Second: 6,800.75068

Timestep Collection Time: 3.46335
Timestep Consumption Time: 3.89172
PPO Batch Consumption Time: 0.47487
Total Iteration Time: 7.35507

Cumulative Model Updates: 3,342
Cumulative Timesteps: 27,909,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 27909098...
Checkpoint 27909098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03530
Policy Entropy: 4.39219
Value Function Loss: 0.06080

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04015
Policy Update Magnitude: 0.76050
Value Function Update Magnitude: 0.33005

Collected Steps per Second: 13,940.41954
Overall Steps per Second: 6,745.26739

Timestep Collection Time: 3.58727
Timestep Consumption Time: 3.82652
PPO Batch Consumption Time: 0.48086
Total Iteration Time: 7.41379

Cumulative Model Updates: 3,348
Cumulative Timesteps: 27,959,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03245
Policy Entropy: 4.38784
Value Function Loss: 0.07986

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04500
Policy Update Magnitude: 0.80302
Value Function Update Magnitude: 0.35451

Collected Steps per Second: 14,465.34371
Overall Steps per Second: 6,752.75527

Timestep Collection Time: 3.45723
Timestep Consumption Time: 3.94864
PPO Batch Consumption Time: 0.48927
Total Iteration Time: 7.40587

Cumulative Model Updates: 3,354
Cumulative Timesteps: 28,009,116

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 28009116...
Checkpoint 28009116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03832
Policy Entropy: 4.37965
Value Function Loss: 0.07674

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05224
Policy Update Magnitude: 0.87468
Value Function Update Magnitude: 0.37325

Collected Steps per Second: 14,308.54982
Overall Steps per Second: 6,770.24236

Timestep Collection Time: 3.49455
Timestep Consumption Time: 3.89100
PPO Batch Consumption Time: 0.48601
Total Iteration Time: 7.38556

Cumulative Model Updates: 3,360
Cumulative Timesteps: 28,059,118

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07877
Policy Entropy: 4.37125
Value Function Loss: 0.08140

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05310
Policy Update Magnitude: 0.89150
Value Function Update Magnitude: 0.35814

Collected Steps per Second: 14,567.74489
Overall Steps per Second: 6,885.82790

Timestep Collection Time: 3.43389
Timestep Consumption Time: 3.83089
PPO Batch Consumption Time: 0.47701
Total Iteration Time: 7.26478

Cumulative Model Updates: 3,366
Cumulative Timesteps: 28,109,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 28109142...
Checkpoint 28109142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04396
Policy Entropy: 4.37189
Value Function Loss: 0.08321

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05271
Policy Update Magnitude: 0.89612
Value Function Update Magnitude: 0.41110

Collected Steps per Second: 14,327.49312
Overall Steps per Second: 6,766.33764

Timestep Collection Time: 3.49035
Timestep Consumption Time: 3.90035
PPO Batch Consumption Time: 0.47450
Total Iteration Time: 7.39070

Cumulative Model Updates: 3,372
Cumulative Timesteps: 28,159,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15804
Policy Entropy: 4.36860
Value Function Loss: 0.09320

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05819
Policy Update Magnitude: 0.88874
Value Function Update Magnitude: 0.37105

Collected Steps per Second: 14,470.86268
Overall Steps per Second: 6,850.59107

Timestep Collection Time: 3.45646
Timestep Consumption Time: 3.84480
PPO Batch Consumption Time: 0.48372
Total Iteration Time: 7.30127

Cumulative Model Updates: 3,378
Cumulative Timesteps: 28,209,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 28209168...
Checkpoint 28209168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04051
Policy Entropy: 4.36543
Value Function Loss: 0.11382

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05618
Policy Update Magnitude: 0.92780
Value Function Update Magnitude: 0.33473

Collected Steps per Second: 14,355.53406
Overall Steps per Second: 6,781.78493

Timestep Collection Time: 3.48479
Timestep Consumption Time: 3.89174
PPO Batch Consumption Time: 0.48366
Total Iteration Time: 7.37652

Cumulative Model Updates: 3,384
Cumulative Timesteps: 28,259,194

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06045
Policy Entropy: 4.36297
Value Function Loss: 0.11804

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06152
Policy Update Magnitude: 0.98835
Value Function Update Magnitude: 0.34322

Collected Steps per Second: 14,329.49522
Overall Steps per Second: 6,852.34834

Timestep Collection Time: 3.49154
Timestep Consumption Time: 3.80990
PPO Batch Consumption Time: 0.47038
Total Iteration Time: 7.30144

Cumulative Model Updates: 3,390
Cumulative Timesteps: 28,309,226

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 28309226...
Checkpoint 28309226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02167
Policy Entropy: 4.36308
Value Function Loss: 0.12246

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06361
Policy Update Magnitude: 1.00936
Value Function Update Magnitude: 0.37963

Collected Steps per Second: 14,397.23186
Overall Steps per Second: 6,648.74400

Timestep Collection Time: 3.47358
Timestep Consumption Time: 4.04814
PPO Batch Consumption Time: 0.51151
Total Iteration Time: 7.52172

Cumulative Model Updates: 3,396
Cumulative Timesteps: 28,359,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10360
Policy Entropy: 4.35582
Value Function Loss: 0.10823

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.97455
Value Function Update Magnitude: 0.35471

Collected Steps per Second: 14,329.76409
Overall Steps per Second: 6,857.39496

Timestep Collection Time: 3.49050
Timestep Consumption Time: 3.80353
PPO Batch Consumption Time: 0.46984
Total Iteration Time: 7.29402

Cumulative Model Updates: 3,402
Cumulative Timesteps: 28,409,254

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 28409254...
Checkpoint 28409254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07913
Policy Entropy: 4.36233
Value Function Loss: 0.09343

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07105
Policy Update Magnitude: 0.91798
Value Function Update Magnitude: 0.35030

Collected Steps per Second: 14,391.39192
Overall Steps per Second: 6,875.30589

Timestep Collection Time: 3.47430
Timestep Consumption Time: 3.79810
PPO Batch Consumption Time: 0.47747
Total Iteration Time: 7.27240

Cumulative Model Updates: 3,408
Cumulative Timesteps: 28,459,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11349
Policy Entropy: 4.35458
Value Function Loss: 0.09326

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.05964
Policy Update Magnitude: 0.91502
Value Function Update Magnitude: 0.40806

Collected Steps per Second: 14,380.11949
Overall Steps per Second: 6,874.26844

Timestep Collection Time: 3.47897
Timestep Consumption Time: 3.79860
PPO Batch Consumption Time: 0.46360
Total Iteration Time: 7.27757

Cumulative Model Updates: 3,414
Cumulative Timesteps: 28,509,282

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 28509282...
Checkpoint 28509282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02876
Policy Entropy: 4.35958
Value Function Loss: 0.08869

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05150
Policy Update Magnitude: 0.91847
Value Function Update Magnitude: 0.41129

Collected Steps per Second: 14,353.29588
Overall Steps per Second: 6,885.78548

Timestep Collection Time: 3.48533
Timestep Consumption Time: 3.77978
PPO Batch Consumption Time: 0.46743
Total Iteration Time: 7.26511

Cumulative Model Updates: 3,420
Cumulative Timesteps: 28,559,308

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21895
Policy Entropy: 4.35274
Value Function Loss: 0.10493

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05440
Policy Update Magnitude: 0.93567
Value Function Update Magnitude: 0.41002

Collected Steps per Second: 14,553.86358
Overall Steps per Second: 6,917.14962

Timestep Collection Time: 3.43648
Timestep Consumption Time: 3.79396
PPO Batch Consumption Time: 0.47482
Total Iteration Time: 7.23043

Cumulative Model Updates: 3,426
Cumulative Timesteps: 28,609,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 28609322...
Checkpoint 28609322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03472
Policy Entropy: 4.34642
Value Function Loss: 0.10375

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05605
Policy Update Magnitude: 0.95303
Value Function Update Magnitude: 0.42444

Collected Steps per Second: 14,338.26411
Overall Steps per Second: 6,779.83757

Timestep Collection Time: 3.48801
Timestep Consumption Time: 3.88857
PPO Batch Consumption Time: 0.47853
Total Iteration Time: 7.37658

Cumulative Model Updates: 3,432
Cumulative Timesteps: 28,659,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01058
Policy Entropy: 4.34922
Value Function Loss: 0.09667

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07269
Policy Update Magnitude: 0.93279
Value Function Update Magnitude: 0.35812

Collected Steps per Second: 14,365.25747
Overall Steps per Second: 6,832.75529

Timestep Collection Time: 3.48271
Timestep Consumption Time: 3.83937
PPO Batch Consumption Time: 0.48877
Total Iteration Time: 7.32208

Cumulative Model Updates: 3,438
Cumulative Timesteps: 28,709,364

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 28709364...
Checkpoint 28709364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02096
Policy Entropy: 4.35568
Value Function Loss: 0.07341

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06156
Policy Update Magnitude: 0.86238
Value Function Update Magnitude: 0.32901

Collected Steps per Second: 14,385.91898
Overall Steps per Second: 6,778.49246

Timestep Collection Time: 3.47757
Timestep Consumption Time: 3.90283
PPO Batch Consumption Time: 0.48223
Total Iteration Time: 7.38040

Cumulative Model Updates: 3,444
Cumulative Timesteps: 28,759,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01835
Policy Entropy: 4.36996
Value Function Loss: 0.06626

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04878
Policy Update Magnitude: 0.78386
Value Function Update Magnitude: 0.30305

Collected Steps per Second: 14,390.09618
Overall Steps per Second: 6,705.04765

Timestep Collection Time: 3.47586
Timestep Consumption Time: 3.98389
PPO Batch Consumption Time: 0.49794
Total Iteration Time: 7.45975

Cumulative Model Updates: 3,450
Cumulative Timesteps: 28,809,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 28809410...
Checkpoint 28809410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03152
Policy Entropy: 4.37242
Value Function Loss: 0.06465

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04737
Policy Update Magnitude: 0.76526
Value Function Update Magnitude: 0.31481

Collected Steps per Second: 14,617.83620
Overall Steps per Second: 6,807.60310

Timestep Collection Time: 3.42062
Timestep Consumption Time: 3.92441
PPO Batch Consumption Time: 0.48339
Total Iteration Time: 7.34502

Cumulative Model Updates: 3,456
Cumulative Timesteps: 28,859,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02009
Policy Entropy: 4.37137
Value Function Loss: 0.06740

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04381
Policy Update Magnitude: 0.77640
Value Function Update Magnitude: 0.32090

Collected Steps per Second: 14,483.10603
Overall Steps per Second: 6,793.12179

Timestep Collection Time: 3.45299
Timestep Consumption Time: 3.90887
PPO Batch Consumption Time: 0.47788
Total Iteration Time: 7.36186

Cumulative Model Updates: 3,462
Cumulative Timesteps: 28,909,422

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 28909422...
Checkpoint 28909422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05219
Policy Entropy: 4.37243
Value Function Loss: 0.05994

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.03908
Policy Update Magnitude: 0.77755
Value Function Update Magnitude: 0.32226

Collected Steps per Second: 14,599.35020
Overall Steps per Second: 6,785.13034

Timestep Collection Time: 3.42591
Timestep Consumption Time: 3.94551
PPO Batch Consumption Time: 0.49043
Total Iteration Time: 7.37141

Cumulative Model Updates: 3,468
Cumulative Timesteps: 28,959,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00962
Policy Entropy: 4.37111
Value Function Loss: 0.07533

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04024
Policy Update Magnitude: 0.78547
Value Function Update Magnitude: 0.33975

Collected Steps per Second: 14,482.11791
Overall Steps per Second: 6,768.97106

Timestep Collection Time: 3.45350
Timestep Consumption Time: 3.93521
PPO Batch Consumption Time: 0.48465
Total Iteration Time: 7.38872

Cumulative Model Updates: 3,474
Cumulative Timesteps: 29,009,452

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 29009452...
Checkpoint 29009452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07495
Policy Entropy: 4.36663
Value Function Loss: 0.10001

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04998
Policy Update Magnitude: 0.85962
Value Function Update Magnitude: 0.37343

Collected Steps per Second: 14,421.67101
Overall Steps per Second: 6,922.54681

Timestep Collection Time: 3.46853
Timestep Consumption Time: 3.75742
PPO Batch Consumption Time: 0.46621
Total Iteration Time: 7.22595

Cumulative Model Updates: 3,480
Cumulative Timesteps: 29,059,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09108
Policy Entropy: 4.36826
Value Function Loss: 0.10521

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05175
Policy Update Magnitude: 0.90077
Value Function Update Magnitude: 0.45650

Collected Steps per Second: 14,408.57824
Overall Steps per Second: 6,795.99931

Timestep Collection Time: 3.47210
Timestep Consumption Time: 3.88929
PPO Batch Consumption Time: 0.47405
Total Iteration Time: 7.36139

Cumulative Model Updates: 3,486
Cumulative Timesteps: 29,109,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 29109502...
Checkpoint 29109502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05860
Policy Entropy: 4.36847
Value Function Loss: 0.08632

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.04982
Policy Update Magnitude: 0.90731
Value Function Update Magnitude: 0.49196

Collected Steps per Second: 14,417.21903
Overall Steps per Second: 6,877.85904

Timestep Collection Time: 3.46918
Timestep Consumption Time: 3.80285
PPO Batch Consumption Time: 0.47387
Total Iteration Time: 7.27203

Cumulative Model Updates: 3,492
Cumulative Timesteps: 29,159,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00767
Policy Entropy: 4.37132
Value Function Loss: 0.08508

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05063
Policy Update Magnitude: 0.88241
Value Function Update Magnitude: 0.46615

Collected Steps per Second: 14,463.18753
Overall Steps per Second: 6,643.97525

Timestep Collection Time: 3.45857
Timestep Consumption Time: 4.07035
PPO Batch Consumption Time: 0.50082
Total Iteration Time: 7.52893

Cumulative Model Updates: 3,498
Cumulative Timesteps: 29,209,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 29209540...
Checkpoint 29209540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06152
Policy Entropy: 4.37169
Value Function Loss: 0.07383

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05001
Policy Update Magnitude: 0.88100
Value Function Update Magnitude: 0.45286

Collected Steps per Second: 14,197.03290
Overall Steps per Second: 6,723.99933

Timestep Collection Time: 3.52383
Timestep Consumption Time: 3.91638
PPO Batch Consumption Time: 0.49127
Total Iteration Time: 7.44021

Cumulative Model Updates: 3,504
Cumulative Timesteps: 29,259,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11340
Policy Entropy: 4.37669
Value Function Loss: 0.07616

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.04963
Policy Update Magnitude: 0.85179
Value Function Update Magnitude: 0.41797

Collected Steps per Second: 14,279.22351
Overall Steps per Second: 6,889.48809

Timestep Collection Time: 3.50453
Timestep Consumption Time: 3.75900
PPO Batch Consumption Time: 0.47636
Total Iteration Time: 7.26353

Cumulative Model Updates: 3,510
Cumulative Timesteps: 29,309,610

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 29309610...
Checkpoint 29309610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00913
Policy Entropy: 4.37924
Value Function Loss: 0.06182

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04340
Policy Update Magnitude: 0.80594
Value Function Update Magnitude: 0.39587

Collected Steps per Second: 14,370.72304
Overall Steps per Second: 6,790.26218

Timestep Collection Time: 3.47957
Timestep Consumption Time: 3.88450
PPO Batch Consumption Time: 0.47293
Total Iteration Time: 7.36407

Cumulative Model Updates: 3,516
Cumulative Timesteps: 29,359,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10433
Policy Entropy: 4.38214
Value Function Loss: 0.07117

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.03798
Policy Update Magnitude: 0.79698
Value Function Update Magnitude: 0.36875

Collected Steps per Second: 14,579.64695
Overall Steps per Second: 6,927.58070

Timestep Collection Time: 3.43081
Timestep Consumption Time: 3.78960
PPO Batch Consumption Time: 0.47539
Total Iteration Time: 7.22041

Cumulative Model Updates: 3,522
Cumulative Timesteps: 29,409,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 29409634...
Checkpoint 29409634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02194
Policy Entropy: 4.37869
Value Function Loss: 0.07711

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04241
Policy Update Magnitude: 0.81933
Value Function Update Magnitude: 0.44113

Collected Steps per Second: 14,241.74699
Overall Steps per Second: 6,704.24597

Timestep Collection Time: 3.51193
Timestep Consumption Time: 3.94842
PPO Batch Consumption Time: 0.48417
Total Iteration Time: 7.46035

Cumulative Model Updates: 3,528
Cumulative Timesteps: 29,459,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04729
Policy Entropy: 4.38245
Value Function Loss: 0.07905

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04864
Policy Update Magnitude: 0.83997
Value Function Update Magnitude: 0.47043

Collected Steps per Second: 14,228.69844
Overall Steps per Second: 6,721.83433

Timestep Collection Time: 3.51459
Timestep Consumption Time: 3.92505
PPO Batch Consumption Time: 0.48941
Total Iteration Time: 7.43964

Cumulative Model Updates: 3,534
Cumulative Timesteps: 29,509,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 29509658...
Checkpoint 29509658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00250
Policy Entropy: 4.38574
Value Function Loss: 0.09233

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.04857
Policy Update Magnitude: 0.87750
Value Function Update Magnitude: 0.41870

Collected Steps per Second: 14,519.20207
Overall Steps per Second: 6,847.21220

Timestep Collection Time: 3.44537
Timestep Consumption Time: 3.86038
PPO Batch Consumption Time: 0.47177
Total Iteration Time: 7.30575

Cumulative Model Updates: 3,540
Cumulative Timesteps: 29,559,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17738
Policy Entropy: 4.38511
Value Function Loss: 0.08772

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04429
Policy Update Magnitude: 0.88774
Value Function Update Magnitude: 0.41005

Collected Steps per Second: 14,368.94300
Overall Steps per Second: 6,781.44457

Timestep Collection Time: 3.48070
Timestep Consumption Time: 3.89442
PPO Batch Consumption Time: 0.47661
Total Iteration Time: 7.37512

Cumulative Model Updates: 3,546
Cumulative Timesteps: 29,609,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 29609696...
Checkpoint 29609696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03320
Policy Entropy: 4.38071
Value Function Loss: 0.08385

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.04958
Policy Update Magnitude: 0.84798
Value Function Update Magnitude: 0.38387

Collected Steps per Second: 14,505.80413
Overall Steps per Second: 6,776.57262

Timestep Collection Time: 3.44759
Timestep Consumption Time: 3.93225
PPO Batch Consumption Time: 0.49066
Total Iteration Time: 7.37984

Cumulative Model Updates: 3,552
Cumulative Timesteps: 29,659,706

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01466
Policy Entropy: 4.38102
Value Function Loss: 0.07217

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04391
Policy Update Magnitude: 0.83564
Value Function Update Magnitude: 0.33642

Collected Steps per Second: 14,446.78693
Overall Steps per Second: 6,833.84735

Timestep Collection Time: 3.46208
Timestep Consumption Time: 3.85678
PPO Batch Consumption Time: 0.47955
Total Iteration Time: 7.31886

Cumulative Model Updates: 3,558
Cumulative Timesteps: 29,709,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 29709722...
Checkpoint 29709722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13574
Policy Entropy: 4.38064
Value Function Loss: 0.07774

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04026
Policy Update Magnitude: 0.83287
Value Function Update Magnitude: 0.31272

Collected Steps per Second: 14,468.46122
Overall Steps per Second: 6,848.26597

Timestep Collection Time: 3.45704
Timestep Consumption Time: 3.84671
PPO Batch Consumption Time: 0.48744
Total Iteration Time: 7.30375

Cumulative Model Updates: 3,564
Cumulative Timesteps: 29,759,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00884
Policy Entropy: 4.38105
Value Function Loss: 0.08580

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04486
Policy Update Magnitude: 0.86823
Value Function Update Magnitude: 0.35069

Collected Steps per Second: 14,539.28823
Overall Steps per Second: 6,802.35118

Timestep Collection Time: 3.43992
Timestep Consumption Time: 3.91254
PPO Batch Consumption Time: 0.48918
Total Iteration Time: 7.35246

Cumulative Model Updates: 3,570
Cumulative Timesteps: 29,809,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 29809754...
Checkpoint 29809754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02985
Policy Entropy: 4.38093
Value Function Loss: 0.09308

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04290
Policy Update Magnitude: 0.89850
Value Function Update Magnitude: 0.33342

Collected Steps per Second: 14,308.76875
Overall Steps per Second: 6,750.11881

Timestep Collection Time: 3.49632
Timestep Consumption Time: 3.91511
PPO Batch Consumption Time: 0.48864
Total Iteration Time: 7.41143

Cumulative Model Updates: 3,576
Cumulative Timesteps: 29,859,782

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06574
Policy Entropy: 4.37986
Value Function Loss: 0.07648

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04760
Policy Update Magnitude: 0.86171
Value Function Update Magnitude: 0.36628

Collected Steps per Second: 14,401.76905
Overall Steps per Second: 6,859.80069

Timestep Collection Time: 3.47332
Timestep Consumption Time: 3.81873
PPO Batch Consumption Time: 0.47624
Total Iteration Time: 7.29205

Cumulative Model Updates: 3,582
Cumulative Timesteps: 29,909,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 29909804...
Checkpoint 29909804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04471
Policy Entropy: 4.38046
Value Function Loss: 0.07236

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03731
Policy Update Magnitude: 0.82585
Value Function Update Magnitude: 0.32389

Collected Steps per Second: 14,317.99844
Overall Steps per Second: 6,740.01677

Timestep Collection Time: 3.49225
Timestep Consumption Time: 3.92643
PPO Batch Consumption Time: 0.47734
Total Iteration Time: 7.41868

Cumulative Model Updates: 3,588
Cumulative Timesteps: 29,959,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00490
Policy Entropy: 4.37965
Value Function Loss: 0.05856

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.03755
Policy Update Magnitude: 0.81721
Value Function Update Magnitude: 0.30366

Collected Steps per Second: 14,780.03219
Overall Steps per Second: 6,956.37522

Timestep Collection Time: 3.38321
Timestep Consumption Time: 3.80501
PPO Batch Consumption Time: 0.47520
Total Iteration Time: 7.18823

Cumulative Model Updates: 3,594
Cumulative Timesteps: 30,009,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 30009810...
Checkpoint 30009810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21052
Policy Entropy: 4.38317
Value Function Loss: 0.06835

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03993
Policy Update Magnitude: 0.82383
Value Function Update Magnitude: 0.28711

Collected Steps per Second: 14,490.64513
Overall Steps per Second: 6,625.96243

Timestep Collection Time: 3.45188
Timestep Consumption Time: 4.09721
PPO Batch Consumption Time: 0.50956
Total Iteration Time: 7.54909

Cumulative Model Updates: 3,600
Cumulative Timesteps: 30,059,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01211
Policy Entropy: 4.37397
Value Function Loss: 0.05983

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04333
Policy Update Magnitude: 0.80370
Value Function Update Magnitude: 0.30847

Collected Steps per Second: 14,276.75075
Overall Steps per Second: 6,751.30232

Timestep Collection Time: 3.50388
Timestep Consumption Time: 3.90565
PPO Batch Consumption Time: 0.48895
Total Iteration Time: 7.40953

Cumulative Model Updates: 3,606
Cumulative Timesteps: 30,109,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 30109854...
Checkpoint 30109854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03095
Policy Entropy: 4.37476
Value Function Loss: 0.05965

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04050
Policy Update Magnitude: 0.76814
Value Function Update Magnitude: 0.28588

Collected Steps per Second: 14,855.22631
Overall Steps per Second: 6,832.70411

Timestep Collection Time: 3.36582
Timestep Consumption Time: 3.95193
PPO Batch Consumption Time: 0.48350
Total Iteration Time: 7.31775

Cumulative Model Updates: 3,612
Cumulative Timesteps: 30,159,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16223
Policy Entropy: 4.37054
Value Function Loss: 0.06935

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04510
Policy Update Magnitude: 0.79926
Value Function Update Magnitude: 0.29762

Collected Steps per Second: 14,473.19171
Overall Steps per Second: 6,814.96436

Timestep Collection Time: 3.45577
Timestep Consumption Time: 3.88337
PPO Batch Consumption Time: 0.47582
Total Iteration Time: 7.33914

Cumulative Model Updates: 3,618
Cumulative Timesteps: 30,209,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 30209870...
Checkpoint 30209870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01609
Policy Entropy: 4.37625
Value Function Loss: 0.07750

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04797
Policy Update Magnitude: 0.82841
Value Function Update Magnitude: 0.28932

Collected Steps per Second: 14,256.28601
Overall Steps per Second: 6,891.68719

Timestep Collection Time: 3.50863
Timestep Consumption Time: 3.74939
PPO Batch Consumption Time: 0.47192
Total Iteration Time: 7.25802

Cumulative Model Updates: 3,624
Cumulative Timesteps: 30,259,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19302
Policy Entropy: 4.37194
Value Function Loss: 0.10146

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05348
Policy Update Magnitude: 0.88822
Value Function Update Magnitude: 0.28474

Collected Steps per Second: 14,496.34814
Overall Steps per Second: 6,808.13514

Timestep Collection Time: 3.44970
Timestep Consumption Time: 3.89563
PPO Batch Consumption Time: 0.47624
Total Iteration Time: 7.34533

Cumulative Model Updates: 3,630
Cumulative Timesteps: 30,309,898

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 30309898...
Checkpoint 30309898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16168
Policy Entropy: 4.37665
Value Function Loss: 0.08695

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05843
Policy Update Magnitude: 0.89125
Value Function Update Magnitude: 0.29178

Collected Steps per Second: 14,365.55616
Overall Steps per Second: 6,884.13924

Timestep Collection Time: 3.48208
Timestep Consumption Time: 3.78419
PPO Batch Consumption Time: 0.47658
Total Iteration Time: 7.26627

Cumulative Model Updates: 3,636
Cumulative Timesteps: 30,359,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02469
Policy Entropy: 4.37990
Value Function Loss: 0.09377

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04898
Policy Update Magnitude: 0.88255
Value Function Update Magnitude: 0.30223

Collected Steps per Second: 14,601.28677
Overall Steps per Second: 6,829.29175

Timestep Collection Time: 3.42504
Timestep Consumption Time: 3.89783
PPO Batch Consumption Time: 0.47437
Total Iteration Time: 7.32287

Cumulative Model Updates: 3,642
Cumulative Timesteps: 30,409,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 30409930...
Checkpoint 30409930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21596
Policy Entropy: 4.37965
Value Function Loss: 0.08642

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04909
Policy Update Magnitude: 0.89297
Value Function Update Magnitude: 0.32487

Collected Steps per Second: 14,281.19163
Overall Steps per Second: 6,769.54962

Timestep Collection Time: 3.50237
Timestep Consumption Time: 3.88631
PPO Batch Consumption Time: 0.48312
Total Iteration Time: 7.38867

Cumulative Model Updates: 3,648
Cumulative Timesteps: 30,459,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18477
Policy Entropy: 4.37580
Value Function Loss: 0.09816

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05289
Policy Update Magnitude: 0.91242
Value Function Update Magnitude: 0.32095

Collected Steps per Second: 14,802.92894
Overall Steps per Second: 6,785.06937

Timestep Collection Time: 3.37893
Timestep Consumption Time: 3.99285
PPO Batch Consumption Time: 0.49738
Total Iteration Time: 7.37177

Cumulative Model Updates: 3,654
Cumulative Timesteps: 30,509,966

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 30509966...
Checkpoint 30509966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00052
Policy Entropy: 4.36891
Value Function Loss: 0.10749

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05698
Policy Update Magnitude: 0.90112
Value Function Update Magnitude: 0.31661

Collected Steps per Second: 14,617.58990
Overall Steps per Second: 6,852.39947

Timestep Collection Time: 3.42108
Timestep Consumption Time: 3.87680
PPO Batch Consumption Time: 0.47362
Total Iteration Time: 7.29788

Cumulative Model Updates: 3,660
Cumulative Timesteps: 30,559,974

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06902
Policy Entropy: 4.36767
Value Function Loss: 0.10347

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06075
Policy Update Magnitude: 0.89842
Value Function Update Magnitude: 0.32359

Collected Steps per Second: 14,671.72736
Overall Steps per Second: 6,885.47336

Timestep Collection Time: 3.40860
Timestep Consumption Time: 3.85452
PPO Batch Consumption Time: 0.47630
Total Iteration Time: 7.26312

Cumulative Model Updates: 3,666
Cumulative Timesteps: 30,609,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 30609984...
Checkpoint 30609984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04046
Policy Entropy: 4.36200
Value Function Loss: 0.09299

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05917
Policy Update Magnitude: 0.90384
Value Function Update Magnitude: 0.38692

Collected Steps per Second: 14,365.85209
Overall Steps per Second: 6,774.64212

Timestep Collection Time: 3.48075
Timestep Consumption Time: 3.90030
PPO Batch Consumption Time: 0.47895
Total Iteration Time: 7.38105

Cumulative Model Updates: 3,672
Cumulative Timesteps: 30,659,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09472
Policy Entropy: 4.36349
Value Function Loss: 0.08092

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05230
Policy Update Magnitude: 0.86793
Value Function Update Magnitude: 0.41053

Collected Steps per Second: 14,810.88167
Overall Steps per Second: 6,857.91859

Timestep Collection Time: 3.37644
Timestep Consumption Time: 3.91557
PPO Batch Consumption Time: 0.48734
Total Iteration Time: 7.29201

Cumulative Model Updates: 3,678
Cumulative Timesteps: 30,709,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 30709996...
Checkpoint 30709996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09430
Policy Entropy: 4.36294
Value Function Loss: 0.06359

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04520
Policy Update Magnitude: 0.82522
Value Function Update Magnitude: 0.42202

Collected Steps per Second: 14,451.66000
Overall Steps per Second: 6,849.66243

Timestep Collection Time: 3.46078
Timestep Consumption Time: 3.84089
PPO Batch Consumption Time: 0.47474
Total Iteration Time: 7.30167

Cumulative Model Updates: 3,684
Cumulative Timesteps: 30,760,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01822
Policy Entropy: 4.35955
Value Function Loss: 0.06154

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05072
Policy Update Magnitude: 0.79794
Value Function Update Magnitude: 0.47698

Collected Steps per Second: 14,457.42124
Overall Steps per Second: 6,835.91583

Timestep Collection Time: 3.46092
Timestep Consumption Time: 3.85865
PPO Batch Consumption Time: 0.48757
Total Iteration Time: 7.31958

Cumulative Model Updates: 3,690
Cumulative Timesteps: 30,810,046

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 30810046...
Checkpoint 30810046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06649
Policy Entropy: 4.36324
Value Function Loss: 0.06090

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05444
Policy Update Magnitude: 0.79036
Value Function Update Magnitude: 0.46741

Collected Steps per Second: 14,307.08733
Overall Steps per Second: 6,776.11700

Timestep Collection Time: 3.49519
Timestep Consumption Time: 3.88455
PPO Batch Consumption Time: 0.48127
Total Iteration Time: 7.37974

Cumulative Model Updates: 3,696
Cumulative Timesteps: 30,860,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01910
Policy Entropy: 4.36081
Value Function Loss: 0.06148

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05247
Policy Update Magnitude: 0.80961
Value Function Update Magnitude: 0.45467

Collected Steps per Second: 14,318.72406
Overall Steps per Second: 6,718.27859

Timestep Collection Time: 3.49347
Timestep Consumption Time: 3.95219
PPO Batch Consumption Time: 0.49669
Total Iteration Time: 7.44566

Cumulative Model Updates: 3,702
Cumulative Timesteps: 30,910,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 30910074...
Checkpoint 30910074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05599
Policy Entropy: 4.36633
Value Function Loss: 0.07272

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04041
Policy Update Magnitude: 0.81515
Value Function Update Magnitude: 0.42587

Collected Steps per Second: 14,151.56560
Overall Steps per Second: 6,811.99838

Timestep Collection Time: 3.53431
Timestep Consumption Time: 3.80803
PPO Batch Consumption Time: 0.47926
Total Iteration Time: 7.34234

Cumulative Model Updates: 3,708
Cumulative Timesteps: 30,960,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07682
Policy Entropy: 4.36464
Value Function Loss: 0.08243

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05052
Policy Update Magnitude: 0.84708
Value Function Update Magnitude: 0.40762

Collected Steps per Second: 14,566.78028
Overall Steps per Second: 6,814.28730

Timestep Collection Time: 3.43329
Timestep Consumption Time: 3.90599
PPO Batch Consumption Time: 0.48090
Total Iteration Time: 7.33929

Cumulative Model Updates: 3,714
Cumulative Timesteps: 31,010,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 31010102...
Checkpoint 31010102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04106
Policy Entropy: 4.36312
Value Function Loss: 0.08982

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04950
Policy Update Magnitude: 0.88266
Value Function Update Magnitude: 0.42342

Collected Steps per Second: 14,463.44705
Overall Steps per Second: 6,919.43839

Timestep Collection Time: 3.45879
Timestep Consumption Time: 3.77099
PPO Batch Consumption Time: 0.47805
Total Iteration Time: 7.22978

Cumulative Model Updates: 3,720
Cumulative Timesteps: 31,060,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12368
Policy Entropy: 4.36095
Value Function Loss: 0.09252

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04970
Policy Update Magnitude: 0.88155
Value Function Update Magnitude: 0.40097

Collected Steps per Second: 14,271.46077
Overall Steps per Second: 6,791.23466

Timestep Collection Time: 3.50350
Timestep Consumption Time: 3.85894
PPO Batch Consumption Time: 0.47346
Total Iteration Time: 7.36243

Cumulative Model Updates: 3,726
Cumulative Timesteps: 31,110,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 31110128...
Checkpoint 31110128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00749
Policy Entropy: 4.37074
Value Function Loss: 0.08319

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04561
Policy Update Magnitude: 0.86090
Value Function Update Magnitude: 0.38177

Collected Steps per Second: 14,250.30228
Overall Steps per Second: 6,767.20779

Timestep Collection Time: 3.50870
Timestep Consumption Time: 3.87987
PPO Batch Consumption Time: 0.47769
Total Iteration Time: 7.38857

Cumulative Model Updates: 3,732
Cumulative Timesteps: 31,160,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07645
Policy Entropy: 4.37324
Value Function Loss: 0.07955

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04462
Policy Update Magnitude: 0.82195
Value Function Update Magnitude: 0.36137

Collected Steps per Second: 14,816.20068
Overall Steps per Second: 6,925.27020

Timestep Collection Time: 3.37482
Timestep Consumption Time: 3.84540
PPO Batch Consumption Time: 0.47387
Total Iteration Time: 7.22022

Cumulative Model Updates: 3,738
Cumulative Timesteps: 31,210,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 31210130...
Checkpoint 31210130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00526
Policy Entropy: 4.37559
Value Function Loss: 0.06819

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03699
Policy Update Magnitude: 0.78387
Value Function Update Magnitude: 0.38908

Collected Steps per Second: 14,319.80306
Overall Steps per Second: 6,735.82569

Timestep Collection Time: 3.49348
Timestep Consumption Time: 3.93337
PPO Batch Consumption Time: 0.47861
Total Iteration Time: 7.42685

Cumulative Model Updates: 3,744
Cumulative Timesteps: 31,260,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06972
Policy Entropy: 4.37082
Value Function Loss: 0.05707

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03685
Policy Update Magnitude: 0.74249
Value Function Update Magnitude: 0.39798

Collected Steps per Second: 14,264.98400
Overall Steps per Second: 6,826.24703

Timestep Collection Time: 3.50509
Timestep Consumption Time: 3.81958
PPO Batch Consumption Time: 0.46965
Total Iteration Time: 7.32467

Cumulative Model Updates: 3,750
Cumulative Timesteps: 31,310,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 31310156...
Checkpoint 31310156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10533
Policy Entropy: 4.37174
Value Function Loss: 0.06435

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03484
Policy Update Magnitude: 0.74454
Value Function Update Magnitude: 0.37074

Collected Steps per Second: 14,236.63347
Overall Steps per Second: 6,579.07899

Timestep Collection Time: 3.51333
Timestep Consumption Time: 4.08925
PPO Batch Consumption Time: 0.51123
Total Iteration Time: 7.60258

Cumulative Model Updates: 3,756
Cumulative Timesteps: 31,360,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05206
Policy Entropy: 4.36664
Value Function Loss: 0.07740

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03960
Policy Update Magnitude: 0.81067
Value Function Update Magnitude: 0.41758

Collected Steps per Second: 14,385.31520
Overall Steps per Second: 6,839.46394

Timestep Collection Time: 3.47744
Timestep Consumption Time: 3.83659
PPO Batch Consumption Time: 0.48183
Total Iteration Time: 7.31402

Cumulative Model Updates: 3,762
Cumulative Timesteps: 31,410,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 31410198...
Checkpoint 31410198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01609
Policy Entropy: 4.36456
Value Function Loss: 0.08005

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04454
Policy Update Magnitude: 0.85618
Value Function Update Magnitude: 0.38957

Collected Steps per Second: 14,312.88956
Overall Steps per Second: 6,776.44269

Timestep Collection Time: 3.49335
Timestep Consumption Time: 3.88515
PPO Batch Consumption Time: 0.47655
Total Iteration Time: 7.37850

Cumulative Model Updates: 3,768
Cumulative Timesteps: 31,460,198

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01814
Policy Entropy: 4.36006
Value Function Loss: 0.07911

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04232
Policy Update Magnitude: 0.83192
Value Function Update Magnitude: 0.30753

Collected Steps per Second: 14,331.64170
Overall Steps per Second: 6,719.13134

Timestep Collection Time: 3.48948
Timestep Consumption Time: 3.95344
PPO Batch Consumption Time: 0.48749
Total Iteration Time: 7.44293

Cumulative Model Updates: 3,774
Cumulative Timesteps: 31,510,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 31510208...
Checkpoint 31510208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01228
Policy Entropy: 4.36426
Value Function Loss: 0.06869

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04211
Policy Update Magnitude: 0.80827
Value Function Update Magnitude: 0.30141

Collected Steps per Second: 14,624.19315
Overall Steps per Second: 6,820.92609

Timestep Collection Time: 3.41981
Timestep Consumption Time: 3.91233
PPO Batch Consumption Time: 0.48273
Total Iteration Time: 7.33214

Cumulative Model Updates: 3,780
Cumulative Timesteps: 31,560,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03383
Policy Entropy: 4.36174
Value Function Loss: 0.07560

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04777
Policy Update Magnitude: 0.81068
Value Function Update Magnitude: 0.37144

Collected Steps per Second: 14,606.28654
Overall Steps per Second: 6,826.20306

Timestep Collection Time: 3.42537
Timestep Consumption Time: 3.90403
PPO Batch Consumption Time: 0.48340
Total Iteration Time: 7.32940

Cumulative Model Updates: 3,786
Cumulative Timesteps: 31,610,252

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 31610252...
Checkpoint 31610252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08862
Policy Entropy: 4.36636
Value Function Loss: 0.06223

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04257
Policy Update Magnitude: 0.79485
Value Function Update Magnitude: 0.36768

Collected Steps per Second: 14,213.76590
Overall Steps per Second: 6,794.99834

Timestep Collection Time: 3.51800
Timestep Consumption Time: 3.84094
PPO Batch Consumption Time: 0.48178
Total Iteration Time: 7.35894

Cumulative Model Updates: 3,792
Cumulative Timesteps: 31,660,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03165
Policy Entropy: 4.36399
Value Function Loss: 0.06636

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04035
Policy Update Magnitude: 0.77556
Value Function Update Magnitude: 0.35108

Collected Steps per Second: 14,497.15785
Overall Steps per Second: 6,763.81309

Timestep Collection Time: 3.44992
Timestep Consumption Time: 3.94443
PPO Batch Consumption Time: 0.48215
Total Iteration Time: 7.39435

Cumulative Model Updates: 3,798
Cumulative Timesteps: 31,710,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 31710270...
Checkpoint 31710270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08331
Policy Entropy: 4.36400
Value Function Loss: 0.06215

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03851
Policy Update Magnitude: 0.78130
Value Function Update Magnitude: 0.35876

Collected Steps per Second: 14,336.56875
Overall Steps per Second: 6,791.94650

Timestep Collection Time: 3.48954
Timestep Consumption Time: 3.87624
PPO Batch Consumption Time: 0.47387
Total Iteration Time: 7.36578

Cumulative Model Updates: 3,804
Cumulative Timesteps: 31,760,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08611
Policy Entropy: 4.36995
Value Function Loss: 0.06131

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04218
Policy Update Magnitude: 0.77637
Value Function Update Magnitude: 0.40223

Collected Steps per Second: 14,645.51229
Overall Steps per Second: 6,853.15036

Timestep Collection Time: 3.41538
Timestep Consumption Time: 3.88345
PPO Batch Consumption Time: 0.48157
Total Iteration Time: 7.29883

Cumulative Model Updates: 3,810
Cumulative Timesteps: 31,810,318

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 31810318...
Checkpoint 31810318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02887
Policy Entropy: 4.36996
Value Function Loss: 0.05771

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04005
Policy Update Magnitude: 0.76126
Value Function Update Magnitude: 0.41515

Collected Steps per Second: 14,395.87783
Overall Steps per Second: 6,760.11567

Timestep Collection Time: 3.47336
Timestep Consumption Time: 3.92326
PPO Batch Consumption Time: 0.48745
Total Iteration Time: 7.39662

Cumulative Model Updates: 3,816
Cumulative Timesteps: 31,860,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00408
Policy Entropy: 4.36310
Value Function Loss: 0.06480

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03799
Policy Update Magnitude: 0.77313
Value Function Update Magnitude: 0.44703

Collected Steps per Second: 14,595.65545
Overall Steps per Second: 6,883.35170

Timestep Collection Time: 3.42609
Timestep Consumption Time: 3.83869
PPO Batch Consumption Time: 0.47518
Total Iteration Time: 7.26477

Cumulative Model Updates: 3,822
Cumulative Timesteps: 31,910,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 31910326...
Checkpoint 31910326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01825
Policy Entropy: 4.36274
Value Function Loss: 0.06426

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04343
Policy Update Magnitude: 0.77727
Value Function Update Magnitude: 0.46125

Collected Steps per Second: 14,245.90948
Overall Steps per Second: 6,662.92557

Timestep Collection Time: 3.51020
Timestep Consumption Time: 3.99491
PPO Batch Consumption Time: 0.49533
Total Iteration Time: 7.50511

Cumulative Model Updates: 3,828
Cumulative Timesteps: 31,960,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06206
Policy Entropy: 4.36115
Value Function Loss: 0.05793

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04244
Policy Update Magnitude: 0.77933
Value Function Update Magnitude: 0.41079

Collected Steps per Second: 14,415.13562
Overall Steps per Second: 6,852.80499

Timestep Collection Time: 3.47066
Timestep Consumption Time: 3.83000
PPO Batch Consumption Time: 0.48014
Total Iteration Time: 7.30066

Cumulative Model Updates: 3,834
Cumulative Timesteps: 32,010,362

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 32010362...
Checkpoint 32010362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11330
Policy Entropy: 4.35477
Value Function Loss: 0.07253

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04281
Policy Update Magnitude: 0.82706
Value Function Update Magnitude: 0.42719

Collected Steps per Second: 14,131.25208
Overall Steps per Second: 6,651.55254

Timestep Collection Time: 3.53925
Timestep Consumption Time: 3.97990
PPO Batch Consumption Time: 0.48462
Total Iteration Time: 7.51915

Cumulative Model Updates: 3,840
Cumulative Timesteps: 32,060,376

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07796
Policy Entropy: 4.36110
Value Function Loss: 0.08257

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04343
Policy Update Magnitude: 0.85815
Value Function Update Magnitude: 0.45467

Collected Steps per Second: 14,341.56361
Overall Steps per Second: 6,769.30073

Timestep Collection Time: 3.48637
Timestep Consumption Time: 3.89992
PPO Batch Consumption Time: 0.48169
Total Iteration Time: 7.38629

Cumulative Model Updates: 3,846
Cumulative Timesteps: 32,110,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 32110376...
Checkpoint 32110376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03518
Policy Entropy: 4.35219
Value Function Loss: 0.08711

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04535
Policy Update Magnitude: 0.88504
Value Function Update Magnitude: 0.42110

Collected Steps per Second: 14,325.18960
Overall Steps per Second: 6,737.37706

Timestep Collection Time: 3.49036
Timestep Consumption Time: 3.93093
PPO Batch Consumption Time: 0.49960
Total Iteration Time: 7.42129

Cumulative Model Updates: 3,852
Cumulative Timesteps: 32,160,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08419
Policy Entropy: 4.35645
Value Function Loss: 0.06925

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04620
Policy Update Magnitude: 0.85312
Value Function Update Magnitude: 0.39957

Collected Steps per Second: 14,495.52880
Overall Steps per Second: 6,732.84938

Timestep Collection Time: 3.45141
Timestep Consumption Time: 3.97932
PPO Batch Consumption Time: 0.48960
Total Iteration Time: 7.43073

Cumulative Model Updates: 3,858
Cumulative Timesteps: 32,210,406

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 32210406...
Checkpoint 32210406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09199
Policy Entropy: 4.35753
Value Function Loss: 0.07078

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04528
Policy Update Magnitude: 0.83223
Value Function Update Magnitude: 0.40703

Collected Steps per Second: 14,248.14506
Overall Steps per Second: 6,789.04001

Timestep Collection Time: 3.50937
Timestep Consumption Time: 3.85574
PPO Batch Consumption Time: 0.48170
Total Iteration Time: 7.36511

Cumulative Model Updates: 3,864
Cumulative Timesteps: 32,260,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05677
Policy Entropy: 4.36278
Value Function Loss: 0.06658

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04468
Policy Update Magnitude: 0.81222
Value Function Update Magnitude: 0.38212

Collected Steps per Second: 14,447.96187
Overall Steps per Second: 6,810.69742

Timestep Collection Time: 3.46153
Timestep Consumption Time: 3.88163
PPO Batch Consumption Time: 0.47481
Total Iteration Time: 7.34315

Cumulative Model Updates: 3,870
Cumulative Timesteps: 32,310,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 32310420...
Checkpoint 32310420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06387
Policy Entropy: 4.35843
Value Function Loss: 0.08722

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05035
Policy Update Magnitude: 0.83096
Value Function Update Magnitude: 0.39407

Collected Steps per Second: 14,355.48060
Overall Steps per Second: 6,745.13447

Timestep Collection Time: 3.48355
Timestep Consumption Time: 3.93039
PPO Batch Consumption Time: 0.49114
Total Iteration Time: 7.41394

Cumulative Model Updates: 3,876
Cumulative Timesteps: 32,360,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00779
Policy Entropy: 4.35655
Value Function Loss: 0.08576

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04948
Policy Update Magnitude: 0.87252
Value Function Update Magnitude: 0.41605

Collected Steps per Second: 14,559.71496
Overall Steps per Second: 6,775.17397

Timestep Collection Time: 3.43716
Timestep Consumption Time: 3.94922
PPO Batch Consumption Time: 0.49143
Total Iteration Time: 7.38638

Cumulative Model Updates: 3,882
Cumulative Timesteps: 32,410,472

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 32410472...
Checkpoint 32410472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17936
Policy Entropy: 4.35515
Value Function Loss: 0.08445

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05092
Policy Update Magnitude: 0.86100
Value Function Update Magnitude: 0.39762

Collected Steps per Second: 14,112.23225
Overall Steps per Second: 6,696.13143

Timestep Collection Time: 3.54444
Timestep Consumption Time: 3.92554
PPO Batch Consumption Time: 0.47820
Total Iteration Time: 7.46998

Cumulative Model Updates: 3,888
Cumulative Timesteps: 32,460,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01829
Policy Entropy: 4.35004
Value Function Loss: 0.07632

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05058
Policy Update Magnitude: 0.83595
Value Function Update Magnitude: 0.38999

Collected Steps per Second: 14,420.87253
Overall Steps per Second: 6,872.07513

Timestep Collection Time: 3.46817
Timestep Consumption Time: 3.80969
PPO Batch Consumption Time: 0.47935
Total Iteration Time: 7.27786

Cumulative Model Updates: 3,894
Cumulative Timesteps: 32,510,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 32510506...
Checkpoint 32510506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04203
Policy Entropy: 4.34204
Value Function Loss: 0.07211

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05009
Policy Update Magnitude: 0.83041
Value Function Update Magnitude: 0.36277

Collected Steps per Second: 14,202.00363
Overall Steps per Second: 6,703.68454

Timestep Collection Time: 3.52176
Timestep Consumption Time: 3.93921
PPO Batch Consumption Time: 0.49007
Total Iteration Time: 7.46097

Cumulative Model Updates: 3,900
Cumulative Timesteps: 32,560,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04974
Policy Entropy: 4.33387
Value Function Loss: 0.08413

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04836
Policy Update Magnitude: 0.84337
Value Function Update Magnitude: 0.35764

Collected Steps per Second: 14,227.88854
Overall Steps per Second: 6,702.28119

Timestep Collection Time: 3.51507
Timestep Consumption Time: 3.94687
PPO Batch Consumption Time: 0.48435
Total Iteration Time: 7.46194

Cumulative Model Updates: 3,906
Cumulative Timesteps: 32,610,534

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 32610534...
Checkpoint 32610534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22397
Policy Entropy: 4.33752
Value Function Loss: 0.07929

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04619
Policy Update Magnitude: 0.86863
Value Function Update Magnitude: 0.37530

Collected Steps per Second: 14,445.04803
Overall Steps per Second: 6,739.88383

Timestep Collection Time: 3.46209
Timestep Consumption Time: 3.95792
PPO Batch Consumption Time: 0.48565
Total Iteration Time: 7.42001

Cumulative Model Updates: 3,912
Cumulative Timesteps: 32,660,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01272
Policy Entropy: 4.33413
Value Function Loss: 0.09252

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.04863
Policy Update Magnitude: 0.86417
Value Function Update Magnitude: 0.35485

Collected Steps per Second: 14,192.11149
Overall Steps per Second: 6,732.67599

Timestep Collection Time: 3.52407
Timestep Consumption Time: 3.90448
PPO Batch Consumption Time: 0.48279
Total Iteration Time: 7.42855

Cumulative Model Updates: 3,918
Cumulative Timesteps: 32,710,558

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 32710558...
Checkpoint 32710558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07841
Policy Entropy: 4.33820
Value Function Loss: 0.07664

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.04659
Policy Update Magnitude: 0.87836
Value Function Update Magnitude: 0.34502

Collected Steps per Second: 14,312.59915
Overall Steps per Second: 6,842.30488

Timestep Collection Time: 3.49538
Timestep Consumption Time: 3.81619
PPO Batch Consumption Time: 0.47673
Total Iteration Time: 7.31157

Cumulative Model Updates: 3,924
Cumulative Timesteps: 32,760,586

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08149
Policy Entropy: 4.32771
Value Function Loss: 0.08575

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05467
Policy Update Magnitude: 0.84395
Value Function Update Magnitude: 0.34367

Collected Steps per Second: 14,355.83753
Overall Steps per Second: 6,769.25794

Timestep Collection Time: 3.48527
Timestep Consumption Time: 3.90608
PPO Batch Consumption Time: 0.48010
Total Iteration Time: 7.39136

Cumulative Model Updates: 3,930
Cumulative Timesteps: 32,810,620

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 32810620...
Checkpoint 32810620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18255
Policy Entropy: 4.33287
Value Function Loss: 0.08237

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.04969
Policy Update Magnitude: 0.84154
Value Function Update Magnitude: 0.31906

Collected Steps per Second: 14,185.37537
Overall Steps per Second: 6,718.77592

Timestep Collection Time: 3.52504
Timestep Consumption Time: 3.91739
PPO Batch Consumption Time: 0.49001
Total Iteration Time: 7.44243

Cumulative Model Updates: 3,936
Cumulative Timesteps: 32,860,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02579
Policy Entropy: 4.33072
Value Function Loss: 0.09243

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05726
Policy Update Magnitude: 0.84760
Value Function Update Magnitude: 0.27467

Collected Steps per Second: 14,765.92879
Overall Steps per Second: 6,910.28951

Timestep Collection Time: 3.38699
Timestep Consumption Time: 3.85034
PPO Batch Consumption Time: 0.47705
Total Iteration Time: 7.23732

Cumulative Model Updates: 3,942
Cumulative Timesteps: 32,910,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 32910636...
Checkpoint 32910636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00885
Policy Entropy: 4.33107
Value Function Loss: 0.09419

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06743
Policy Update Magnitude: 0.88009
Value Function Update Magnitude: 0.31658

Collected Steps per Second: 14,246.93009
Overall Steps per Second: 6,760.33381

Timestep Collection Time: 3.51023
Timestep Consumption Time: 3.88733
PPO Batch Consumption Time: 0.47802
Total Iteration Time: 7.39756

Cumulative Model Updates: 3,948
Cumulative Timesteps: 32,960,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03589
Policy Entropy: 4.33152
Value Function Loss: 0.10705

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.90598
Value Function Update Magnitude: 0.31885

Collected Steps per Second: 14,490.74372
Overall Steps per Second: 6,819.48674

Timestep Collection Time: 3.45103
Timestep Consumption Time: 3.88207
PPO Batch Consumption Time: 0.49548
Total Iteration Time: 7.33310

Cumulative Model Updates: 3,954
Cumulative Timesteps: 33,010,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 33010654...
Checkpoint 33010654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07164
Policy Entropy: 4.33787
Value Function Loss: 0.10535

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.90719
Value Function Update Magnitude: 0.30745

Collected Steps per Second: 14,228.78128
Overall Steps per Second: 6,695.61577

Timestep Collection Time: 3.51541
Timestep Consumption Time: 3.95515
PPO Batch Consumption Time: 0.48910
Total Iteration Time: 7.47056

Cumulative Model Updates: 3,960
Cumulative Timesteps: 33,060,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03390
Policy Entropy: 4.34404
Value Function Loss: 0.10060

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.87569
Value Function Update Magnitude: 0.30261

Collected Steps per Second: 14,425.16299
Overall Steps per Second: 6,805.50297

Timestep Collection Time: 3.46783
Timestep Consumption Time: 3.88269
PPO Batch Consumption Time: 0.47875
Total Iteration Time: 7.35052

Cumulative Model Updates: 3,966
Cumulative Timesteps: 33,110,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 33110698...
Checkpoint 33110698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03545
Policy Entropy: 4.35228
Value Function Loss: 0.08747

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05520
Policy Update Magnitude: 0.83407
Value Function Update Magnitude: 0.33486

Collected Steps per Second: 14,422.14604
Overall Steps per Second: 6,842.19235

Timestep Collection Time: 3.46703
Timestep Consumption Time: 3.84086
PPO Batch Consumption Time: 0.47624
Total Iteration Time: 7.30789

Cumulative Model Updates: 3,972
Cumulative Timesteps: 33,160,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13111
Policy Entropy: 4.34803
Value Function Loss: 0.09051

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05264
Policy Update Magnitude: 0.81588
Value Function Update Magnitude: 0.31842

Collected Steps per Second: 14,568.10847
Overall Steps per Second: 6,797.67085

Timestep Collection Time: 3.43380
Timestep Consumption Time: 3.92519
PPO Batch Consumption Time: 0.47975
Total Iteration Time: 7.35899

Cumulative Model Updates: 3,978
Cumulative Timesteps: 33,210,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 33210724...
Checkpoint 33210724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03721
Policy Entropy: 4.34821
Value Function Loss: 0.09249

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03991
Policy Update Magnitude: 0.83656
Value Function Update Magnitude: 0.32684

Collected Steps per Second: 14,080.53459
Overall Steps per Second: 6,714.04043

Timestep Collection Time: 3.55157
Timestep Consumption Time: 3.89670
PPO Batch Consumption Time: 0.48042
Total Iteration Time: 7.44827

Cumulative Model Updates: 3,984
Cumulative Timesteps: 33,260,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02618
Policy Entropy: 4.34957
Value Function Loss: 0.08707

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.03987
Policy Update Magnitude: 0.82261
Value Function Update Magnitude: 0.32426

Collected Steps per Second: 14,310.29266
Overall Steps per Second: 6,797.12178

Timestep Collection Time: 3.49413
Timestep Consumption Time: 3.86222
PPO Batch Consumption Time: 0.47479
Total Iteration Time: 7.35635

Cumulative Model Updates: 3,990
Cumulative Timesteps: 33,310,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 33310734...
Checkpoint 33310734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02333
Policy Entropy: 4.35028
Value Function Loss: 0.08237

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04103
Policy Update Magnitude: 0.77994
Value Function Update Magnitude: 0.29315

Collected Steps per Second: 14,312.44531
Overall Steps per Second: 6,738.80278

Timestep Collection Time: 3.49444
Timestep Consumption Time: 3.92735
PPO Batch Consumption Time: 0.49075
Total Iteration Time: 7.42179

Cumulative Model Updates: 3,996
Cumulative Timesteps: 33,360,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07498
Policy Entropy: 4.34954
Value Function Loss: 0.07032

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04122
Policy Update Magnitude: 0.73113
Value Function Update Magnitude: 0.22199

Collected Steps per Second: 14,837.35881
Overall Steps per Second: 7,002.83192

Timestep Collection Time: 3.36987
Timestep Consumption Time: 3.77010
PPO Batch Consumption Time: 0.46443
Total Iteration Time: 7.13997

Cumulative Model Updates: 4,002
Cumulative Timesteps: 33,410,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 33410748...
Checkpoint 33410748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01211
Policy Entropy: 4.34470
Value Function Loss: 0.07731

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04213
Policy Update Magnitude: 0.72889
Value Function Update Magnitude: 0.19045

Collected Steps per Second: 13,939.89734
Overall Steps per Second: 6,619.25370

Timestep Collection Time: 3.58783
Timestep Consumption Time: 3.96801
PPO Batch Consumption Time: 0.49306
Total Iteration Time: 7.55584

Cumulative Model Updates: 4,008
Cumulative Timesteps: 33,460,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08338
Policy Entropy: 4.34148
Value Function Loss: 0.08229

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04660
Policy Update Magnitude: 0.75340
Value Function Update Magnitude: 0.17276

Collected Steps per Second: 14,405.79881
Overall Steps per Second: 6,826.05415

Timestep Collection Time: 3.47277
Timestep Consumption Time: 3.85621
PPO Batch Consumption Time: 0.48127
Total Iteration Time: 7.32898

Cumulative Model Updates: 4,014
Cumulative Timesteps: 33,510,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 33510790...
Checkpoint 33510790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00313
Policy Entropy: 4.33828
Value Function Loss: 0.09800

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04869
Policy Update Magnitude: 0.78898
Value Function Update Magnitude: 0.21897

Collected Steps per Second: 14,184.29821
Overall Steps per Second: 6,727.75573

Timestep Collection Time: 3.52643
Timestep Consumption Time: 3.90844
PPO Batch Consumption Time: 0.48045
Total Iteration Time: 7.43487

Cumulative Model Updates: 4,020
Cumulative Timesteps: 33,560,810

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00043
Policy Entropy: 4.33616
Value Function Loss: 0.09919

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05014
Policy Update Magnitude: 0.83205
Value Function Update Magnitude: 0.25248

Collected Steps per Second: 14,546.36272
Overall Steps per Second: 6,807.08477

Timestep Collection Time: 3.43866
Timestep Consumption Time: 3.90957
PPO Batch Consumption Time: 0.48514
Total Iteration Time: 7.34823

Cumulative Model Updates: 4,026
Cumulative Timesteps: 33,610,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 33610830...
Checkpoint 33610830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04349
Policy Entropy: 4.33476
Value Function Loss: 0.09711

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05408
Policy Update Magnitude: 0.85208
Value Function Update Magnitude: 0.27177

Collected Steps per Second: 14,379.14331
Overall Steps per Second: 6,730.15884

Timestep Collection Time: 3.47754
Timestep Consumption Time: 3.95230
PPO Batch Consumption Time: 0.49038
Total Iteration Time: 7.42984

Cumulative Model Updates: 4,032
Cumulative Timesteps: 33,660,834

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05100
Policy Entropy: 4.33905
Value Function Loss: 0.08008

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04498
Policy Update Magnitude: 0.81529
Value Function Update Magnitude: 0.25493

Collected Steps per Second: 14,414.63976
Overall Steps per Second: 6,794.23997

Timestep Collection Time: 3.47022
Timestep Consumption Time: 3.89219
PPO Batch Consumption Time: 0.47216
Total Iteration Time: 7.36241

Cumulative Model Updates: 4,038
Cumulative Timesteps: 33,710,856

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 33710856...
Checkpoint 33710856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03859
Policy Entropy: 4.33964
Value Function Loss: 0.07311

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04565
Policy Update Magnitude: 0.79253
Value Function Update Magnitude: 0.23249

Collected Steps per Second: 14,246.62529
Overall Steps per Second: 6,905.71249

Timestep Collection Time: 3.51030
Timestep Consumption Time: 3.73153
PPO Batch Consumption Time: 0.46919
Total Iteration Time: 7.24183

Cumulative Model Updates: 4,044
Cumulative Timesteps: 33,760,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22801
Policy Entropy: 4.34323
Value Function Loss: 0.07368

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04552
Policy Update Magnitude: 0.77563
Value Function Update Magnitude: 0.22292

Collected Steps per Second: 14,383.79529
Overall Steps per Second: 6,717.06601

Timestep Collection Time: 3.47794
Timestep Consumption Time: 3.96966
PPO Batch Consumption Time: 0.48674
Total Iteration Time: 7.44760

Cumulative Model Updates: 4,050
Cumulative Timesteps: 33,810,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 33810892...
Checkpoint 33810892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04050
Policy Entropy: 4.34060
Value Function Loss: 0.08019

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04578
Policy Update Magnitude: 0.76946
Value Function Update Magnitude: 0.21622

Collected Steps per Second: 14,358.77327
Overall Steps per Second: 6,713.35207

Timestep Collection Time: 3.48358
Timestep Consumption Time: 3.96724
PPO Batch Consumption Time: 0.50656
Total Iteration Time: 7.45082

Cumulative Model Updates: 4,056
Cumulative Timesteps: 33,860,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11290
Policy Entropy: 4.33539
Value Function Loss: 0.09415

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04407
Policy Update Magnitude: 0.80554
Value Function Update Magnitude: 0.24598

Collected Steps per Second: 14,259.86547
Overall Steps per Second: 6,766.80909

Timestep Collection Time: 3.50859
Timestep Consumption Time: 3.88515
PPO Batch Consumption Time: 0.48495
Total Iteration Time: 7.39374

Cumulative Model Updates: 4,062
Cumulative Timesteps: 33,910,944

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 33910944...
Checkpoint 33910944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02943
Policy Entropy: 4.33391
Value Function Loss: 0.08821

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04971
Policy Update Magnitude: 0.83555
Value Function Update Magnitude: 0.27127

Collected Steps per Second: 14,379.48913
Overall Steps per Second: 6,803.76284

Timestep Collection Time: 3.47815
Timestep Consumption Time: 3.87278
PPO Batch Consumption Time: 0.47791
Total Iteration Time: 7.35093

Cumulative Model Updates: 4,068
Cumulative Timesteps: 33,960,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03868
Policy Entropy: 4.32826
Value Function Loss: 0.08401

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05203
Policy Update Magnitude: 0.80464
Value Function Update Magnitude: 0.27286

Collected Steps per Second: 14,566.42899
Overall Steps per Second: 6,788.48459

Timestep Collection Time: 3.43351
Timestep Consumption Time: 3.93396
PPO Batch Consumption Time: 0.48960
Total Iteration Time: 7.36748

Cumulative Model Updates: 4,074
Cumulative Timesteps: 34,010,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 34010972...
Checkpoint 34010972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18027
Policy Entropy: 4.32706
Value Function Loss: 0.07796

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04873
Policy Update Magnitude: 0.77786
Value Function Update Magnitude: 0.32824

Collected Steps per Second: 14,161.13427
Overall Steps per Second: 6,726.24866

Timestep Collection Time: 3.53206
Timestep Consumption Time: 3.90418
PPO Batch Consumption Time: 0.47698
Total Iteration Time: 7.43624

Cumulative Model Updates: 4,080
Cumulative Timesteps: 34,060,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16917
Policy Entropy: 4.32140
Value Function Loss: 0.10115

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05505
Policy Update Magnitude: 0.81319
Value Function Update Magnitude: 0.38850

Collected Steps per Second: 14,636.79894
Overall Steps per Second: 6,774.51189

Timestep Collection Time: 3.41810
Timestep Consumption Time: 3.96694
PPO Batch Consumption Time: 0.48980
Total Iteration Time: 7.38503

Cumulative Model Updates: 4,086
Cumulative Timesteps: 34,111,020

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 34111020...
Checkpoint 34111020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04709
Policy Entropy: 4.32611
Value Function Loss: 0.10645

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04946
Policy Update Magnitude: 0.83965
Value Function Update Magnitude: 0.33430

Collected Steps per Second: 14,349.16087
Overall Steps per Second: 6,779.66680

Timestep Collection Time: 3.48759
Timestep Consumption Time: 3.89389
PPO Batch Consumption Time: 0.47788
Total Iteration Time: 7.38148

Cumulative Model Updates: 4,092
Cumulative Timesteps: 34,161,064

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00498
Policy Entropy: 4.32784
Value Function Loss: 0.09606

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04200
Policy Update Magnitude: 0.81691
Value Function Update Magnitude: 0.35237

Collected Steps per Second: 14,920.58824
Overall Steps per Second: 6,872.41530

Timestep Collection Time: 3.35228
Timestep Consumption Time: 3.92580
PPO Batch Consumption Time: 0.48383
Total Iteration Time: 7.27808

Cumulative Model Updates: 4,098
Cumulative Timesteps: 34,211,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 34211082...
Checkpoint 34211082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02343
Policy Entropy: 4.33456
Value Function Loss: 0.07845

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04649
Policy Update Magnitude: 0.78102
Value Function Update Magnitude: 0.35610

Collected Steps per Second: 14,342.16849
Overall Steps per Second: 6,719.94533

Timestep Collection Time: 3.48804
Timestep Consumption Time: 3.95637
PPO Batch Consumption Time: 0.48825
Total Iteration Time: 7.44441

Cumulative Model Updates: 4,104
Cumulative Timesteps: 34,261,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04992
Policy Entropy: 4.33284
Value Function Loss: 0.08091

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05070
Policy Update Magnitude: 0.74516
Value Function Update Magnitude: 0.33989

Collected Steps per Second: 14,377.28368
Overall Steps per Second: 6,686.70440

Timestep Collection Time: 3.47799
Timestep Consumption Time: 4.00014
PPO Batch Consumption Time: 0.50410
Total Iteration Time: 7.47812

Cumulative Model Updates: 4,110
Cumulative Timesteps: 34,311,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 34311112...
Checkpoint 34311112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21719
Policy Entropy: 4.33088
Value Function Loss: 0.08432

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04845
Policy Update Magnitude: 0.77730
Value Function Update Magnitude: 0.44381

Collected Steps per Second: 14,284.22110
Overall Steps per Second: 6,720.75365

Timestep Collection Time: 3.50163
Timestep Consumption Time: 3.94069
PPO Batch Consumption Time: 0.48938
Total Iteration Time: 7.44232

Cumulative Model Updates: 4,116
Cumulative Timesteps: 34,361,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07239
Policy Entropy: 4.32351
Value Function Loss: 0.08810

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04831
Policy Update Magnitude: 0.79322
Value Function Update Magnitude: 0.50907

Collected Steps per Second: 14,383.13604
Overall Steps per Second: 6,810.20642

Timestep Collection Time: 3.47727
Timestep Consumption Time: 3.86671
PPO Batch Consumption Time: 0.47642
Total Iteration Time: 7.34398

Cumulative Model Updates: 4,122
Cumulative Timesteps: 34,411,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 34411144...
Checkpoint 34411144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19338
Policy Entropy: 4.31668
Value Function Loss: 0.09984

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06261
Policy Update Magnitude: 0.81250
Value Function Update Magnitude: 0.48322

Collected Steps per Second: 14,086.21081
Overall Steps per Second: 6,839.76162

Timestep Collection Time: 3.54971
Timestep Consumption Time: 3.76078
PPO Batch Consumption Time: 0.47578
Total Iteration Time: 7.31049

Cumulative Model Updates: 4,128
Cumulative Timesteps: 34,461,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06606
Policy Entropy: 4.32117
Value Function Loss: 0.10269

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05403
Policy Update Magnitude: 0.83945
Value Function Update Magnitude: 0.48989

Collected Steps per Second: 14,450.17381
Overall Steps per Second: 6,860.73736

Timestep Collection Time: 3.46030
Timestep Consumption Time: 3.82783
PPO Batch Consumption Time: 0.46538
Total Iteration Time: 7.28814

Cumulative Model Updates: 4,134
Cumulative Timesteps: 34,511,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 34511148...
Checkpoint 34511148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01169
Policy Entropy: 4.32030
Value Function Loss: 0.11583

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06310
Policy Update Magnitude: 0.84279
Value Function Update Magnitude: 0.41009

Collected Steps per Second: 14,310.36816
Overall Steps per Second: 6,838.58373

Timestep Collection Time: 3.49467
Timestep Consumption Time: 3.81825
PPO Batch Consumption Time: 0.47870
Total Iteration Time: 7.31292

Cumulative Model Updates: 4,140
Cumulative Timesteps: 34,561,158

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10315
Policy Entropy: 4.32227
Value Function Loss: 0.11459

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05652
Policy Update Magnitude: 0.83502
Value Function Update Magnitude: 0.39527

Collected Steps per Second: 14,475.31455
Overall Steps per Second: 6,804.79442

Timestep Collection Time: 3.45609
Timestep Consumption Time: 3.89578
PPO Batch Consumption Time: 0.47491
Total Iteration Time: 7.35188

Cumulative Model Updates: 4,146
Cumulative Timesteps: 34,611,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 34611186...
Checkpoint 34611186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07441
Policy Entropy: 4.31210
Value Function Loss: 0.12194

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06189
Policy Update Magnitude: 0.84710
Value Function Update Magnitude: 0.39890

Collected Steps per Second: 14,262.84837
Overall Steps per Second: 6,750.78676

Timestep Collection Time: 3.50715
Timestep Consumption Time: 3.90265
PPO Batch Consumption Time: 0.47915
Total Iteration Time: 7.40980

Cumulative Model Updates: 4,152
Cumulative Timesteps: 34,661,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09779
Policy Entropy: 4.31367
Value Function Loss: 0.12432

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05994
Policy Update Magnitude: 0.86893
Value Function Update Magnitude: 0.41920

Collected Steps per Second: 14,715.33436
Overall Steps per Second: 6,855.25808

Timestep Collection Time: 3.39890
Timestep Consumption Time: 3.89710
PPO Batch Consumption Time: 0.48357
Total Iteration Time: 7.29601

Cumulative Model Updates: 4,158
Cumulative Timesteps: 34,711,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 34711224...
Checkpoint 34711224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10247
Policy Entropy: 4.32096
Value Function Loss: 0.11744

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06229
Policy Update Magnitude: 0.86806
Value Function Update Magnitude: 0.48308

Collected Steps per Second: 14,245.31165
Overall Steps per Second: 6,798.11390

Timestep Collection Time: 3.51091
Timestep Consumption Time: 3.84613
PPO Batch Consumption Time: 0.47395
Total Iteration Time: 7.35704

Cumulative Model Updates: 4,164
Cumulative Timesteps: 34,761,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12909
Policy Entropy: 4.32451
Value Function Loss: 0.09925

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05473
Policy Update Magnitude: 0.81822
Value Function Update Magnitude: 0.46749

Collected Steps per Second: 14,260.91963
Overall Steps per Second: 6,845.31091

Timestep Collection Time: 3.50721
Timestep Consumption Time: 3.79940
PPO Batch Consumption Time: 0.47355
Total Iteration Time: 7.30661

Cumulative Model Updates: 4,170
Cumulative Timesteps: 34,811,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 34811254...
Checkpoint 34811254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04257
Policy Entropy: 4.32146
Value Function Loss: 0.10040

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05424
Policy Update Magnitude: 0.78957
Value Function Update Magnitude: 0.45281

Collected Steps per Second: 14,430.93118
Overall Steps per Second: 6,897.96154

Timestep Collection Time: 3.46603
Timestep Consumption Time: 3.78510
PPO Batch Consumption Time: 0.46562
Total Iteration Time: 7.25113

Cumulative Model Updates: 4,176
Cumulative Timesteps: 34,861,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01800
Policy Entropy: 4.31810
Value Function Loss: 0.10594

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.04914
Policy Update Magnitude: 0.79993
Value Function Update Magnitude: 0.49785

Collected Steps per Second: 14,483.94909
Overall Steps per Second: 6,793.89225

Timestep Collection Time: 3.45375
Timestep Consumption Time: 3.90933
PPO Batch Consumption Time: 0.48792
Total Iteration Time: 7.36308

Cumulative Model Updates: 4,182
Cumulative Timesteps: 34,911,296

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 34911296...
Checkpoint 34911296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04609
Policy Entropy: 4.30779
Value Function Loss: 0.10048

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05176
Policy Update Magnitude: 0.80219
Value Function Update Magnitude: 0.55357

Collected Steps per Second: 14,513.74893
Overall Steps per Second: 6,891.26672

Timestep Collection Time: 3.44611
Timestep Consumption Time: 3.81177
PPO Batch Consumption Time: 0.47292
Total Iteration Time: 7.25788

Cumulative Model Updates: 4,188
Cumulative Timesteps: 34,961,312

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02411
Policy Entropy: 4.30485
Value Function Loss: 0.08656

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04894
Policy Update Magnitude: 0.75772
Value Function Update Magnitude: 0.54834

Collected Steps per Second: 14,412.49627
Overall Steps per Second: 6,770.21035

Timestep Collection Time: 3.47032
Timestep Consumption Time: 3.91734
PPO Batch Consumption Time: 0.47850
Total Iteration Time: 7.38766

Cumulative Model Updates: 4,194
Cumulative Timesteps: 35,011,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 35011328...
Checkpoint 35011328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07580
Policy Entropy: 4.30687
Value Function Loss: 0.07112

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.04987
Policy Update Magnitude: 0.72708
Value Function Update Magnitude: 0.47305

Collected Steps per Second: 14,494.17553
Overall Steps per Second: 6,935.71045

Timestep Collection Time: 3.45118
Timestep Consumption Time: 3.76106
PPO Batch Consumption Time: 0.47261
Total Iteration Time: 7.21224

Cumulative Model Updates: 4,200
Cumulative Timesteps: 35,061,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06982
Policy Entropy: 4.30946
Value Function Loss: 0.07520

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.04782
Policy Update Magnitude: 0.70748
Value Function Update Magnitude: 0.45108

Collected Steps per Second: 14,577.76987
Overall Steps per Second: 6,811.62825

Timestep Collection Time: 3.43304
Timestep Consumption Time: 3.91411
PPO Batch Consumption Time: 0.48144
Total Iteration Time: 7.34714

Cumulative Model Updates: 4,206
Cumulative Timesteps: 35,111,396

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 35111396...
Checkpoint 35111396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17427
Policy Entropy: 4.31178
Value Function Loss: 0.07827

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.04939
Policy Update Magnitude: 0.72616
Value Function Update Magnitude: 0.50285

Collected Steps per Second: 14,379.90430
Overall Steps per Second: 6,792.06060

Timestep Collection Time: 3.47707
Timestep Consumption Time: 3.88446
PPO Batch Consumption Time: 0.49078
Total Iteration Time: 7.36154

Cumulative Model Updates: 4,212
Cumulative Timesteps: 35,161,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02953
Policy Entropy: 4.31404
Value Function Loss: 0.08537

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05074
Policy Update Magnitude: 0.73124
Value Function Update Magnitude: 0.52338

Collected Steps per Second: 14,342.92699
Overall Steps per Second: 6,729.27195

Timestep Collection Time: 3.48604
Timestep Consumption Time: 3.94419
PPO Batch Consumption Time: 0.48997
Total Iteration Time: 7.43022

Cumulative Model Updates: 4,218
Cumulative Timesteps: 35,211,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 35211396...
Checkpoint 35211396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08354
Policy Entropy: 4.31866
Value Function Loss: 0.08938

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05168
Policy Update Magnitude: 0.74361
Value Function Update Magnitude: 0.52799

Collected Steps per Second: 14,174.95539
Overall Steps per Second: 6,749.83174

Timestep Collection Time: 3.52876
Timestep Consumption Time: 3.88180
PPO Batch Consumption Time: 0.48300
Total Iteration Time: 7.41056

Cumulative Model Updates: 4,224
Cumulative Timesteps: 35,261,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02793
Policy Entropy: 4.32984
Value Function Loss: 0.07459

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05173
Policy Update Magnitude: 0.72360
Value Function Update Magnitude: 0.47855

Collected Steps per Second: 14,519.91639
Overall Steps per Second: 6,851.75730

Timestep Collection Time: 3.44355
Timestep Consumption Time: 3.85385
PPO Batch Consumption Time: 0.48206
Total Iteration Time: 7.29740

Cumulative Model Updates: 4,230
Cumulative Timesteps: 35,311,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 35311416...
Checkpoint 35311416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06487
Policy Entropy: 4.32397
Value Function Loss: 0.08699

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04640
Policy Update Magnitude: 0.70127
Value Function Update Magnitude: 0.43098

Collected Steps per Second: 14,165.29163
Overall Steps per Second: 6,788.14230

Timestep Collection Time: 3.53074
Timestep Consumption Time: 3.83711
PPO Batch Consumption Time: 0.46901
Total Iteration Time: 7.36785

Cumulative Model Updates: 4,236
Cumulative Timesteps: 35,361,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.29511
Policy Entropy: 4.31700
Value Function Loss: 0.09495

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04852
Policy Update Magnitude: 0.75502
Value Function Update Magnitude: 0.46724

Collected Steps per Second: 14,481.69114
Overall Steps per Second: 6,904.42175

Timestep Collection Time: 3.45429
Timestep Consumption Time: 3.79092
PPO Batch Consumption Time: 0.48021
Total Iteration Time: 7.24521

Cumulative Model Updates: 4,242
Cumulative Timesteps: 35,411,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 35411454...
Checkpoint 35411454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18988
Policy Entropy: 4.31988
Value Function Loss: 0.09499

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04838
Policy Update Magnitude: 0.75708
Value Function Update Magnitude: 0.44337

Collected Steps per Second: 14,286.69775
Overall Steps per Second: 6,739.66783

Timestep Collection Time: 3.50074
Timestep Consumption Time: 3.92010
PPO Batch Consumption Time: 0.48007
Total Iteration Time: 7.42084

Cumulative Model Updates: 4,248
Cumulative Timesteps: 35,461,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02572
Policy Entropy: 4.32009
Value Function Loss: 0.08929

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04107
Policy Update Magnitude: 0.74024
Value Function Update Magnitude: 0.48957

Collected Steps per Second: 14,443.12536
Overall Steps per Second: 6,771.48815

Timestep Collection Time: 3.46241
Timestep Consumption Time: 3.92267
PPO Batch Consumption Time: 0.48281
Total Iteration Time: 7.38508

Cumulative Model Updates: 4,254
Cumulative Timesteps: 35,511,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 35511476...
Checkpoint 35511476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09957
Policy Entropy: 4.31241
Value Function Loss: 0.07760

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04510
Policy Update Magnitude: 0.70886
Value Function Update Magnitude: 0.44236

Collected Steps per Second: 14,700.40085
Overall Steps per Second: 6,843.39714

Timestep Collection Time: 3.40208
Timestep Consumption Time: 3.90598
PPO Batch Consumption Time: 0.47827
Total Iteration Time: 7.30807

Cumulative Model Updates: 4,260
Cumulative Timesteps: 35,561,488

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13011
Policy Entropy: 4.31391
Value Function Loss: 0.07633

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04122
Policy Update Magnitude: 0.66661
Value Function Update Magnitude: 0.41717

Collected Steps per Second: 14,356.84178
Overall Steps per Second: 6,734.37736

Timestep Collection Time: 3.48489
Timestep Consumption Time: 3.94445
PPO Batch Consumption Time: 0.48845
Total Iteration Time: 7.42934

Cumulative Model Updates: 4,266
Cumulative Timesteps: 35,611,520

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 35611520...
Checkpoint 35611520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01332
Policy Entropy: 4.30871
Value Function Loss: 0.09104

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04640
Policy Update Magnitude: 0.68303
Value Function Update Magnitude: 0.44319

Collected Steps per Second: 14,301.22514
Overall Steps per Second: 6,915.16203

Timestep Collection Time: 3.49718
Timestep Consumption Time: 3.73533
PPO Batch Consumption Time: 0.46703
Total Iteration Time: 7.23251

Cumulative Model Updates: 4,272
Cumulative Timesteps: 35,661,534

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06892
Policy Entropy: 4.30945
Value Function Loss: 0.08904

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05105
Policy Update Magnitude: 0.72268
Value Function Update Magnitude: 0.48613

Collected Steps per Second: 14,323.62925
Overall Steps per Second: 6,747.67183

Timestep Collection Time: 3.49157
Timestep Consumption Time: 3.92017
PPO Batch Consumption Time: 0.47677
Total Iteration Time: 7.41174

Cumulative Model Updates: 4,278
Cumulative Timesteps: 35,711,546

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 35711546...
Checkpoint 35711546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09536
Policy Entropy: 4.30829
Value Function Loss: 0.09515

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05461
Policy Update Magnitude: 0.70258
Value Function Update Magnitude: 0.46389

Collected Steps per Second: 14,276.87021
Overall Steps per Second: 6,885.38725

Timestep Collection Time: 3.50259
Timestep Consumption Time: 3.76004
PPO Batch Consumption Time: 0.47625
Total Iteration Time: 7.26263

Cumulative Model Updates: 4,284
Cumulative Timesteps: 35,761,552

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10497
Policy Entropy: 4.30654
Value Function Loss: 0.09034

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05036
Policy Update Magnitude: 0.68414
Value Function Update Magnitude: 0.43287

Collected Steps per Second: 14,432.02997
Overall Steps per Second: 6,804.67437

Timestep Collection Time: 3.46729
Timestep Consumption Time: 3.88648
PPO Batch Consumption Time: 0.47574
Total Iteration Time: 7.35377

Cumulative Model Updates: 4,290
Cumulative Timesteps: 35,811,592

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 35811592...
Checkpoint 35811592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00020
Policy Entropy: 4.30462
Value Function Loss: 0.09746

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.04760
Policy Update Magnitude: 0.70889
Value Function Update Magnitude: 0.51454

Collected Steps per Second: 14,204.24532
Overall Steps per Second: 6,763.22563

Timestep Collection Time: 3.52120
Timestep Consumption Time: 3.87409
PPO Batch Consumption Time: 0.47294
Total Iteration Time: 7.39529

Cumulative Model Updates: 4,296
Cumulative Timesteps: 35,861,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07299
Policy Entropy: 4.29955
Value Function Loss: 0.11186

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04945
Policy Update Magnitude: 0.75958
Value Function Update Magnitude: 0.52066

Collected Steps per Second: 14,405.57178
Overall Steps per Second: 6,925.85455

Timestep Collection Time: 3.47310
Timestep Consumption Time: 3.75085
PPO Batch Consumption Time: 0.47285
Total Iteration Time: 7.22395

Cumulative Model Updates: 4,302
Cumulative Timesteps: 35,911,640

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 35911640...
Checkpoint 35911640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14232
Policy Entropy: 4.29044
Value Function Loss: 0.12365

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05699
Policy Update Magnitude: 0.79798
Value Function Update Magnitude: 0.47832

Collected Steps per Second: 14,317.69423
Overall Steps per Second: 6,741.00406

Timestep Collection Time: 3.49344
Timestep Consumption Time: 3.92652
PPO Batch Consumption Time: 0.48135
Total Iteration Time: 7.41996

Cumulative Model Updates: 4,308
Cumulative Timesteps: 35,961,658

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07515
Policy Entropy: 4.28854
Value Function Loss: 0.12049

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.06855
Policy Update Magnitude: 0.81857
Value Function Update Magnitude: 0.57236

Collected Steps per Second: 14,494.76670
Overall Steps per Second: 6,825.19646

Timestep Collection Time: 3.45062
Timestep Consumption Time: 3.87752
PPO Batch Consumption Time: 0.49117
Total Iteration Time: 7.32814

Cumulative Model Updates: 4,314
Cumulative Timesteps: 36,011,674

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 36011674...
Checkpoint 36011674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11731
Policy Entropy: 4.29114
Value Function Loss: 0.10013

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.05782
Policy Update Magnitude: 0.77731
Value Function Update Magnitude: 0.54907

Collected Steps per Second: 14,385.95042
Overall Steps per Second: 6,806.85317

Timestep Collection Time: 3.47756
Timestep Consumption Time: 3.87209
PPO Batch Consumption Time: 0.48175
Total Iteration Time: 7.34965

Cumulative Model Updates: 4,320
Cumulative Timesteps: 36,061,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04734
Policy Entropy: 4.29688
Value Function Loss: 0.08456

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.04945
Policy Update Magnitude: 0.73347
Value Function Update Magnitude: 0.46653

Collected Steps per Second: 14,384.40963
Overall Steps per Second: 6,790.14244

Timestep Collection Time: 3.47793
Timestep Consumption Time: 3.88981
PPO Batch Consumption Time: 0.48276
Total Iteration Time: 7.36774

Cumulative Model Updates: 4,326
Cumulative Timesteps: 36,111,730

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 36111730...
Checkpoint 36111730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.20409
Policy Entropy: 4.30076
Value Function Loss: 0.08057

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04778
Policy Update Magnitude: 0.69534
Value Function Update Magnitude: 0.48328

Collected Steps per Second: 14,152.92543
Overall Steps per Second: 6,857.93969

Timestep Collection Time: 3.53482
Timestep Consumption Time: 3.76009
PPO Batch Consumption Time: 0.46296
Total Iteration Time: 7.29490

Cumulative Model Updates: 4,332
Cumulative Timesteps: 36,161,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.20358
Policy Entropy: 4.29514
Value Function Loss: 0.07877

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04866
Policy Update Magnitude: 0.68883
Value Function Update Magnitude: 0.50178

Collected Steps per Second: 14,437.81065
Overall Steps per Second: 6,870.13607

Timestep Collection Time: 3.46562
Timestep Consumption Time: 3.81749
PPO Batch Consumption Time: 0.47302
Total Iteration Time: 7.28312

Cumulative Model Updates: 4,338
Cumulative Timesteps: 36,211,794

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 36211794...
Checkpoint 36211794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02880
Policy Entropy: 4.29662
Value Function Loss: 0.08210

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04537
Policy Update Magnitude: 0.68999
Value Function Update Magnitude: 0.45821

Collected Steps per Second: 14,262.08480
Overall Steps per Second: 6,761.96993

Timestep Collection Time: 3.50748
Timestep Consumption Time: 3.89036
PPO Batch Consumption Time: 0.47957
Total Iteration Time: 7.39784

Cumulative Model Updates: 4,344
Cumulative Timesteps: 36,261,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10284
Policy Entropy: 4.29909
Value Function Loss: 0.08744

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04236
Policy Update Magnitude: 0.71392
Value Function Update Magnitude: 0.43964

Collected Steps per Second: 14,936.34410
Overall Steps per Second: 6,997.90151

Timestep Collection Time: 3.34968
Timestep Consumption Time: 3.79989
PPO Batch Consumption Time: 0.46576
Total Iteration Time: 7.14957

Cumulative Model Updates: 4,350
Cumulative Timesteps: 36,311,850

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 36311850...
Checkpoint 36311850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01639
Policy Entropy: 4.29896
Value Function Loss: 0.08794

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04500
Policy Update Magnitude: 0.73740
Value Function Update Magnitude: 0.47640

Collected Steps per Second: 14,195.84302
Overall Steps per Second: 6,662.59896

Timestep Collection Time: 3.52272
Timestep Consumption Time: 3.98306
PPO Batch Consumption Time: 0.49472
Total Iteration Time: 7.50578

Cumulative Model Updates: 4,356
Cumulative Timesteps: 36,361,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02774
Policy Entropy: 4.29680
Value Function Loss: 0.07799

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04247
Policy Update Magnitude: 0.69571
Value Function Update Magnitude: 0.53277

Collected Steps per Second: 14,417.62912
Overall Steps per Second: 6,841.78400

Timestep Collection Time: 3.46964
Timestep Consumption Time: 3.84190
PPO Batch Consumption Time: 0.47971
Total Iteration Time: 7.31154

Cumulative Model Updates: 4,362
Cumulative Timesteps: 36,411,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 36411882...
Checkpoint 36411882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05936
Policy Entropy: 4.28718
Value Function Loss: 0.06336

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04140
Policy Update Magnitude: 0.65515
Value Function Update Magnitude: 0.52313

Collected Steps per Second: 14,314.40590
Overall Steps per Second: 6,715.70571

Timestep Collection Time: 3.49410
Timestep Consumption Time: 3.95351
PPO Batch Consumption Time: 0.48915
Total Iteration Time: 7.44762

Cumulative Model Updates: 4,368
Cumulative Timesteps: 36,461,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.32947
Policy Entropy: 4.28758
Value Function Loss: 0.07152

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.03986
Policy Update Magnitude: 0.67183
Value Function Update Magnitude: 0.50361

Collected Steps per Second: 14,480.31366
Overall Steps per Second: 6,907.55833

Timestep Collection Time: 3.45462
Timestep Consumption Time: 3.78730
PPO Batch Consumption Time: 0.47757
Total Iteration Time: 7.24192

Cumulative Model Updates: 4,374
Cumulative Timesteps: 36,511,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 36511922...
Checkpoint 36511922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06965
Policy Entropy: 4.29007
Value Function Loss: 0.07952

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04972
Policy Update Magnitude: 0.71341
Value Function Update Magnitude: 0.49901

Collected Steps per Second: 14,271.55731
Overall Steps per Second: 6,699.73755

Timestep Collection Time: 3.50347
Timestep Consumption Time: 3.95951
PPO Batch Consumption Time: 0.48723
Total Iteration Time: 7.46298

Cumulative Model Updates: 4,380
Cumulative Timesteps: 36,561,922

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.30527
Policy Entropy: 4.28983
Value Function Loss: 0.09570

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05612
Policy Update Magnitude: 0.72664
Value Function Update Magnitude: 0.54753

Collected Steps per Second: 14,518.23745
Overall Steps per Second: 6,824.96054

Timestep Collection Time: 3.44532
Timestep Consumption Time: 3.88366
PPO Batch Consumption Time: 0.47863
Total Iteration Time: 7.32898

Cumulative Model Updates: 4,386
Cumulative Timesteps: 36,611,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 36611942...
Checkpoint 36611942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06462
Policy Entropy: 4.28884
Value Function Loss: 0.08740

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05387
Policy Update Magnitude: 0.74137
Value Function Update Magnitude: 0.55231

Collected Steps per Second: 14,445.68704
Overall Steps per Second: 6,888.89552

Timestep Collection Time: 3.46290
Timestep Consumption Time: 3.79864
PPO Batch Consumption Time: 0.48004
Total Iteration Time: 7.26154

Cumulative Model Updates: 4,392
Cumulative Timesteps: 36,661,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04156
Policy Entropy: 4.28952
Value Function Loss: 0.08201

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05527
Policy Update Magnitude: 0.71164
Value Function Update Magnitude: 0.47923

Collected Steps per Second: 14,561.17774
Overall Steps per Second: 6,821.97836

Timestep Collection Time: 3.43571
Timestep Consumption Time: 3.89765
PPO Batch Consumption Time: 0.47654
Total Iteration Time: 7.33336

Cumulative Model Updates: 4,398
Cumulative Timesteps: 36,711,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 36711994...
Checkpoint 36711994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13209
Policy Entropy: 4.28826
Value Function Loss: 0.06959

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05239
Policy Update Magnitude: 0.70035
Value Function Update Magnitude: 0.47362

Collected Steps per Second: 14,046.47612
Overall Steps per Second: 6,692.97708

Timestep Collection Time: 3.56004
Timestep Consumption Time: 3.91137
PPO Batch Consumption Time: 0.49613
Total Iteration Time: 7.47141

Cumulative Model Updates: 4,404
Cumulative Timesteps: 36,762,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17454
Policy Entropy: 4.29463
Value Function Loss: 0.06245

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04753
Policy Update Magnitude: 0.67050
Value Function Update Magnitude: 0.53681

Collected Steps per Second: 14,314.33339
Overall Steps per Second: 6,653.49545

Timestep Collection Time: 3.49412
Timestep Consumption Time: 4.02313
PPO Batch Consumption Time: 0.50312
Total Iteration Time: 7.51725

Cumulative Model Updates: 4,410
Cumulative Timesteps: 36,812,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 36812016...
Checkpoint 36812016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01214
Policy Entropy: 4.29009
Value Function Loss: 0.06160

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04052
Policy Update Magnitude: 0.64887
Value Function Update Magnitude: 0.49649

Collected Steps per Second: 14,437.39292
Overall Steps per Second: 6,809.56341

Timestep Collection Time: 3.46489
Timestep Consumption Time: 3.88125
PPO Batch Consumption Time: 0.48560
Total Iteration Time: 7.34614

Cumulative Model Updates: 4,416
Cumulative Timesteps: 36,862,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04997
Policy Entropy: 4.29264
Value Function Loss: 0.05847

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03884
Policy Update Magnitude: 0.64132
Value Function Update Magnitude: 0.48411

Collected Steps per Second: 14,722.38255
Overall Steps per Second: 6,871.21734

Timestep Collection Time: 3.39782
Timestep Consumption Time: 3.88240
PPO Batch Consumption Time: 0.47333
Total Iteration Time: 7.28022

Cumulative Model Updates: 4,422
Cumulative Timesteps: 36,912,064

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 36912064...
Checkpoint 36912064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14080
Policy Entropy: 4.29346
Value Function Loss: 0.05024

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03570
Policy Update Magnitude: 0.63971
Value Function Update Magnitude: 0.49107

Collected Steps per Second: 14,182.77300
Overall Steps per Second: 6,705.68331

Timestep Collection Time: 3.52653
Timestep Consumption Time: 3.93222
PPO Batch Consumption Time: 0.47948
Total Iteration Time: 7.45875

Cumulative Model Updates: 4,428
Cumulative Timesteps: 36,962,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22036
Policy Entropy: 4.28949
Value Function Loss: 0.06361

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03472
Policy Update Magnitude: 0.63961
Value Function Update Magnitude: 0.46663

Collected Steps per Second: 14,526.53184
Overall Steps per Second: 6,878.41397

Timestep Collection Time: 3.44391
Timestep Consumption Time: 3.82928
PPO Batch Consumption Time: 0.48472
Total Iteration Time: 7.27319

Cumulative Model Updates: 4,434
Cumulative Timesteps: 37,012,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 37012108...
Checkpoint 37012108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10191
Policy Entropy: 4.29205
Value Function Loss: 0.06728

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04355
Policy Update Magnitude: 0.68255
Value Function Update Magnitude: 0.54309

Collected Steps per Second: 14,394.99880
Overall Steps per Second: 6,851.23822

Timestep Collection Time: 3.47357
Timestep Consumption Time: 3.82468
PPO Batch Consumption Time: 0.46654
Total Iteration Time: 7.29824

Cumulative Model Updates: 4,440
Cumulative Timesteps: 37,062,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00987
Policy Entropy: 4.28922
Value Function Loss: 0.06769

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04835
Policy Update Magnitude: 0.70167
Value Function Update Magnitude: 0.55503

Collected Steps per Second: 14,559.90963
Overall Steps per Second: 6,795.00179

Timestep Collection Time: 3.43615
Timestep Consumption Time: 3.92662
PPO Batch Consumption Time: 0.48994
Total Iteration Time: 7.36276

Cumulative Model Updates: 4,446
Cumulative Timesteps: 37,112,140

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 37112140...
Checkpoint 37112140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00251
Policy Entropy: 4.28689
Value Function Loss: 0.06941

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05177
Policy Update Magnitude: 0.68728
Value Function Update Magnitude: 0.52838

Collected Steps per Second: 14,569.52616
Overall Steps per Second: 6,847.27445

Timestep Collection Time: 3.43333
Timestep Consumption Time: 3.87206
PPO Batch Consumption Time: 0.47880
Total Iteration Time: 7.30539

Cumulative Model Updates: 4,452
Cumulative Timesteps: 37,162,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11222
Policy Entropy: 4.28877
Value Function Loss: 0.07731

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05117
Policy Update Magnitude: 0.71065
Value Function Update Magnitude: 0.51682

Collected Steps per Second: 14,391.06646
Overall Steps per Second: 6,775.35796

Timestep Collection Time: 3.47535
Timestep Consumption Time: 3.90640
PPO Batch Consumption Time: 0.47942
Total Iteration Time: 7.38175

Cumulative Model Updates: 4,458
Cumulative Timesteps: 37,212,176

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 37212176...
Checkpoint 37212176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02027
Policy Entropy: 4.28235
Value Function Loss: 0.09272

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05282
Policy Update Magnitude: 0.72121
Value Function Update Magnitude: 0.48552

Collected Steps per Second: 14,255.28412
Overall Steps per Second: 6,770.79027

Timestep Collection Time: 3.50803
Timestep Consumption Time: 3.87781
PPO Batch Consumption Time: 0.49364
Total Iteration Time: 7.38584

Cumulative Model Updates: 4,464
Cumulative Timesteps: 37,262,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11371
Policy Entropy: 4.27903
Value Function Loss: 0.09073

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05400
Policy Update Magnitude: 0.72342
Value Function Update Magnitude: 0.47548

Collected Steps per Second: 14,342.66024
Overall Steps per Second: 6,799.51942

Timestep Collection Time: 3.48694
Timestep Consumption Time: 3.86829
PPO Batch Consumption Time: 0.47118
Total Iteration Time: 7.35523

Cumulative Model Updates: 4,470
Cumulative Timesteps: 37,312,196

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 37312196...
Checkpoint 37312196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22294
Policy Entropy: 4.27169
Value Function Loss: 0.08891

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05522
Policy Update Magnitude: 0.71876
Value Function Update Magnitude: 0.47430

Collected Steps per Second: 14,296.69369
Overall Steps per Second: 6,888.27964

Timestep Collection Time: 3.49941
Timestep Consumption Time: 3.76365
PPO Batch Consumption Time: 0.47265
Total Iteration Time: 7.26306

Cumulative Model Updates: 4,476
Cumulative Timesteps: 37,362,226

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22806
Policy Entropy: 4.27184
Value Function Loss: 0.08159

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06775
Policy Update Magnitude: 0.72165
Value Function Update Magnitude: 0.44187

Collected Steps per Second: 14,496.03059
Overall Steps per Second: 6,813.16038

Timestep Collection Time: 3.44963
Timestep Consumption Time: 3.88998
PPO Batch Consumption Time: 0.47501
Total Iteration Time: 7.33962

Cumulative Model Updates: 4,482
Cumulative Timesteps: 37,412,232

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 37412232...
Checkpoint 37412232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02971
Policy Entropy: 4.27863
Value Function Loss: 0.08244

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06027
Policy Update Magnitude: 0.72665
Value Function Update Magnitude: 0.47193

Collected Steps per Second: 14,245.57067
Overall Steps per Second: 6,747.38846

Timestep Collection Time: 3.50986
Timestep Consumption Time: 3.90041
PPO Batch Consumption Time: 0.48577
Total Iteration Time: 7.41027

Cumulative Model Updates: 4,488
Cumulative Timesteps: 37,462,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03316
Policy Entropy: 4.27669
Value Function Loss: 0.07643

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05635
Policy Update Magnitude: 0.72610
Value Function Update Magnitude: 0.40822

Collected Steps per Second: 15,029.64777
Overall Steps per Second: 6,893.30568

Timestep Collection Time: 3.32782
Timestep Consumption Time: 3.92791
PPO Batch Consumption Time: 0.48022
Total Iteration Time: 7.25574

Cumulative Model Updates: 4,494
Cumulative Timesteps: 37,512,248

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 37512248...
Checkpoint 37512248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09213
Policy Entropy: 4.28609
Value Function Loss: 0.07743

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04619
Policy Update Magnitude: 0.72204
Value Function Update Magnitude: 0.37153

Collected Steps per Second: 13,913.90721
Overall Steps per Second: 6,705.13038

Timestep Collection Time: 3.59453
Timestep Consumption Time: 3.86453
PPO Batch Consumption Time: 0.47854
Total Iteration Time: 7.45906

Cumulative Model Updates: 4,500
Cumulative Timesteps: 37,562,262

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02041
Policy Entropy: 4.27957
Value Function Loss: 0.07307

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.04580
Policy Update Magnitude: 0.70451
Value Function Update Magnitude: 0.38740

Collected Steps per Second: 14,549.13847
Overall Steps per Second: 6,852.98604

Timestep Collection Time: 3.43704
Timestep Consumption Time: 3.85992
PPO Batch Consumption Time: 0.48836
Total Iteration Time: 7.29697

Cumulative Model Updates: 4,506
Cumulative Timesteps: 37,612,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 37612268...
Checkpoint 37612268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04868
Policy Entropy: 4.28929
Value Function Loss: 0.05723

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04674
Policy Update Magnitude: 0.67212
Value Function Update Magnitude: 0.38453

Collected Steps per Second: 14,421.58204
Overall Steps per Second: 6,681.77169

Timestep Collection Time: 3.46855
Timestep Consumption Time: 4.01779
PPO Batch Consumption Time: 0.50673
Total Iteration Time: 7.48634

Cumulative Model Updates: 4,512
Cumulative Timesteps: 37,662,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04030
Policy Entropy: 4.28735
Value Function Loss: 0.04781

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04569
Policy Update Magnitude: 0.60306
Value Function Update Magnitude: 0.35603

Collected Steps per Second: 14,494.96259
Overall Steps per Second: 6,839.37034

Timestep Collection Time: 3.45168
Timestep Consumption Time: 3.86361
PPO Batch Consumption Time: 0.48684
Total Iteration Time: 7.31529

Cumulative Model Updates: 4,518
Cumulative Timesteps: 37,712,322

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 37712322...
Checkpoint 37712322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07905
Policy Entropy: 4.29131
Value Function Loss: 0.05526

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03801
Policy Update Magnitude: 0.58413
Value Function Update Magnitude: 0.36163

Collected Steps per Second: 14,449.65220
Overall Steps per Second: 6,865.47357

Timestep Collection Time: 3.46029
Timestep Consumption Time: 3.82253
PPO Batch Consumption Time: 0.47229
Total Iteration Time: 7.28282

Cumulative Model Updates: 4,524
Cumulative Timesteps: 37,762,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00093
Policy Entropy: 4.29077
Value Function Loss: 0.06287

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04122
Policy Update Magnitude: 0.63000
Value Function Update Magnitude: 0.33280

Collected Steps per Second: 14,536.96403
Overall Steps per Second: 6,805.98348

Timestep Collection Time: 3.43965
Timestep Consumption Time: 3.90713
PPO Batch Consumption Time: 0.48667
Total Iteration Time: 7.34677

Cumulative Model Updates: 4,530
Cumulative Timesteps: 37,812,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 37812324...
Checkpoint 37812324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.20550
Policy Entropy: 4.28439
Value Function Loss: 0.07477

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04378
Policy Update Magnitude: 0.64923
Value Function Update Magnitude: 0.35714

Collected Steps per Second: 14,597.47472
Overall Steps per Second: 6,792.27884

Timestep Collection Time: 3.42689
Timestep Consumption Time: 3.93794
PPO Batch Consumption Time: 0.48953
Total Iteration Time: 7.36483

Cumulative Model Updates: 4,536
Cumulative Timesteps: 37,862,348

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07148
Policy Entropy: 4.28651
Value Function Loss: 0.07084

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04204
Policy Update Magnitude: 0.67519
Value Function Update Magnitude: 0.36244

Collected Steps per Second: 14,367.25092
Overall Steps per Second: 6,893.53599

Timestep Collection Time: 3.48028
Timestep Consumption Time: 3.77319
PPO Batch Consumption Time: 0.46581
Total Iteration Time: 7.25346

Cumulative Model Updates: 4,542
Cumulative Timesteps: 37,912,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 37912350...
Checkpoint 37912350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17268
Policy Entropy: 4.28677
Value Function Loss: 0.07336

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04528
Policy Update Magnitude: 0.66813
Value Function Update Magnitude: 0.38067

Collected Steps per Second: 14,344.09127
Overall Steps per Second: 6,939.42023

Timestep Collection Time: 3.48785
Timestep Consumption Time: 3.72169
PPO Batch Consumption Time: 0.46510
Total Iteration Time: 7.20954

Cumulative Model Updates: 4,548
Cumulative Timesteps: 37,962,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10029
Policy Entropy: 4.28390
Value Function Loss: 0.07785

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04765
Policy Update Magnitude: 0.70015
Value Function Update Magnitude: 0.43054

Collected Steps per Second: 14,530.90932
Overall Steps per Second: 6,854.25613

Timestep Collection Time: 3.44245
Timestep Consumption Time: 3.85549
PPO Batch Consumption Time: 0.47789
Total Iteration Time: 7.29795

Cumulative Model Updates: 4,554
Cumulative Timesteps: 38,012,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 38012402...
Checkpoint 38012402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05325
Policy Entropy: 4.28517
Value Function Loss: 0.06120

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04580
Policy Update Magnitude: 0.68752
Value Function Update Magnitude: 0.47450

Collected Steps per Second: 14,563.40803
Overall Steps per Second: 6,827.10155

Timestep Collection Time: 3.43409
Timestep Consumption Time: 3.89142
PPO Batch Consumption Time: 0.47939
Total Iteration Time: 7.32551

Cumulative Model Updates: 4,560
Cumulative Timesteps: 38,062,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09911
Policy Entropy: 4.28911
Value Function Loss: 0.05777

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.03714
Policy Update Magnitude: 0.64260
Value Function Update Magnitude: 0.43375

Collected Steps per Second: 14,479.57536
Overall Steps per Second: 6,688.71781

Timestep Collection Time: 3.45507
Timestep Consumption Time: 4.02439
PPO Batch Consumption Time: 0.50412
Total Iteration Time: 7.47946

Cumulative Model Updates: 4,566
Cumulative Timesteps: 38,112,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 38112442...
Checkpoint 38112442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07284
Policy Entropy: 4.28558
Value Function Loss: 0.06490

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03470
Policy Update Magnitude: 0.64765
Value Function Update Magnitude: 0.45171

Collected Steps per Second: 14,344.25642
Overall Steps per Second: 6,823.80095

Timestep Collection Time: 3.48613
Timestep Consumption Time: 3.84204
PPO Batch Consumption Time: 0.47142
Total Iteration Time: 7.32817

Cumulative Model Updates: 4,572
Cumulative Timesteps: 38,162,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14673
Policy Entropy: 4.28592
Value Function Loss: 0.07108

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04697
Policy Update Magnitude: 0.69734
Value Function Update Magnitude: 0.51336

Collected Steps per Second: 14,653.75795
Overall Steps per Second: 6,944.90922

Timestep Collection Time: 3.41319
Timestep Consumption Time: 3.78864
PPO Batch Consumption Time: 0.47132
Total Iteration Time: 7.20182

Cumulative Model Updates: 4,578
Cumulative Timesteps: 38,212,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 38212464...
Checkpoint 38212464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12543
Policy Entropy: 4.28210
Value Function Loss: 0.07412

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.04889
Policy Update Magnitude: 0.70815
Value Function Update Magnitude: 0.47600

Collected Steps per Second: 14,539.01847
Overall Steps per Second: 6,875.66053

Timestep Collection Time: 3.43902
Timestep Consumption Time: 3.83301
PPO Batch Consumption Time: 0.47672
Total Iteration Time: 7.27203

Cumulative Model Updates: 4,584
Cumulative Timesteps: 38,262,464

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09924
Policy Entropy: 4.28060
Value Function Loss: 0.06981

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04943
Policy Update Magnitude: 0.68854
Value Function Update Magnitude: 0.42760

Collected Steps per Second: 14,612.04501
Overall Steps per Second: 7,045.38136

Timestep Collection Time: 3.42348
Timestep Consumption Time: 3.67678
PPO Batch Consumption Time: 0.46363
Total Iteration Time: 7.10025

Cumulative Model Updates: 4,590
Cumulative Timesteps: 38,312,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 38312488...
Checkpoint 38312488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06599
Policy Entropy: 4.28203
Value Function Loss: 0.06869

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04364
Policy Update Magnitude: 0.67658
Value Function Update Magnitude: 0.43596

Collected Steps per Second: 14,649.53979
Overall Steps per Second: 6,877.52952

Timestep Collection Time: 3.41308
Timestep Consumption Time: 3.85698
PPO Batch Consumption Time: 0.47163
Total Iteration Time: 7.27005

Cumulative Model Updates: 4,596
Cumulative Timesteps: 38,362,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08434
Policy Entropy: 4.28061
Value Function Loss: 0.06823

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04197
Policy Update Magnitude: 0.67583
Value Function Update Magnitude: 0.40952

Collected Steps per Second: 14,486.38251
Overall Steps per Second: 6,729.00893

Timestep Collection Time: 3.45331
Timestep Consumption Time: 3.98107
PPO Batch Consumption Time: 0.49510
Total Iteration Time: 7.43438

Cumulative Model Updates: 4,602
Cumulative Timesteps: 38,412,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 38412514...
Checkpoint 38412514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03481
Policy Entropy: 4.27662
Value Function Loss: 0.07227

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04063
Policy Update Magnitude: 0.69270
Value Function Update Magnitude: 0.40647

Collected Steps per Second: 14,775.29024
Overall Steps per Second: 6,991.41327

Timestep Collection Time: 3.38430
Timestep Consumption Time: 3.76790
PPO Batch Consumption Time: 0.46697
Total Iteration Time: 7.15220

Cumulative Model Updates: 4,608
Cumulative Timesteps: 38,462,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10724
Policy Entropy: 4.27662
Value Function Loss: 0.07053

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04515
Policy Update Magnitude: 0.68712
Value Function Update Magnitude: 0.43295

Collected Steps per Second: 14,398.58986
Overall Steps per Second: 6,666.29722

Timestep Collection Time: 3.47381
Timestep Consumption Time: 4.02930
PPO Batch Consumption Time: 0.50009
Total Iteration Time: 7.50312

Cumulative Model Updates: 4,614
Cumulative Timesteps: 38,512,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 38512536...
Checkpoint 38512536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08295
Policy Entropy: 4.28117
Value Function Loss: 0.06473

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04316
Policy Update Magnitude: 0.68817
Value Function Update Magnitude: 0.46314

Collected Steps per Second: 14,644.04750
Overall Steps per Second: 6,875.54192

Timestep Collection Time: 3.41586
Timestep Consumption Time: 3.85949
PPO Batch Consumption Time: 0.48512
Total Iteration Time: 7.27535

Cumulative Model Updates: 4,620
Cumulative Timesteps: 38,562,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07460
Policy Entropy: 4.28474
Value Function Loss: 0.06489

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03935
Policy Update Magnitude: 0.67112
Value Function Update Magnitude: 0.47339

Collected Steps per Second: 14,543.15700
Overall Steps per Second: 6,826.97227

Timestep Collection Time: 3.43956
Timestep Consumption Time: 3.88756
PPO Batch Consumption Time: 0.48439
Total Iteration Time: 7.32711

Cumulative Model Updates: 4,626
Cumulative Timesteps: 38,612,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 38612580...
Checkpoint 38612580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05881
Policy Entropy: 4.27912
Value Function Loss: 0.07096

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04189
Policy Update Magnitude: 0.68517
Value Function Update Magnitude: 0.46986

Collected Steps per Second: 14,512.19303
Overall Steps per Second: 6,834.37996

Timestep Collection Time: 3.44676
Timestep Consumption Time: 3.87212
PPO Batch Consumption Time: 0.48024
Total Iteration Time: 7.31888

Cumulative Model Updates: 4,632
Cumulative Timesteps: 38,662,600

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15618
Policy Entropy: 4.28236
Value Function Loss: 0.06964

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04636
Policy Update Magnitude: 0.66919
Value Function Update Magnitude: 0.46395

Collected Steps per Second: 14,399.39079
Overall Steps per Second: 6,886.27945

Timestep Collection Time: 3.47306
Timestep Consumption Time: 3.78920
PPO Batch Consumption Time: 0.48005
Total Iteration Time: 7.26227

Cumulative Model Updates: 4,638
Cumulative Timesteps: 38,712,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 38712610...
Checkpoint 38712610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01827
Policy Entropy: 4.27625
Value Function Loss: 0.07225

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04099
Policy Update Magnitude: 0.66625
Value Function Update Magnitude: 0.46002

Collected Steps per Second: 14,568.31915
Overall Steps per Second: 6,777.18467

Timestep Collection Time: 3.43238
Timestep Consumption Time: 3.94591
PPO Batch Consumption Time: 0.48503
Total Iteration Time: 7.37829

Cumulative Model Updates: 4,644
Cumulative Timesteps: 38,762,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06673
Policy Entropy: 4.27669
Value Function Loss: 0.07652

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04524
Policy Update Magnitude: 0.70131
Value Function Update Magnitude: 0.44233

Collected Steps per Second: 14,535.31876
Overall Steps per Second: 6,973.63866

Timestep Collection Time: 3.44127
Timestep Consumption Time: 3.73145
PPO Batch Consumption Time: 0.47039
Total Iteration Time: 7.17273

Cumulative Model Updates: 4,650
Cumulative Timesteps: 38,812,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 38812634...
Checkpoint 38812634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.24135
Policy Entropy: 4.27541
Value Function Loss: 0.09084

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05075
Policy Update Magnitude: 0.72783
Value Function Update Magnitude: 0.49488

Collected Steps per Second: 14,537.07273
Overall Steps per Second: 6,932.32501

Timestep Collection Time: 3.43948
Timestep Consumption Time: 3.77311
PPO Batch Consumption Time: 0.46648
Total Iteration Time: 7.21259

Cumulative Model Updates: 4,656
Cumulative Timesteps: 38,862,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01602
Policy Entropy: 4.27915
Value Function Loss: 0.09243

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.05811
Policy Update Magnitude: 0.72377
Value Function Update Magnitude: 0.48731

Collected Steps per Second: 14,733.63394
Overall Steps per Second: 6,937.61659

Timestep Collection Time: 3.39509
Timestep Consumption Time: 3.81517
PPO Batch Consumption Time: 0.47265
Total Iteration Time: 7.21026

Cumulative Model Updates: 4,662
Cumulative Timesteps: 38,912,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 38912656...
Checkpoint 38912656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11522
Policy Entropy: 4.27390
Value Function Loss: 0.08909

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05025
Policy Update Magnitude: 0.72825
Value Function Update Magnitude: 0.52975

Collected Steps per Second: 14,611.77725
Overall Steps per Second: 6,899.66996

Timestep Collection Time: 3.42203
Timestep Consumption Time: 3.82498
PPO Batch Consumption Time: 0.47560
Total Iteration Time: 7.24701

Cumulative Model Updates: 4,668
Cumulative Timesteps: 38,962,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06768
Policy Entropy: 4.27513
Value Function Loss: 0.08112

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04841
Policy Update Magnitude: 0.72657
Value Function Update Magnitude: 0.54647

Collected Steps per Second: 14,720.80730
Overall Steps per Second: 6,797.96614

Timestep Collection Time: 3.39710
Timestep Consumption Time: 3.95922
PPO Batch Consumption Time: 0.49085
Total Iteration Time: 7.35632

Cumulative Model Updates: 4,674
Cumulative Timesteps: 39,012,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 39012666...
Checkpoint 39012666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06179
Policy Entropy: 4.27083
Value Function Loss: 0.07357

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05393
Policy Update Magnitude: 0.70364
Value Function Update Magnitude: 0.46506

Collected Steps per Second: 14,529.88627
Overall Steps per Second: 6,913.87003

Timestep Collection Time: 3.44187
Timestep Consumption Time: 3.79141
PPO Batch Consumption Time: 0.47585
Total Iteration Time: 7.23329

Cumulative Model Updates: 4,680
Cumulative Timesteps: 39,062,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12593
Policy Entropy: 4.27138
Value Function Loss: 0.07071

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.06787
Policy Update Magnitude: 0.67062
Value Function Update Magnitude: 0.41057

Collected Steps per Second: 14,667.64467
Overall Steps per Second: 6,834.52151

Timestep Collection Time: 3.40886
Timestep Consumption Time: 3.90694
PPO Batch Consumption Time: 0.47792
Total Iteration Time: 7.31580

Cumulative Model Updates: 4,686
Cumulative Timesteps: 39,112,676

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 39112676...
Checkpoint 39112676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10633
Policy Entropy: 4.27471
Value Function Loss: 0.06885

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07004
Policy Update Magnitude: 0.63755
Value Function Update Magnitude: 0.39941

Collected Steps per Second: 14,261.75944
Overall Steps per Second: 6,710.75218

Timestep Collection Time: 3.50630
Timestep Consumption Time: 3.94532
PPO Batch Consumption Time: 0.49280
Total Iteration Time: 7.45162

Cumulative Model Updates: 4,692
Cumulative Timesteps: 39,162,682

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.26793
Policy Entropy: 4.28528
Value Function Loss: 0.07432

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06327
Policy Update Magnitude: 0.63995
Value Function Update Magnitude: 0.40563

Collected Steps per Second: 14,828.99984
Overall Steps per Second: 6,885.56654

Timestep Collection Time: 3.37393
Timestep Consumption Time: 3.89228
PPO Batch Consumption Time: 0.48153
Total Iteration Time: 7.26621

Cumulative Model Updates: 4,698
Cumulative Timesteps: 39,212,714

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 39212714...
Checkpoint 39212714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07021
Policy Entropy: 4.28899
Value Function Loss: 0.08124

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06229
Policy Update Magnitude: 0.66352
Value Function Update Magnitude: 0.43353

Collected Steps per Second: 14,295.22533
Overall Steps per Second: 6,744.56448

Timestep Collection Time: 3.49879
Timestep Consumption Time: 3.91696
PPO Batch Consumption Time: 0.48140
Total Iteration Time: 7.41575

Cumulative Model Updates: 4,704
Cumulative Timesteps: 39,262,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21403
Policy Entropy: 4.28798
Value Function Loss: 0.08464

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06113
Policy Update Magnitude: 0.70285
Value Function Update Magnitude: 0.50573

Collected Steps per Second: 14,385.45714
Overall Steps per Second: 6,840.64388

Timestep Collection Time: 3.47698
Timestep Consumption Time: 3.83490
PPO Batch Consumption Time: 0.47329
Total Iteration Time: 7.31188

Cumulative Model Updates: 4,710
Cumulative Timesteps: 39,312,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 39312748...
Checkpoint 39312748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00550
Policy Entropy: 4.28584
Value Function Loss: 0.08625

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05857
Policy Update Magnitude: 0.72232
Value Function Update Magnitude: 0.53013

Collected Steps per Second: 14,281.68592
Overall Steps per Second: 6,611.86206

Timestep Collection Time: 3.50337
Timestep Consumption Time: 4.06394
PPO Batch Consumption Time: 0.50902
Total Iteration Time: 7.56731

Cumulative Model Updates: 4,716
Cumulative Timesteps: 39,362,782

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22693
Policy Entropy: 4.29096
Value Function Loss: 0.08290

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05040
Policy Update Magnitude: 0.70495
Value Function Update Magnitude: 0.53625

Collected Steps per Second: 14,274.45922
Overall Steps per Second: 6,847.15306

Timestep Collection Time: 3.50458
Timestep Consumption Time: 3.80152
PPO Batch Consumption Time: 0.47653
Total Iteration Time: 7.30610

Cumulative Model Updates: 4,722
Cumulative Timesteps: 39,412,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 39412808...
Checkpoint 39412808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09605
Policy Entropy: 4.28870
Value Function Loss: 0.08094

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04896
Policy Update Magnitude: 0.68480
Value Function Update Magnitude: 0.51609

Collected Steps per Second: 14,310.00224
Overall Steps per Second: 6,759.74290

Timestep Collection Time: 3.49462
Timestep Consumption Time: 3.90330
PPO Batch Consumption Time: 0.47690
Total Iteration Time: 7.39791

Cumulative Model Updates: 4,728
Cumulative Timesteps: 39,462,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04932
Policy Entropy: 4.28941
Value Function Loss: 0.06792

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04709
Policy Update Magnitude: 0.66391
Value Function Update Magnitude: 0.52363

Collected Steps per Second: 14,385.61903
Overall Steps per Second: 6,734.93646

Timestep Collection Time: 3.47708
Timestep Consumption Time: 3.94986
PPO Batch Consumption Time: 0.48413
Total Iteration Time: 7.42694

Cumulative Model Updates: 4,734
Cumulative Timesteps: 39,512,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 39512836...
Checkpoint 39512836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03758
Policy Entropy: 4.28796
Value Function Loss: 0.06236

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04336
Policy Update Magnitude: 0.63537
Value Function Update Magnitude: 0.50529

Collected Steps per Second: 14,352.18500
Overall Steps per Second: 6,856.38306

Timestep Collection Time: 3.48379
Timestep Consumption Time: 3.80868
PPO Batch Consumption Time: 0.48126
Total Iteration Time: 7.29247

Cumulative Model Updates: 4,740
Cumulative Timesteps: 39,562,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07769
Policy Entropy: 4.28507
Value Function Loss: 0.06762

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04345
Policy Update Magnitude: 0.64179
Value Function Update Magnitude: 0.49660

Collected Steps per Second: 14,525.87584
Overall Steps per Second: 6,826.18536

Timestep Collection Time: 3.44434
Timestep Consumption Time: 3.88509
PPO Batch Consumption Time: 0.48112
Total Iteration Time: 7.32942

Cumulative Model Updates: 4,746
Cumulative Timesteps: 39,612,868

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 39612868...
Checkpoint 39612868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13629
Policy Entropy: 4.29130
Value Function Loss: 0.06679

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03882
Policy Update Magnitude: 0.66961
Value Function Update Magnitude: 0.55683

Collected Steps per Second: 14,311.60982
Overall Steps per Second: 6,798.11178

Timestep Collection Time: 3.49465
Timestep Consumption Time: 3.86240
PPO Batch Consumption Time: 0.49052
Total Iteration Time: 7.35704

Cumulative Model Updates: 4,752
Cumulative Timesteps: 39,662,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12464
Policy Entropy: 4.28829
Value Function Loss: 0.07088

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04229
Policy Update Magnitude: 0.67556
Value Function Update Magnitude: 0.60832

Collected Steps per Second: 14,331.61417
Overall Steps per Second: 6,765.72328

Timestep Collection Time: 3.48921
Timestep Consumption Time: 3.90187
PPO Batch Consumption Time: 0.47445
Total Iteration Time: 7.39108

Cumulative Model Updates: 4,758
Cumulative Timesteps: 39,712,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 39712888...
Checkpoint 39712888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08462
Policy Entropy: 4.28352
Value Function Loss: 0.06563

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04875
Policy Update Magnitude: 0.68426
Value Function Update Magnitude: 0.61420

Collected Steps per Second: 14,221.52817
Overall Steps per Second: 6,827.10994

Timestep Collection Time: 3.51636
Timestep Consumption Time: 3.80856
PPO Batch Consumption Time: 0.46873
Total Iteration Time: 7.32492

Cumulative Model Updates: 4,764
Cumulative Timesteps: 39,762,896

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06912
Policy Entropy: 4.28501
Value Function Loss: 0.05676

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04273
Policy Update Magnitude: 0.66724
Value Function Update Magnitude: 0.60591

Collected Steps per Second: 14,553.73765
Overall Steps per Second: 6,771.92364

Timestep Collection Time: 3.43692
Timestep Consumption Time: 3.94946
PPO Batch Consumption Time: 0.48956
Total Iteration Time: 7.38638

Cumulative Model Updates: 4,770
Cumulative Timesteps: 39,812,916

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 39812916...
Checkpoint 39812916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01837
Policy Entropy: 4.28603
Value Function Loss: 0.05826

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03667
Policy Update Magnitude: 0.64110
Value Function Update Magnitude: 0.57913

Collected Steps per Second: 14,091.76215
Overall Steps per Second: 6,779.34476

Timestep Collection Time: 3.54874
Timestep Consumption Time: 3.82778
PPO Batch Consumption Time: 0.46928
Total Iteration Time: 7.37652

Cumulative Model Updates: 4,776
Cumulative Timesteps: 39,862,924

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04034
Policy Entropy: 4.28851
Value Function Loss: 0.05307

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02950
Policy Update Magnitude: 0.64066
Value Function Update Magnitude: 0.55025

Collected Steps per Second: 14,223.99857
Overall Steps per Second: 6,840.62562

Timestep Collection Time: 3.51603
Timestep Consumption Time: 3.79500
PPO Batch Consumption Time: 0.47207
Total Iteration Time: 7.31103

Cumulative Model Updates: 4,782
Cumulative Timesteps: 39,912,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 39912936...
Checkpoint 39912936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04461
Policy Entropy: 4.28354
Value Function Loss: 0.06255

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.03823
Policy Update Magnitude: 0.64261
Value Function Update Magnitude: 0.54869

Collected Steps per Second: 14,266.35411
Overall Steps per Second: 6,768.14152

Timestep Collection Time: 3.50587
Timestep Consumption Time: 3.88405
PPO Batch Consumption Time: 0.47221
Total Iteration Time: 7.38992

Cumulative Model Updates: 4,788
Cumulative Timesteps: 39,962,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01940
Policy Entropy: 4.28736
Value Function Loss: 0.05171

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03775
Policy Update Magnitude: 0.63895
Value Function Update Magnitude: 0.59028

Collected Steps per Second: 14,512.63224
Overall Steps per Second: 6,928.47693

Timestep Collection Time: 3.44555
Timestep Consumption Time: 3.77162
PPO Batch Consumption Time: 0.46666
Total Iteration Time: 7.21717

Cumulative Model Updates: 4,794
Cumulative Timesteps: 40,012,956

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 40012956...
Checkpoint 40012956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08265
Policy Entropy: 4.29766
Value Function Loss: 0.04815

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03827
Policy Update Magnitude: 0.62837
Value Function Update Magnitude: 0.55791

Collected Steps per Second: 14,541.27138
Overall Steps per Second: 6,928.46540

Timestep Collection Time: 3.43959
Timestep Consumption Time: 3.77933
PPO Batch Consumption Time: 0.46559
Total Iteration Time: 7.21891

Cumulative Model Updates: 4,800
Cumulative Timesteps: 40,062,972

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16650
Policy Entropy: 4.30019
Value Function Loss: 0.04624

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03478
Policy Update Magnitude: 0.61427
Value Function Update Magnitude: 0.56407

Collected Steps per Second: 14,316.22794
Overall Steps per Second: 6,725.70542

Timestep Collection Time: 3.49352
Timestep Consumption Time: 3.94273
PPO Batch Consumption Time: 0.48121
Total Iteration Time: 7.43625

Cumulative Model Updates: 4,806
Cumulative Timesteps: 40,112,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 40112986...
Checkpoint 40112986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07381
Policy Entropy: 4.29592
Value Function Loss: 0.04399

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03412
Policy Update Magnitude: 0.60344
Value Function Update Magnitude: 0.51530

Collected Steps per Second: 14,278.15386
Overall Steps per Second: 6,773.02582

Timestep Collection Time: 3.50339
Timestep Consumption Time: 3.88208
PPO Batch Consumption Time: 0.49275
Total Iteration Time: 7.38547

Cumulative Model Updates: 4,812
Cumulative Timesteps: 40,163,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00775
Policy Entropy: 4.29093
Value Function Loss: 0.05513

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03508
Policy Update Magnitude: 0.62073
Value Function Update Magnitude: 0.49470

Collected Steps per Second: 14,452.22119
Overall Steps per Second: 6,675.47132

Timestep Collection Time: 3.46189
Timestep Consumption Time: 4.03301
PPO Batch Consumption Time: 0.50299
Total Iteration Time: 7.49490

Cumulative Model Updates: 4,818
Cumulative Timesteps: 40,213,040

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 40213040...
Checkpoint 40213040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06010
Policy Entropy: 4.29252
Value Function Loss: 0.06125

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03583
Policy Update Magnitude: 0.63211
Value Function Update Magnitude: 0.47154

Collected Steps per Second: 14,318.27389
Overall Steps per Second: 6,826.60710

Timestep Collection Time: 3.49232
Timestep Consumption Time: 3.83255
PPO Batch Consumption Time: 0.47888
Total Iteration Time: 7.32487

Cumulative Model Updates: 4,824
Cumulative Timesteps: 40,263,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06706
Policy Entropy: 4.28797
Value Function Loss: 0.06632

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03563
Policy Update Magnitude: 0.64694
Value Function Update Magnitude: 0.46838

Collected Steps per Second: 14,469.92679
Overall Steps per Second: 6,759.25823

Timestep Collection Time: 3.45544
Timestep Consumption Time: 3.94182
PPO Batch Consumption Time: 0.48319
Total Iteration Time: 7.39726

Cumulative Model Updates: 4,830
Cumulative Timesteps: 40,313,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 40313044...
Checkpoint 40313044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05178
Policy Entropy: 4.28159
Value Function Loss: 0.06024

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03641
Policy Update Magnitude: 0.64812
Value Function Update Magnitude: 0.46007

Collected Steps per Second: 14,115.88302
Overall Steps per Second: 6,718.32645

Timestep Collection Time: 3.54268
Timestep Consumption Time: 3.90084
PPO Batch Consumption Time: 0.47735
Total Iteration Time: 7.44352

Cumulative Model Updates: 4,836
Cumulative Timesteps: 40,363,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11232
Policy Entropy: 4.28077
Value Function Loss: 0.06583

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03469
Policy Update Magnitude: 0.64084
Value Function Update Magnitude: 0.48396

Collected Steps per Second: 14,444.46842
Overall Steps per Second: 6,854.12036

Timestep Collection Time: 3.46195
Timestep Consumption Time: 3.83381
PPO Batch Consumption Time: 0.48452
Total Iteration Time: 7.29576

Cumulative Model Updates: 4,842
Cumulative Timesteps: 40,413,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 40413058...
Checkpoint 40413058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08225
Policy Entropy: 4.28401
Value Function Loss: 0.05865

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04572
Policy Update Magnitude: 0.63361
Value Function Update Magnitude: 0.46737

Collected Steps per Second: 14,271.48781
Overall Steps per Second: 6,824.82335

Timestep Collection Time: 3.50363
Timestep Consumption Time: 3.82286
PPO Batch Consumption Time: 0.47515
Total Iteration Time: 7.32649

Cumulative Model Updates: 4,848
Cumulative Timesteps: 40,463,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01076
Policy Entropy: 4.29199
Value Function Loss: 0.06797

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04133
Policy Update Magnitude: 0.64078
Value Function Update Magnitude: 0.48760

Collected Steps per Second: 14,522.72599
Overall Steps per Second: 6,846.89984

Timestep Collection Time: 3.44467
Timestep Consumption Time: 3.86170
PPO Batch Consumption Time: 0.49188
Total Iteration Time: 7.30637

Cumulative Model Updates: 4,854
Cumulative Timesteps: 40,513,086

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 40513086...
Checkpoint 40513086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03326
Policy Entropy: 4.28628
Value Function Loss: 0.06312

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04027
Policy Update Magnitude: 0.66183
Value Function Update Magnitude: 0.50376

Collected Steps per Second: 13,240.44176
Overall Steps per Second: 6,525.93119

Timestep Collection Time: 3.77646
Timestep Consumption Time: 3.88559
PPO Batch Consumption Time: 0.49311
Total Iteration Time: 7.66205

Cumulative Model Updates: 4,860
Cumulative Timesteps: 40,563,088

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03628
Policy Entropy: 4.28701
Value Function Loss: 0.07067

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.03972
Policy Update Magnitude: 0.67442
Value Function Update Magnitude: 0.51550

Collected Steps per Second: 13,358.00157
Overall Steps per Second: 6,493.75594

Timestep Collection Time: 3.74457
Timestep Consumption Time: 3.95821
PPO Batch Consumption Time: 0.48867
Total Iteration Time: 7.70278

Cumulative Model Updates: 4,866
Cumulative Timesteps: 40,613,108

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 40613108...
Checkpoint 40613108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10457
Policy Entropy: 4.29054
Value Function Loss: 0.06795

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03886
Policy Update Magnitude: 0.67081
Value Function Update Magnitude: 0.50017

Collected Steps per Second: 13,380.17107
Overall Steps per Second: 6,619.83775

Timestep Collection Time: 3.73747
Timestep Consumption Time: 3.81679
PPO Batch Consumption Time: 0.48038
Total Iteration Time: 7.55426

Cumulative Model Updates: 4,872
Cumulative Timesteps: 40,663,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04542
Policy Entropy: 4.28980
Value Function Loss: 0.06119

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03626
Policy Update Magnitude: 0.65445
Value Function Update Magnitude: 0.41972

Collected Steps per Second: 14,024.18290
Overall Steps per Second: 6,671.98722

Timestep Collection Time: 3.56655
Timestep Consumption Time: 3.93016
PPO Batch Consumption Time: 0.48236
Total Iteration Time: 7.49672

Cumulative Model Updates: 4,878
Cumulative Timesteps: 40,713,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 40713134...
Checkpoint 40713134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.25224
Policy Entropy: 4.28428
Value Function Loss: 0.06798

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03431
Policy Update Magnitude: 0.67877
Value Function Update Magnitude: 0.41171

Collected Steps per Second: 13,884.77601
Overall Steps per Second: 6,645.91676

Timestep Collection Time: 3.60251
Timestep Consumption Time: 3.92392
PPO Batch Consumption Time: 0.48792
Total Iteration Time: 7.52643

Cumulative Model Updates: 4,884
Cumulative Timesteps: 40,763,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03613
Policy Entropy: 4.28305
Value Function Loss: 0.06208

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04365
Policy Update Magnitude: 0.68178
Value Function Update Magnitude: 0.47891

Collected Steps per Second: 14,074.07013
Overall Steps per Second: 6,682.10744

Timestep Collection Time: 3.55334
Timestep Consumption Time: 3.93082
PPO Batch Consumption Time: 0.48129
Total Iteration Time: 7.48417

Cumulative Model Updates: 4,890
Cumulative Timesteps: 40,813,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 40813164...
Checkpoint 40813164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14285
Policy Entropy: 4.27843
Value Function Loss: 0.05966

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04270
Policy Update Magnitude: 0.67042
Value Function Update Magnitude: 0.52749

Collected Steps per Second: 14,265.40358
Overall Steps per Second: 6,752.97523

Timestep Collection Time: 3.50681
Timestep Consumption Time: 3.90119
PPO Batch Consumption Time: 0.49594
Total Iteration Time: 7.40799

Cumulative Model Updates: 4,896
Cumulative Timesteps: 40,863,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02007
Policy Entropy: 4.28798
Value Function Loss: 0.05474

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04385
Policy Update Magnitude: 0.66915
Value Function Update Magnitude: 0.49763

Collected Steps per Second: 13,672.12961
Overall Steps per Second: 6,385.31159

Timestep Collection Time: 3.65839
Timestep Consumption Time: 4.17490
PPO Batch Consumption Time: 0.51618
Total Iteration Time: 7.83329

Cumulative Model Updates: 4,902
Cumulative Timesteps: 40,913,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 40913208...
Checkpoint 40913208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01377
Policy Entropy: 4.29394
Value Function Loss: 0.05850

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04576
Policy Update Magnitude: 0.67738
Value Function Update Magnitude: 0.54018

Collected Steps per Second: 14,164.02083
Overall Steps per Second: 6,649.28611

Timestep Collection Time: 3.53219
Timestep Consumption Time: 3.99193
PPO Batch Consumption Time: 0.49589
Total Iteration Time: 7.52412

Cumulative Model Updates: 4,908
Cumulative Timesteps: 40,963,238

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03336
Policy Entropy: 4.29080
Value Function Loss: 0.06031

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04474
Policy Update Magnitude: 0.66645
Value Function Update Magnitude: 0.53441

Collected Steps per Second: 14,281.68943
Overall Steps per Second: 6,752.91361

Timestep Collection Time: 3.50323
Timestep Consumption Time: 3.90572
PPO Batch Consumption Time: 0.49490
Total Iteration Time: 7.40895

Cumulative Model Updates: 4,914
Cumulative Timesteps: 41,013,270

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 41013270...
Checkpoint 41013270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06682
Policy Entropy: 4.28597
Value Function Loss: 0.05076

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04138
Policy Update Magnitude: 0.63048
Value Function Update Magnitude: 0.51960

Collected Steps per Second: 14,255.73773
Overall Steps per Second: 6,693.85935

Timestep Collection Time: 3.50736
Timestep Consumption Time: 3.96217
PPO Batch Consumption Time: 0.49176
Total Iteration Time: 7.46953

Cumulative Model Updates: 4,920
Cumulative Timesteps: 41,063,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12788
Policy Entropy: 4.27783
Value Function Loss: 0.05938

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04268
Policy Update Magnitude: 0.64749
Value Function Update Magnitude: 0.52153

Collected Steps per Second: 13,810.39632
Overall Steps per Second: 6,662.44255

Timestep Collection Time: 3.62118
Timestep Consumption Time: 3.88507
PPO Batch Consumption Time: 0.48951
Total Iteration Time: 7.50626

Cumulative Model Updates: 4,926
Cumulative Timesteps: 41,113,280

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 41113280...
Checkpoint 41113280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03185
Policy Entropy: 4.27843
Value Function Loss: 0.05921

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04386
Policy Update Magnitude: 0.66556
Value Function Update Magnitude: 0.50658

Collected Steps per Second: 14,258.01606
Overall Steps per Second: 6,837.70785

Timestep Collection Time: 3.50904
Timestep Consumption Time: 3.80803
PPO Batch Consumption Time: 0.46891
Total Iteration Time: 7.31707

Cumulative Model Updates: 4,932
Cumulative Timesteps: 41,163,312

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06961
Policy Entropy: 4.27837
Value Function Loss: 0.07249

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04210
Policy Update Magnitude: 0.67655
Value Function Update Magnitude: 0.48704

Collected Steps per Second: 14,475.89900
Overall Steps per Second: 6,701.04408

Timestep Collection Time: 3.45512
Timestep Consumption Time: 4.00879
PPO Batch Consumption Time: 0.50039
Total Iteration Time: 7.46391

Cumulative Model Updates: 4,938
Cumulative Timesteps: 41,213,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 41213328...
Checkpoint 41213328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04283
Policy Entropy: 4.28229
Value Function Loss: 0.05584

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03485
Policy Update Magnitude: 0.66281
Value Function Update Magnitude: 0.45732

Collected Steps per Second: 14,151.80923
Overall Steps per Second: 6,755.39072

Timestep Collection Time: 3.53623
Timestep Consumption Time: 3.87178
PPO Batch Consumption Time: 0.48572
Total Iteration Time: 7.40801

Cumulative Model Updates: 4,944
Cumulative Timesteps: 41,263,372

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14980
Policy Entropy: 4.28518
Value Function Loss: 0.05065

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03307
Policy Update Magnitude: 0.63879
Value Function Update Magnitude: 0.41721

Collected Steps per Second: 14,177.00149
Overall Steps per Second: 6,672.48818

Timestep Collection Time: 3.52938
Timestep Consumption Time: 3.96947
PPO Batch Consumption Time: 0.49288
Total Iteration Time: 7.49885

Cumulative Model Updates: 4,950
Cumulative Timesteps: 41,313,408

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 41313408...
Checkpoint 41313408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04372
Policy Entropy: 4.29019
Value Function Loss: 0.04299

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03110
Policy Update Magnitude: 0.62368
Value Function Update Magnitude: 0.38079

Collected Steps per Second: 14,234.50080
Overall Steps per Second: 6,888.05358

Timestep Collection Time: 3.51456
Timestep Consumption Time: 3.74845
PPO Batch Consumption Time: 0.47243
Total Iteration Time: 7.26301

Cumulative Model Updates: 4,956
Cumulative Timesteps: 41,363,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03868
Policy Entropy: 4.29225
Value Function Loss: 0.05130

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03009
Policy Update Magnitude: 0.63297
Value Function Update Magnitude: 0.36070

Collected Steps per Second: 14,347.07596
Overall Steps per Second: 6,793.25074

Timestep Collection Time: 3.48642
Timestep Consumption Time: 3.87677
PPO Batch Consumption Time: 0.47466
Total Iteration Time: 7.36319

Cumulative Model Updates: 4,962
Cumulative Timesteps: 41,413,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 41413456...
Checkpoint 41413456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08527
Policy Entropy: 4.29068
Value Function Loss: 0.05806

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03210
Policy Update Magnitude: 0.64441
Value Function Update Magnitude: 0.39880

Collected Steps per Second: 14,252.06709
Overall Steps per Second: 6,798.34111

Timestep Collection Time: 3.50953
Timestep Consumption Time: 3.84786
PPO Batch Consumption Time: 0.46583
Total Iteration Time: 7.35738

Cumulative Model Updates: 4,968
Cumulative Timesteps: 41,463,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02798
Policy Entropy: 4.29106
Value Function Loss: 0.06369

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.03662
Policy Update Magnitude: 0.64888
Value Function Update Magnitude: 0.41077

Collected Steps per Second: 14,660.38002
Overall Steps per Second: 6,804.00702

Timestep Collection Time: 3.41246
Timestep Consumption Time: 3.94026
PPO Batch Consumption Time: 0.48767
Total Iteration Time: 7.35273

Cumulative Model Updates: 4,974
Cumulative Timesteps: 41,513,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 41513502...
Checkpoint 41513502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04308
Policy Entropy: 4.29027
Value Function Loss: 0.06968

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03478
Policy Update Magnitude: 0.65964
Value Function Update Magnitude: 0.47045

Collected Steps per Second: 14,271.51314
Overall Steps per Second: 6,759.23280

Timestep Collection Time: 3.50404
Timestep Consumption Time: 3.89443
PPO Batch Consumption Time: 0.48187
Total Iteration Time: 7.39847

Cumulative Model Updates: 4,980
Cumulative Timesteps: 41,563,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06803
Policy Entropy: 4.28818
Value Function Loss: 0.06137

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03172
Policy Update Magnitude: 0.64373
Value Function Update Magnitude: 0.47803

Collected Steps per Second: 14,214.43868
Overall Steps per Second: 6,785.27775

Timestep Collection Time: 3.51853
Timestep Consumption Time: 3.85242
PPO Batch Consumption Time: 0.48274
Total Iteration Time: 7.37096

Cumulative Model Updates: 4,986
Cumulative Timesteps: 41,613,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 41613524...
Checkpoint 41613524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00785
Policy Entropy: 4.28549
Value Function Loss: 0.05999

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03391
Policy Update Magnitude: 0.62473
Value Function Update Magnitude: 0.45731

Collected Steps per Second: 14,307.77914
Overall Steps per Second: 6,805.21863

Timestep Collection Time: 3.49502
Timestep Consumption Time: 3.85316
PPO Batch Consumption Time: 0.46935
Total Iteration Time: 7.34818

Cumulative Model Updates: 4,992
Cumulative Timesteps: 41,663,530

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03791
Policy Entropy: 4.29465
Value Function Loss: 0.04669

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03519
Policy Update Magnitude: 0.59482
Value Function Update Magnitude: 0.43233

Collected Steps per Second: 14,318.34064
Overall Steps per Second: 6,770.73625

Timestep Collection Time: 3.49538
Timestep Consumption Time: 3.89643
PPO Batch Consumption Time: 0.48915
Total Iteration Time: 7.39181

Cumulative Model Updates: 4,998
Cumulative Timesteps: 41,713,578

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 41713578...
Checkpoint 41713578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01077
Policy Entropy: 4.30043
Value Function Loss: 0.04476

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03194
Policy Update Magnitude: 0.55594
Value Function Update Magnitude: 0.38749

Collected Steps per Second: 14,246.44092
Overall Steps per Second: 6,762.14047

Timestep Collection Time: 3.51063
Timestep Consumption Time: 3.88555
PPO Batch Consumption Time: 0.47635
Total Iteration Time: 7.39618

Cumulative Model Updates: 5,004
Cumulative Timesteps: 41,763,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02551
Policy Entropy: 4.30322
Value Function Loss: 0.03944

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02380
Policy Update Magnitude: 0.54159
Value Function Update Magnitude: 0.37497

Collected Steps per Second: 14,329.98251
Overall Steps per Second: 6,773.81510

Timestep Collection Time: 3.49086
Timestep Consumption Time: 3.89405
PPO Batch Consumption Time: 0.48559
Total Iteration Time: 7.38491

Cumulative Model Updates: 5,010
Cumulative Timesteps: 41,813,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 41813616...
Checkpoint 41813616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15075
Policy Entropy: 4.29826
Value Function Loss: 0.03668

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.54001
Value Function Update Magnitude: 0.38339

Collected Steps per Second: 14,689.29339
Overall Steps per Second: 6,806.62476

Timestep Collection Time: 3.40384
Timestep Consumption Time: 3.94194
PPO Batch Consumption Time: 0.48592
Total Iteration Time: 7.34578

Cumulative Model Updates: 5,016
Cumulative Timesteps: 41,863,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19168
Policy Entropy: 4.29277
Value Function Loss: 0.04313

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.54945
Value Function Update Magnitude: 0.40713

Collected Steps per Second: 14,419.47136
Overall Steps per Second: 6,864.23302

Timestep Collection Time: 3.46753
Timestep Consumption Time: 3.81660
PPO Batch Consumption Time: 0.46702
Total Iteration Time: 7.28413

Cumulative Model Updates: 5,022
Cumulative Timesteps: 41,913,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 41913616...
Checkpoint 41913616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07594
Policy Entropy: 4.29077
Value Function Loss: 0.04240

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02891
Policy Update Magnitude: 0.57984
Value Function Update Magnitude: 0.45154

Collected Steps per Second: 14,483.52484
Overall Steps per Second: 6,863.69186

Timestep Collection Time: 3.45234
Timestep Consumption Time: 3.83266
PPO Batch Consumption Time: 0.47351
Total Iteration Time: 7.28500

Cumulative Model Updates: 5,028
Cumulative Timesteps: 41,963,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.32470
Policy Entropy: 4.28945
Value Function Loss: 0.05226

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03285
Policy Update Magnitude: 0.60684
Value Function Update Magnitude: 0.47062

Collected Steps per Second: 14,251.32265
Overall Steps per Second: 6,868.37659

Timestep Collection Time: 3.50999
Timestep Consumption Time: 3.77295
PPO Batch Consumption Time: 0.46014
Total Iteration Time: 7.28294

Cumulative Model Updates: 5,034
Cumulative Timesteps: 42,013,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 42013640...
Checkpoint 42013640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03796
Policy Entropy: 4.29142
Value Function Loss: 0.04588

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03485
Policy Update Magnitude: 0.61207
Value Function Update Magnitude: 0.48842

Collected Steps per Second: 14,256.81845
Overall Steps per Second: 6,805.61292

Timestep Collection Time: 3.50906
Timestep Consumption Time: 3.84193
PPO Batch Consumption Time: 0.48328
Total Iteration Time: 7.35099

Cumulative Model Updates: 5,040
Cumulative Timesteps: 42,063,668

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10904
Policy Entropy: 4.29431
Value Function Loss: 0.04229

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03206
Policy Update Magnitude: 0.58643
Value Function Update Magnitude: 0.49679

Collected Steps per Second: 14,076.85716
Overall Steps per Second: 6,626.31163

Timestep Collection Time: 3.55193
Timestep Consumption Time: 3.99375
PPO Batch Consumption Time: 0.49782
Total Iteration Time: 7.54568

Cumulative Model Updates: 5,046
Cumulative Timesteps: 42,113,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 42113668...
Checkpoint 42113668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21347
Policy Entropy: 4.29002
Value Function Loss: 0.04463

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03233
Policy Update Magnitude: 0.58367
Value Function Update Magnitude: 0.46976

Collected Steps per Second: 14,255.68806
Overall Steps per Second: 6,748.30886

Timestep Collection Time: 3.50793
Timestep Consumption Time: 3.90252
PPO Batch Consumption Time: 0.47554
Total Iteration Time: 7.41045

Cumulative Model Updates: 5,052
Cumulative Timesteps: 42,163,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04196
Policy Entropy: 4.29773
Value Function Loss: 0.04837

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03646
Policy Update Magnitude: 0.59984
Value Function Update Magnitude: 0.39547

Collected Steps per Second: 14,246.14135
Overall Steps per Second: 6,768.52503

Timestep Collection Time: 3.50972
Timestep Consumption Time: 3.87741
PPO Batch Consumption Time: 0.48825
Total Iteration Time: 7.38713

Cumulative Model Updates: 5,058
Cumulative Timesteps: 42,213,676

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 42213676...
Checkpoint 42213676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01385
Policy Entropy: 4.29707
Value Function Loss: 0.05586

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03331
Policy Update Magnitude: 0.58984
Value Function Update Magnitude: 0.39683

Collected Steps per Second: 14,214.79215
Overall Steps per Second: 6,737.91956

Timestep Collection Time: 3.51915
Timestep Consumption Time: 3.90510
PPO Batch Consumption Time: 0.47653
Total Iteration Time: 7.42425

Cumulative Model Updates: 5,064
Cumulative Timesteps: 42,263,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05404
Policy Entropy: 4.30163
Value Function Loss: 0.05253

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03062
Policy Update Magnitude: 0.59072
Value Function Update Magnitude: 0.43601

Collected Steps per Second: 14,438.95003
Overall Steps per Second: 6,835.11732

Timestep Collection Time: 3.46507
Timestep Consumption Time: 3.85477
PPO Batch Consumption Time: 0.48568
Total Iteration Time: 7.31985

Cumulative Model Updates: 5,070
Cumulative Timesteps: 42,313,732

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 42313732...
Checkpoint 42313732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06755
Policy Entropy: 4.29902
Value Function Loss: 0.05378

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03155
Policy Update Magnitude: 0.59358
Value Function Update Magnitude: 0.44126

Collected Steps per Second: 14,175.91805
Overall Steps per Second: 6,726.45948

Timestep Collection Time: 3.52824
Timestep Consumption Time: 3.90747
PPO Batch Consumption Time: 0.47643
Total Iteration Time: 7.43571

Cumulative Model Updates: 5,076
Cumulative Timesteps: 42,363,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03064
Policy Entropy: 4.29854
Value Function Loss: 0.06381

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03513
Policy Update Magnitude: 0.62486
Value Function Update Magnitude: 0.42101

Collected Steps per Second: 14,348.20763
Overall Steps per Second: 6,718.31982

Timestep Collection Time: 3.48643
Timestep Consumption Time: 3.95948
PPO Batch Consumption Time: 0.49563
Total Iteration Time: 7.44591

Cumulative Model Updates: 5,082
Cumulative Timesteps: 42,413,772

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 42413772...
Checkpoint 42413772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00294
Policy Entropy: 4.29882
Value Function Loss: 0.06266

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03815
Policy Update Magnitude: 0.63342
Value Function Update Magnitude: 0.45552

Collected Steps per Second: 14,469.18364
Overall Steps per Second: 6,776.00589

Timestep Collection Time: 3.45576
Timestep Consumption Time: 3.92352
PPO Batch Consumption Time: 0.48737
Total Iteration Time: 7.37927

Cumulative Model Updates: 5,088
Cumulative Timesteps: 42,463,774

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13562
Policy Entropy: 4.29388
Value Function Loss: 0.05662

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03801
Policy Update Magnitude: 0.64184
Value Function Update Magnitude: 0.46049

Collected Steps per Second: 14,216.37700
Overall Steps per Second: 6,730.22488

Timestep Collection Time: 3.51862
Timestep Consumption Time: 3.91382
PPO Batch Consumption Time: 0.47588
Total Iteration Time: 7.43244

Cumulative Model Updates: 5,094
Cumulative Timesteps: 42,513,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 42513796...
Checkpoint 42513796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01084
Policy Entropy: 4.29565
Value Function Loss: 0.04847

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03656
Policy Update Magnitude: 0.62299
Value Function Update Magnitude: 0.47217

Collected Steps per Second: 14,084.03453
Overall Steps per Second: 6,749.28703

Timestep Collection Time: 3.55012
Timestep Consumption Time: 3.85807
PPO Batch Consumption Time: 0.47662
Total Iteration Time: 7.40819

Cumulative Model Updates: 5,100
Cumulative Timesteps: 42,563,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11049
Policy Entropy: 4.29794
Value Function Loss: 0.04557

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03785
Policy Update Magnitude: 0.58679
Value Function Update Magnitude: 0.44611

Collected Steps per Second: 14,232.38775
Overall Steps per Second: 6,720.49007

Timestep Collection Time: 3.51396
Timestep Consumption Time: 3.92776
PPO Batch Consumption Time: 0.48231
Total Iteration Time: 7.44172

Cumulative Model Updates: 5,106
Cumulative Timesteps: 42,613,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 42613808...
Checkpoint 42613808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21865
Policy Entropy: 4.29590
Value Function Loss: 0.04995

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03272
Policy Update Magnitude: 0.59011
Value Function Update Magnitude: 0.46459

Collected Steps per Second: 14,212.46098
Overall Steps per Second: 6,789.25482

Timestep Collection Time: 3.51959
Timestep Consumption Time: 3.84823
PPO Batch Consumption Time: 0.47379
Total Iteration Time: 7.36782

Cumulative Model Updates: 5,112
Cumulative Timesteps: 42,663,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04727
Policy Entropy: 4.30235
Value Function Loss: 0.03849

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03332
Policy Update Magnitude: 0.58880
Value Function Update Magnitude: 0.47811

Collected Steps per Second: 14,526.62106
Overall Steps per Second: 6,734.03774

Timestep Collection Time: 3.44292
Timestep Consumption Time: 3.98412
PPO Batch Consumption Time: 0.49177
Total Iteration Time: 7.42704

Cumulative Model Updates: 5,118
Cumulative Timesteps: 42,713,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 42713844...
Checkpoint 42713844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10305
Policy Entropy: 4.30927
Value Function Loss: 0.03597

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02866
Policy Update Magnitude: 0.55613
Value Function Update Magnitude: 0.45098

Collected Steps per Second: 13,977.80562
Overall Steps per Second: 6,709.05128

Timestep Collection Time: 3.57882
Timestep Consumption Time: 3.87738
PPO Batch Consumption Time: 0.48109
Total Iteration Time: 7.45620

Cumulative Model Updates: 5,124
Cumulative Timesteps: 42,763,868

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04407
Policy Entropy: 4.31572
Value Function Loss: 0.03945

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.55153
Value Function Update Magnitude: 0.43793

Collected Steps per Second: 14,364.59489
Overall Steps per Second: 6,865.20708

Timestep Collection Time: 3.48134
Timestep Consumption Time: 3.80293
PPO Batch Consumption Time: 0.47238
Total Iteration Time: 7.28427

Cumulative Model Updates: 5,130
Cumulative Timesteps: 42,813,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 42813876...
Checkpoint 42813876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13650
Policy Entropy: 4.30667
Value Function Loss: 0.04900

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02945
Policy Update Magnitude: 0.57865
Value Function Update Magnitude: 0.46069

Collected Steps per Second: 14,204.57249
Overall Steps per Second: 6,721.71712

Timestep Collection Time: 3.52013
Timestep Consumption Time: 3.91874
PPO Batch Consumption Time: 0.47714
Total Iteration Time: 7.43887

Cumulative Model Updates: 5,136
Cumulative Timesteps: 42,863,878

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12130
Policy Entropy: 4.30496
Value Function Loss: 0.05115

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03265
Policy Update Magnitude: 0.59761
Value Function Update Magnitude: 0.48435

Collected Steps per Second: 14,314.49867
Overall Steps per Second: 6,767.59985

Timestep Collection Time: 3.49366
Timestep Consumption Time: 3.89596
PPO Batch Consumption Time: 0.49036
Total Iteration Time: 7.38962

Cumulative Model Updates: 5,142
Cumulative Timesteps: 42,913,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 42913888...
Checkpoint 42913888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04233
Policy Entropy: 4.29734
Value Function Loss: 0.05770

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03803
Policy Update Magnitude: 0.62024
Value Function Update Magnitude: 0.49882

Collected Steps per Second: 15,026.29060
Overall Steps per Second: 7,130.59011

Timestep Collection Time: 3.32950
Timestep Consumption Time: 3.68675
PPO Batch Consumption Time: 0.46825
Total Iteration Time: 7.01625

Cumulative Model Updates: 5,148
Cumulative Timesteps: 42,963,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02428
Policy Entropy: 4.29342
Value Function Loss: 0.05656

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04112
Policy Update Magnitude: 0.65628
Value Function Update Magnitude: 0.51267

Collected Steps per Second: 14,280.30326
Overall Steps per Second: 6,744.63717

Timestep Collection Time: 3.50343
Timestep Consumption Time: 3.91432
PPO Batch Consumption Time: 0.48205
Total Iteration Time: 7.41775

Cumulative Model Updates: 5,154
Cumulative Timesteps: 43,013,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 43013948...
Checkpoint 43013948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.20471
Policy Entropy: 4.29557
Value Function Loss: 0.04770

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.03896
Policy Update Magnitude: 0.64270
Value Function Update Magnitude: 0.48028

Collected Steps per Second: 14,570.71400
Overall Steps per Second: 6,747.03188

Timestep Collection Time: 3.43236
Timestep Consumption Time: 3.98008
PPO Batch Consumption Time: 0.49531
Total Iteration Time: 7.41244

Cumulative Model Updates: 5,160
Cumulative Timesteps: 43,063,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06198
Policy Entropy: 4.30101
Value Function Loss: 0.04104

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03292
Policy Update Magnitude: 0.58978
Value Function Update Magnitude: 0.43447

Collected Steps per Second: 14,238.04115
Overall Steps per Second: 6,825.25047

Timestep Collection Time: 3.51228
Timestep Consumption Time: 3.81463
PPO Batch Consumption Time: 0.46603
Total Iteration Time: 7.32691

Cumulative Model Updates: 5,166
Cumulative Timesteps: 43,113,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 43113968...
Checkpoint 43113968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04578
Policy Entropy: 4.30998
Value Function Loss: 0.03442

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02939
Policy Update Magnitude: 0.54405
Value Function Update Magnitude: 0.38244

Collected Steps per Second: 14,205.00693
Overall Steps per Second: 6,862.54396

Timestep Collection Time: 3.52129
Timestep Consumption Time: 3.76755
PPO Batch Consumption Time: 0.47423
Total Iteration Time: 7.28884

Cumulative Model Updates: 5,172
Cumulative Timesteps: 43,163,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04823
Policy Entropy: 4.30647
Value Function Loss: 0.03898

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02824
Policy Update Magnitude: 0.52811
Value Function Update Magnitude: 0.34640

Collected Steps per Second: 14,281.09103
Overall Steps per Second: 6,817.74158

Timestep Collection Time: 3.50309
Timestep Consumption Time: 3.83482
PPO Batch Consumption Time: 0.46857
Total Iteration Time: 7.33791

Cumulative Model Updates: 5,178
Cumulative Timesteps: 43,214,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 43214016...
Checkpoint 43214016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00325
Policy Entropy: 4.30353
Value Function Loss: 0.03844

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02288
Policy Update Magnitude: 0.53749
Value Function Update Magnitude: 0.36716

Collected Steps per Second: 14,067.11673
Overall Steps per Second: 6,665.57662

Timestep Collection Time: 3.55524
Timestep Consumption Time: 3.94779
PPO Batch Consumption Time: 0.50154
Total Iteration Time: 7.50303

Cumulative Model Updates: 5,184
Cumulative Timesteps: 43,264,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01993
Policy Entropy: 4.30460
Value Function Loss: 0.03704

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02763
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.35874

Collected Steps per Second: 14,315.89648
Overall Steps per Second: 6,773.37252

Timestep Collection Time: 3.49402
Timestep Consumption Time: 3.89078
PPO Batch Consumption Time: 0.48120
Total Iteration Time: 7.38480

Cumulative Model Updates: 5,190
Cumulative Timesteps: 43,314,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 43314048...
Checkpoint 43314048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08019
Policy Entropy: 4.30843
Value Function Loss: 0.03263

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03257
Policy Update Magnitude: 0.52190
Value Function Update Magnitude: 0.33721

Collected Steps per Second: 14,404.24227
Overall Steps per Second: 6,763.89861

Timestep Collection Time: 3.47120
Timestep Consumption Time: 3.92099
PPO Batch Consumption Time: 0.48028
Total Iteration Time: 7.39219

Cumulative Model Updates: 5,196
Cumulative Timesteps: 43,364,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00999
Policy Entropy: 4.31006
Value Function Loss: 0.04015

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03437
Policy Update Magnitude: 0.51715
Value Function Update Magnitude: 0.36729

Collected Steps per Second: 14,709.79867
Overall Steps per Second: 6,776.11358

Timestep Collection Time: 3.40018
Timestep Consumption Time: 3.98104
PPO Batch Consumption Time: 0.49712
Total Iteration Time: 7.38122

Cumulative Model Updates: 5,202
Cumulative Timesteps: 43,414,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 43414064...
Checkpoint 43414064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01242
Policy Entropy: 4.30773
Value Function Loss: 0.04459

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03573
Policy Update Magnitude: 0.54467
Value Function Update Magnitude: 0.37070

Collected Steps per Second: 14,347.32950
Overall Steps per Second: 6,848.93400

Timestep Collection Time: 3.48525
Timestep Consumption Time: 3.81574
PPO Batch Consumption Time: 0.46826
Total Iteration Time: 7.30099

Cumulative Model Updates: 5,208
Cumulative Timesteps: 43,464,068

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11169
Policy Entropy: 4.30868
Value Function Loss: 0.04689

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03794
Policy Update Magnitude: 0.54285
Value Function Update Magnitude: 0.33861

Collected Steps per Second: 14,386.41202
Overall Steps per Second: 6,865.25100

Timestep Collection Time: 3.47731
Timestep Consumption Time: 3.80953
PPO Batch Consumption Time: 0.47607
Total Iteration Time: 7.28684

Cumulative Model Updates: 5,214
Cumulative Timesteps: 43,514,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 43514094...
Checkpoint 43514094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03260
Policy Entropy: 4.31364
Value Function Loss: 0.04571

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02524
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.36052

Collected Steps per Second: 14,401.01505
Overall Steps per Second: 6,754.52173

Timestep Collection Time: 3.47253
Timestep Consumption Time: 3.93110
PPO Batch Consumption Time: 0.48212
Total Iteration Time: 7.40363

Cumulative Model Updates: 5,220
Cumulative Timesteps: 43,564,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05963
Policy Entropy: 4.31630
Value Function Loss: 0.04339

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.56464
Value Function Update Magnitude: 0.38000

Collected Steps per Second: 14,302.89678
Overall Steps per Second: 6,705.41505

Timestep Collection Time: 3.49691
Timestep Consumption Time: 3.96213
PPO Batch Consumption Time: 0.48580
Total Iteration Time: 7.45905

Cumulative Model Updates: 5,226
Cumulative Timesteps: 43,614,118

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 43614118...
Checkpoint 43614118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10852
Policy Entropy: 4.31114
Value Function Loss: 0.05283

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02908
Policy Update Magnitude: 0.55644
Value Function Update Magnitude: 0.32644

Collected Steps per Second: 14,535.58118
Overall Steps per Second: 6,791.43754

Timestep Collection Time: 3.44066
Timestep Consumption Time: 3.92332
PPO Batch Consumption Time: 0.48017
Total Iteration Time: 7.36398

Cumulative Model Updates: 5,232
Cumulative Timesteps: 43,664,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04053
Policy Entropy: 4.30791
Value Function Loss: 0.05540

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03249
Policy Update Magnitude: 0.59856
Value Function Update Magnitude: 0.28263

Collected Steps per Second: 14,358.72298
Overall Steps per Second: 6,701.96224

Timestep Collection Time: 3.48360
Timestep Consumption Time: 3.97989
PPO Batch Consumption Time: 0.48824
Total Iteration Time: 7.46349

Cumulative Model Updates: 5,238
Cumulative Timesteps: 43,714,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 43714150...
Checkpoint 43714150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08994
Policy Entropy: 4.30292
Value Function Loss: 0.05766

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03605
Policy Update Magnitude: 0.60579
Value Function Update Magnitude: 0.27676

Collected Steps per Second: 14,328.27199
Overall Steps per Second: 6,839.14701

Timestep Collection Time: 3.48988
Timestep Consumption Time: 3.82155
PPO Batch Consumption Time: 0.47991
Total Iteration Time: 7.31144

Cumulative Model Updates: 5,244
Cumulative Timesteps: 43,764,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08086
Policy Entropy: 4.30327
Value Function Loss: 0.06121

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03352
Policy Update Magnitude: 0.62088
Value Function Update Magnitude: 0.34166

Collected Steps per Second: 14,300.35586
Overall Steps per Second: 6,749.26294

Timestep Collection Time: 3.49670
Timestep Consumption Time: 3.91211
PPO Batch Consumption Time: 0.47735
Total Iteration Time: 7.40881

Cumulative Model Updates: 5,250
Cumulative Timesteps: 43,814,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 43814158...
Checkpoint 43814158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00509
Policy Entropy: 4.29818
Value Function Loss: 0.06164

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03904
Policy Update Magnitude: 0.63990
Value Function Update Magnitude: 0.40564

Collected Steps per Second: 14,225.65172
Overall Steps per Second: 6,746.35700

Timestep Collection Time: 3.51885
Timestep Consumption Time: 3.90115
PPO Batch Consumption Time: 0.48254
Total Iteration Time: 7.42000

Cumulative Model Updates: 5,256
Cumulative Timesteps: 43,864,216

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03071
Policy Entropy: 4.29922
Value Function Loss: 0.05852

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03928
Policy Update Magnitude: 0.64904
Value Function Update Magnitude: 0.44858

Collected Steps per Second: 14,613.74460
Overall Steps per Second: 6,720.50163

Timestep Collection Time: 3.42226
Timestep Consumption Time: 4.01945
PPO Batch Consumption Time: 0.50195
Total Iteration Time: 7.44171

Cumulative Model Updates: 5,262
Cumulative Timesteps: 43,914,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 43914228...
Checkpoint 43914228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14210
Policy Entropy: 4.29720
Value Function Loss: 0.04807

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04479
Policy Update Magnitude: 0.61531
Value Function Update Magnitude: 0.45844

Collected Steps per Second: 14,218.33180
Overall Steps per Second: 6,743.28264

Timestep Collection Time: 3.51715
Timestep Consumption Time: 3.89882
PPO Batch Consumption Time: 0.48117
Total Iteration Time: 7.41597

Cumulative Model Updates: 5,268
Cumulative Timesteps: 43,964,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01310
Policy Entropy: 4.29580
Value Function Loss: 0.04253

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.03813
Policy Update Magnitude: 0.58291
Value Function Update Magnitude: 0.45454

Collected Steps per Second: 14,328.87983
Overall Steps per Second: 6,810.58514

Timestep Collection Time: 3.48946
Timestep Consumption Time: 3.85206
PPO Batch Consumption Time: 0.47851
Total Iteration Time: 7.34151

Cumulative Model Updates: 5,274
Cumulative Timesteps: 44,014,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 44014236...
Checkpoint 44014236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02549
Policy Entropy: 4.29554
Value Function Loss: 0.04027

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03817
Policy Update Magnitude: 0.57149
Value Function Update Magnitude: 0.43009

Collected Steps per Second: 14,236.31346
Overall Steps per Second: 6,737.28146

Timestep Collection Time: 3.51215
Timestep Consumption Time: 3.90925
PPO Batch Consumption Time: 0.47483
Total Iteration Time: 7.42139

Cumulative Model Updates: 5,280
Cumulative Timesteps: 44,064,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09050
Policy Entropy: 4.29663
Value Function Loss: 0.04710

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03478
Policy Update Magnitude: 0.58011
Value Function Update Magnitude: 0.45482

Collected Steps per Second: 14,452.28946
Overall Steps per Second: 6,693.84025

Timestep Collection Time: 3.46132
Timestep Consumption Time: 4.01182
PPO Batch Consumption Time: 0.50119
Total Iteration Time: 7.47314

Cumulative Model Updates: 5,286
Cumulative Timesteps: 44,114,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 44114260...
Checkpoint 44114260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09091
Policy Entropy: 4.30510
Value Function Loss: 0.04353

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03530
Policy Update Magnitude: 0.61769
Value Function Update Magnitude: 0.46631

Collected Steps per Second: 14,604.61366
Overall Steps per Second: 6,801.98566

Timestep Collection Time: 3.42495
Timestep Consumption Time: 3.92879
PPO Batch Consumption Time: 0.48257
Total Iteration Time: 7.35373

Cumulative Model Updates: 5,292
Cumulative Timesteps: 44,164,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03325
Policy Entropy: 4.30174
Value Function Loss: 0.05016

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04416
Policy Update Magnitude: 0.63824
Value Function Update Magnitude: 0.46322

Collected Steps per Second: 14,471.09661
Overall Steps per Second: 6,766.90600

Timestep Collection Time: 3.45585
Timestep Consumption Time: 3.93452
PPO Batch Consumption Time: 0.47987
Total Iteration Time: 7.39038

Cumulative Model Updates: 5,298
Cumulative Timesteps: 44,214,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 44214290...
Checkpoint 44214290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00087
Policy Entropy: 4.30902
Value Function Loss: 0.05197

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04332
Policy Update Magnitude: 0.64501
Value Function Update Magnitude: 0.48781

Collected Steps per Second: 14,303.49585
Overall Steps per Second: 6,817.43383

Timestep Collection Time: 3.49817
Timestep Consumption Time: 3.84125
PPO Batch Consumption Time: 0.48325
Total Iteration Time: 7.33942

Cumulative Model Updates: 5,304
Cumulative Timesteps: 44,264,326

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00289
Policy Entropy: 4.30236
Value Function Loss: 0.06124

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03913
Policy Update Magnitude: 0.66177
Value Function Update Magnitude: 0.46735

Collected Steps per Second: 14,372.98747
Overall Steps per Second: 6,779.12731

Timestep Collection Time: 3.47986
Timestep Consumption Time: 3.89808
PPO Batch Consumption Time: 0.48102
Total Iteration Time: 7.37794

Cumulative Model Updates: 5,310
Cumulative Timesteps: 44,314,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 44314342...
Checkpoint 44314342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07109
Policy Entropy: 4.29993
Value Function Loss: 0.05721

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03336
Policy Update Magnitude: 0.66947
Value Function Update Magnitude: 0.42878

Collected Steps per Second: 14,314.75660
Overall Steps per Second: 6,746.10942

Timestep Collection Time: 3.49318
Timestep Consumption Time: 3.91909
PPO Batch Consumption Time: 0.48930
Total Iteration Time: 7.41227

Cumulative Model Updates: 5,316
Cumulative Timesteps: 44,364,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04235
Policy Entropy: 4.29385
Value Function Loss: 0.06166

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03661
Policy Update Magnitude: 0.67551
Value Function Update Magnitude: 0.44316

Collected Steps per Second: 14,756.18232
Overall Steps per Second: 6,801.47715

Timestep Collection Time: 3.39180
Timestep Consumption Time: 3.96690
PPO Batch Consumption Time: 0.48826
Total Iteration Time: 7.35870

Cumulative Model Updates: 5,322
Cumulative Timesteps: 44,414,396

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 44414396...
Checkpoint 44414396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05289
Policy Entropy: 4.29443
Value Function Loss: 0.04990

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03583
Policy Update Magnitude: 0.66792
Value Function Update Magnitude: 0.45016

Collected Steps per Second: 14,225.59995
Overall Steps per Second: 6,755.11748

Timestep Collection Time: 3.51563
Timestep Consumption Time: 3.88794
PPO Batch Consumption Time: 0.48215
Total Iteration Time: 7.40357

Cumulative Model Updates: 5,328
Cumulative Timesteps: 44,464,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19443
Policy Entropy: 4.29690
Value Function Loss: 0.04777

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03220
Policy Update Magnitude: 0.62748
Value Function Update Magnitude: 0.44488

Collected Steps per Second: 14,357.04634
Overall Steps per Second: 6,797.77376

Timestep Collection Time: 3.48331
Timestep Consumption Time: 3.87351
PPO Batch Consumption Time: 0.48189
Total Iteration Time: 7.35682

Cumulative Model Updates: 5,334
Cumulative Timesteps: 44,514,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 44514418...
Checkpoint 44514418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10455
Policy Entropy: 4.29804
Value Function Loss: 0.04142

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03105
Policy Update Magnitude: 0.61274
Value Function Update Magnitude: 0.43036

Collected Steps per Second: 14,291.63250
Overall Steps per Second: 6,846.41431

Timestep Collection Time: 3.50009
Timestep Consumption Time: 3.80622
PPO Batch Consumption Time: 0.46146
Total Iteration Time: 7.30631

Cumulative Model Updates: 5,340
Cumulative Timesteps: 44,564,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01789
Policy Entropy: 4.29540
Value Function Loss: 0.04241

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02829
Policy Update Magnitude: 0.62142
Value Function Update Magnitude: 0.42709

Collected Steps per Second: 14,509.73079
Overall Steps per Second: 6,866.33847

Timestep Collection Time: 3.44734
Timestep Consumption Time: 3.83747
PPO Batch Consumption Time: 0.47466
Total Iteration Time: 7.28481

Cumulative Model Updates: 5,346
Cumulative Timesteps: 44,614,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 44614460...
Checkpoint 44614460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.27681
Policy Entropy: 4.29539
Value Function Loss: 0.05798

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02866
Policy Update Magnitude: 0.65317
Value Function Update Magnitude: 0.46935

Collected Steps per Second: 14,490.75796
Overall Steps per Second: 6,732.77548

Timestep Collection Time: 3.45241
Timestep Consumption Time: 3.97811
PPO Batch Consumption Time: 0.49518
Total Iteration Time: 7.43052

Cumulative Model Updates: 5,352
Cumulative Timesteps: 44,664,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22791
Policy Entropy: 4.29508
Value Function Loss: 0.06374

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 0.70759
Value Function Update Magnitude: 0.51151

Collected Steps per Second: 14,574.53051
Overall Steps per Second: 6,809.50576

Timestep Collection Time: 3.43256
Timestep Consumption Time: 3.91423
PPO Batch Consumption Time: 0.47437
Total Iteration Time: 7.34679

Cumulative Model Updates: 5,358
Cumulative Timesteps: 44,714,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 44714516...
Checkpoint 44714516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09706
Policy Entropy: 4.28710
Value Function Loss: 0.07712

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03901
Policy Update Magnitude: 0.73099
Value Function Update Magnitude: 0.50813

Collected Steps per Second: 14,335.83941
Overall Steps per Second: 6,815.38239

Timestep Collection Time: 3.48930
Timestep Consumption Time: 3.85028
PPO Batch Consumption Time: 0.48759
Total Iteration Time: 7.33957

Cumulative Model Updates: 5,364
Cumulative Timesteps: 44,764,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06213
Policy Entropy: 4.28820
Value Function Loss: 0.07108

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03905
Policy Update Magnitude: 0.74541
Value Function Update Magnitude: 0.51138

Collected Steps per Second: 14,322.49939
Overall Steps per Second: 6,844.01757

Timestep Collection Time: 3.49241
Timestep Consumption Time: 3.81617
PPO Batch Consumption Time: 0.47341
Total Iteration Time: 7.30857

Cumulative Model Updates: 5,370
Cumulative Timesteps: 44,814,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 44814558...
Checkpoint 44814558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09373
Policy Entropy: 4.28916
Value Function Loss: 0.06190

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04042
Policy Update Magnitude: 0.72267
Value Function Update Magnitude: 0.52399

Collected Steps per Second: 14,220.49246
Overall Steps per Second: 6,791.39212

Timestep Collection Time: 3.51760
Timestep Consumption Time: 3.84790
PPO Batch Consumption Time: 0.48586
Total Iteration Time: 7.36550

Cumulative Model Updates: 5,376
Cumulative Timesteps: 44,864,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08002
Policy Entropy: 4.29275
Value Function Loss: 0.04884

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03622
Policy Update Magnitude: 0.65785
Value Function Update Magnitude: 0.48257

Collected Steps per Second: 14,211.36257
Overall Steps per Second: 6,672.65507

Timestep Collection Time: 3.51972
Timestep Consumption Time: 3.97655
PPO Batch Consumption Time: 0.48807
Total Iteration Time: 7.49627

Cumulative Model Updates: 5,382
Cumulative Timesteps: 44,914,600

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 44914600...
Checkpoint 44914600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04892
Policy Entropy: 4.29601
Value Function Loss: 0.03977

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03574
Policy Update Magnitude: 0.61667
Value Function Update Magnitude: 0.47040

Collected Steps per Second: 14,133.47887
Overall Steps per Second: 6,780.16737

Timestep Collection Time: 3.53911
Timestep Consumption Time: 3.83828
PPO Batch Consumption Time: 0.47336
Total Iteration Time: 7.37740

Cumulative Model Updates: 5,388
Cumulative Timesteps: 44,964,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07467
Policy Entropy: 4.29223
Value Function Loss: 0.03612

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03648
Policy Update Magnitude: 0.60085
Value Function Update Magnitude: 0.44361

Collected Steps per Second: 14,512.55481
Overall Steps per Second: 6,820.97574

Timestep Collection Time: 3.44695
Timestep Consumption Time: 3.88690
PPO Batch Consumption Time: 0.47270
Total Iteration Time: 7.33385

Cumulative Model Updates: 5,394
Cumulative Timesteps: 45,014,644

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 45014644...
Checkpoint 45014644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01440
Policy Entropy: 4.29985
Value Function Loss: 0.03315

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03668
Policy Update Magnitude: 0.57109
Value Function Update Magnitude: 0.38698

Collected Steps per Second: 14,060.46568
Overall Steps per Second: 6,688.52739

Timestep Collection Time: 3.55778
Timestep Consumption Time: 3.92130
PPO Batch Consumption Time: 0.47828
Total Iteration Time: 7.47908

Cumulative Model Updates: 5,400
Cumulative Timesteps: 45,064,668

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02186
Policy Entropy: 4.30834
Value Function Loss: 0.03047

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 0.53687
Value Function Update Magnitude: 0.39871

Collected Steps per Second: 14,277.07681
Overall Steps per Second: 6,801.09334

Timestep Collection Time: 3.50268
Timestep Consumption Time: 3.85026
PPO Batch Consumption Time: 0.47826
Total Iteration Time: 7.35294

Cumulative Model Updates: 5,406
Cumulative Timesteps: 45,114,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 45114676...
Checkpoint 45114676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19446
Policy Entropy: 4.31027
Value Function Loss: 0.04096

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03038
Policy Update Magnitude: 0.55634
Value Function Update Magnitude: 0.41101

Collected Steps per Second: 14,208.82013
Overall Steps per Second: 6,702.96517

Timestep Collection Time: 3.52133
Timestep Consumption Time: 3.94312
PPO Batch Consumption Time: 0.48110
Total Iteration Time: 7.46446

Cumulative Model Updates: 5,412
Cumulative Timesteps: 45,164,710

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01495
Policy Entropy: 4.30647
Value Function Loss: 0.04212

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03452
Policy Update Magnitude: 0.59723
Value Function Update Magnitude: 0.47764

Collected Steps per Second: 14,319.60037
Overall Steps per Second: 6,785.56102

Timestep Collection Time: 3.49242
Timestep Consumption Time: 3.87765
PPO Batch Consumption Time: 0.48320
Total Iteration Time: 7.37006

Cumulative Model Updates: 5,418
Cumulative Timesteps: 45,214,720

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 45214720...
Checkpoint 45214720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.23054
Policy Entropy: 4.30711
Value Function Loss: 0.04577

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03635
Policy Update Magnitude: 0.59409
Value Function Update Magnitude: 0.45944

Collected Steps per Second: 14,164.43753
Overall Steps per Second: 6,724.52720

Timestep Collection Time: 3.53081
Timestep Consumption Time: 3.90644
PPO Batch Consumption Time: 0.47854
Total Iteration Time: 7.43725

Cumulative Model Updates: 5,424
Cumulative Timesteps: 45,264,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02998
Policy Entropy: 4.30305
Value Function Loss: 0.03810

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03208
Policy Update Magnitude: 0.57316
Value Function Update Magnitude: 0.41484

Collected Steps per Second: 14,210.45166
Overall Steps per Second: 6,731.73454

Timestep Collection Time: 3.52023
Timestep Consumption Time: 3.91085
PPO Batch Consumption Time: 0.48523
Total Iteration Time: 7.43107

Cumulative Model Updates: 5,430
Cumulative Timesteps: 45,314,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 45314756...
Checkpoint 45314756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01852
Policy Entropy: 4.30917
Value Function Loss: 0.04154

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02837
Policy Update Magnitude: 0.56908
Value Function Update Magnitude: 0.43748

Collected Steps per Second: 14,570.24409
Overall Steps per Second: 6,758.09552

Timestep Collection Time: 3.43206
Timestep Consumption Time: 3.96736
PPO Batch Consumption Time: 0.48476
Total Iteration Time: 7.39942

Cumulative Model Updates: 5,436
Cumulative Timesteps: 45,364,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04670
Policy Entropy: 4.31230
Value Function Loss: 0.04129

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03428
Policy Update Magnitude: 0.58271
Value Function Update Magnitude: 0.47854

Collected Steps per Second: 14,489.95069
Overall Steps per Second: 6,784.82225

Timestep Collection Time: 3.45136
Timestep Consumption Time: 3.91951
PPO Batch Consumption Time: 0.48052
Total Iteration Time: 7.37086

Cumulative Model Updates: 5,442
Cumulative Timesteps: 45,414,772

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 45414772...
Checkpoint 45414772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03915
Policy Entropy: 4.31943
Value Function Loss: 0.03926

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 0.59180
Value Function Update Magnitude: 0.52157

Collected Steps per Second: 14,151.67743
Overall Steps per Second: 6,755.47060

Timestep Collection Time: 3.53499
Timestep Consumption Time: 3.87027
PPO Batch Consumption Time: 0.48323
Total Iteration Time: 7.40526

Cumulative Model Updates: 5,448
Cumulative Timesteps: 45,464,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05700
Policy Entropy: 4.31777
Value Function Loss: 0.03223

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02948
Policy Update Magnitude: 0.57489
Value Function Update Magnitude: 0.49584

Collected Steps per Second: 14,297.84521
Overall Steps per Second: 6,744.99141

Timestep Collection Time: 3.49885
Timestep Consumption Time: 3.91791
PPO Batch Consumption Time: 0.48112
Total Iteration Time: 7.41676

Cumulative Model Updates: 5,454
Cumulative Timesteps: 45,514,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 45514824...
Checkpoint 45514824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15897
Policy Entropy: 4.32142
Value Function Loss: 0.03068

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.53497
Value Function Update Magnitude: 0.43360

Collected Steps per Second: 14,167.70041
Overall Steps per Second: 6,794.17366

Timestep Collection Time: 3.53141
Timestep Consumption Time: 3.83254
PPO Batch Consumption Time: 0.47111
Total Iteration Time: 7.36396

Cumulative Model Updates: 5,460
Cumulative Timesteps: 45,564,856

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07187
Policy Entropy: 4.31858
Value Function Loss: 0.03363

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02357
Policy Update Magnitude: 0.55596
Value Function Update Magnitude: 0.45622

Collected Steps per Second: 14,413.70996
Overall Steps per Second: 6,824.04238

Timestep Collection Time: 3.47031
Timestep Consumption Time: 3.85966
PPO Batch Consumption Time: 0.46830
Total Iteration Time: 7.32997

Cumulative Model Updates: 5,466
Cumulative Timesteps: 45,614,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 45614876...
Checkpoint 45614876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02389
Policy Entropy: 4.31669
Value Function Loss: 0.03419

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.56463
Value Function Update Magnitude: 0.45723

Collected Steps per Second: 14,177.21106
Overall Steps per Second: 6,644.97901

Timestep Collection Time: 3.52848
Timestep Consumption Time: 3.99961
PPO Batch Consumption Time: 0.49614
Total Iteration Time: 7.52809

Cumulative Model Updates: 5,472
Cumulative Timesteps: 45,664,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05490
Policy Entropy: 4.31230
Value Function Loss: 0.04088

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03041
Policy Update Magnitude: 0.59619
Value Function Update Magnitude: 0.45704

Collected Steps per Second: 14,487.93048
Overall Steps per Second: 6,816.93509

Timestep Collection Time: 3.45225
Timestep Consumption Time: 3.88477
PPO Batch Consumption Time: 0.48969
Total Iteration Time: 7.33702

Cumulative Model Updates: 5,478
Cumulative Timesteps: 45,714,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 45714916...
Checkpoint 45714916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07023
Policy Entropy: 4.31140
Value Function Loss: 0.04484

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02620
Policy Update Magnitude: 0.60939
Value Function Update Magnitude: 0.48121

Collected Steps per Second: 14,879.00201
Overall Steps per Second: 6,985.71428

Timestep Collection Time: 3.36246
Timestep Consumption Time: 3.79930
PPO Batch Consumption Time: 0.48546
Total Iteration Time: 7.16176

Cumulative Model Updates: 5,484
Cumulative Timesteps: 45,764,946

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04467
Policy Entropy: 4.30962
Value Function Loss: 0.04388

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.62808
Value Function Update Magnitude: 0.52279

Collected Steps per Second: 14,235.76697
Overall Steps per Second: 6,921.49935

Timestep Collection Time: 3.51270
Timestep Consumption Time: 3.71203
PPO Batch Consumption Time: 0.46603
Total Iteration Time: 7.22474

Cumulative Model Updates: 5,490
Cumulative Timesteps: 45,814,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 45814952...
Checkpoint 45814952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18663
Policy Entropy: 4.30659
Value Function Loss: 0.04472

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02530
Policy Update Magnitude: 0.63766
Value Function Update Magnitude: 0.48546

Collected Steps per Second: 15,036.17810
Overall Steps per Second: 7,062.80857

Timestep Collection Time: 3.32638
Timestep Consumption Time: 3.75522
PPO Batch Consumption Time: 0.47890
Total Iteration Time: 7.08160

Cumulative Model Updates: 5,496
Cumulative Timesteps: 45,864,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09225
Policy Entropy: 4.30655
Value Function Loss: 0.04577

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03012
Policy Update Magnitude: 0.63859
Value Function Update Magnitude: 0.45225

Collected Steps per Second: 14,322.93113
Overall Steps per Second: 6,754.71863

Timestep Collection Time: 3.49258
Timestep Consumption Time: 3.91320
PPO Batch Consumption Time: 0.48339
Total Iteration Time: 7.40579

Cumulative Model Updates: 5,502
Cumulative Timesteps: 45,914,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 45914992...
Checkpoint 45914992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03053
Policy Entropy: 4.30782
Value Function Loss: 0.04734

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02813
Policy Update Magnitude: 0.63350
Value Function Update Magnitude: 0.45271

Collected Steps per Second: 14,140.99827
Overall Steps per Second: 6,751.63420

Timestep Collection Time: 3.53596
Timestep Consumption Time: 3.86995
PPO Batch Consumption Time: 0.48351
Total Iteration Time: 7.40591

Cumulative Model Updates: 5,508
Cumulative Timesteps: 45,964,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04240
Policy Entropy: 4.30861
Value Function Loss: 0.03893

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.61360
Value Function Update Magnitude: 0.42322

Collected Steps per Second: 14,572.42586
Overall Steps per Second: 6,831.19744

Timestep Collection Time: 3.43320
Timestep Consumption Time: 3.89056
PPO Batch Consumption Time: 0.47336
Total Iteration Time: 7.32375

Cumulative Model Updates: 5,514
Cumulative Timesteps: 46,015,024

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 46015024...
Checkpoint 46015024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08969
Policy Entropy: 4.30998
Value Function Loss: 0.03710

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03038
Policy Update Magnitude: 0.60177
Value Function Update Magnitude: 0.41397

Collected Steps per Second: 14,422.56186
Overall Steps per Second: 6,920.67140

Timestep Collection Time: 3.46762
Timestep Consumption Time: 3.75884
PPO Batch Consumption Time: 0.46803
Total Iteration Time: 7.22647

Cumulative Model Updates: 5,520
Cumulative Timesteps: 46,065,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04335
Policy Entropy: 4.30963
Value Function Loss: 0.03684

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03310
Policy Update Magnitude: 0.58928
Value Function Update Magnitude: 0.44247

Collected Steps per Second: 13,957.82884
Overall Steps per Second: 6,613.39544

Timestep Collection Time: 3.58251
Timestep Consumption Time: 3.97851
PPO Batch Consumption Time: 0.48431
Total Iteration Time: 7.56102

Cumulative Model Updates: 5,526
Cumulative Timesteps: 46,115,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 46115040...
Checkpoint 46115040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05702
Policy Entropy: 4.31044
Value Function Loss: 0.04222

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03013
Policy Update Magnitude: 0.60608
Value Function Update Magnitude: 0.41667

Collected Steps per Second: 14,493.84120
Overall Steps per Second: 6,847.90751

Timestep Collection Time: 3.45002
Timestep Consumption Time: 3.85207
PPO Batch Consumption Time: 0.47722
Total Iteration Time: 7.30208

Cumulative Model Updates: 5,532
Cumulative Timesteps: 46,165,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09758
Policy Entropy: 4.30776
Value Function Loss: 0.04032

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03444
Policy Update Magnitude: 0.59083
Value Function Update Magnitude: 0.40203

Collected Steps per Second: 14,433.14253
Overall Steps per Second: 6,789.28671

Timestep Collection Time: 3.46577
Timestep Consumption Time: 3.90201
PPO Batch Consumption Time: 0.47788
Total Iteration Time: 7.36778

Cumulative Model Updates: 5,538
Cumulative Timesteps: 46,215,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 46215066...
Checkpoint 46215066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00960
Policy Entropy: 4.31199
Value Function Loss: 0.03838

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03209
Policy Update Magnitude: 0.57543
Value Function Update Magnitude: 0.38421

Collected Steps per Second: 14,372.70460
Overall Steps per Second: 6,432.80593

Timestep Collection Time: 3.48049
Timestep Consumption Time: 4.29590
PPO Batch Consumption Time: 0.52498
Total Iteration Time: 7.77639

Cumulative Model Updates: 5,544
Cumulative Timesteps: 46,265,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01155
Policy Entropy: 4.31532
Value Function Loss: 0.03428

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02685
Policy Update Magnitude: 0.55920
Value Function Update Magnitude: 0.39026

Collected Steps per Second: 13,994.17223
Overall Steps per Second: 6,731.13621

Timestep Collection Time: 3.57492
Timestep Consumption Time: 3.85741
PPO Batch Consumption Time: 0.47842
Total Iteration Time: 7.43233

Cumulative Model Updates: 5,550
Cumulative Timesteps: 46,315,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 46315118...
Checkpoint 46315118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04857
Policy Entropy: 4.31518
Value Function Loss: 0.03091

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.53010
Value Function Update Magnitude: 0.38890

Collected Steps per Second: 14,265.87397
Overall Steps per Second: 6,706.82168

Timestep Collection Time: 3.50585
Timestep Consumption Time: 3.95133
PPO Batch Consumption Time: 0.48384
Total Iteration Time: 7.45718

Cumulative Model Updates: 5,556
Cumulative Timesteps: 46,365,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06916
Policy Entropy: 4.32071
Value Function Loss: 0.02659

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01976
Policy Update Magnitude: 0.50003
Value Function Update Magnitude: 0.37034

Collected Steps per Second: 14,459.45092
Overall Steps per Second: 6,834.27307

Timestep Collection Time: 3.45974
Timestep Consumption Time: 3.86013
PPO Batch Consumption Time: 0.48467
Total Iteration Time: 7.31987

Cumulative Model Updates: 5,562
Cumulative Timesteps: 46,415,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 46415158...
Checkpoint 46415158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03022
Policy Entropy: 4.31730
Value Function Loss: 0.02859

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.01910
Policy Update Magnitude: 0.49918
Value Function Update Magnitude: 0.35548

Collected Steps per Second: 14,400.63470
Overall Steps per Second: 6,738.56726

Timestep Collection Time: 3.47276
Timestep Consumption Time: 3.94870
PPO Batch Consumption Time: 0.49166
Total Iteration Time: 7.42146

Cumulative Model Updates: 5,568
Cumulative Timesteps: 46,465,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03460
Policy Entropy: 4.32530
Value Function Loss: 0.03264

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02380
Policy Update Magnitude: 0.53138
Value Function Update Magnitude: 0.34275

Collected Steps per Second: 14,642.11752
Overall Steps per Second: 6,936.87261

Timestep Collection Time: 3.41535
Timestep Consumption Time: 3.79366
PPO Batch Consumption Time: 0.47018
Total Iteration Time: 7.20901

Cumulative Model Updates: 5,574
Cumulative Timesteps: 46,515,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 46515176...
Checkpoint 46515176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04207
Policy Entropy: 4.31845
Value Function Loss: 0.03909

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02815
Policy Update Magnitude: 0.55985
Value Function Update Magnitude: 0.37428

Collected Steps per Second: 14,340.63236
Overall Steps per Second: 6,670.08202

Timestep Collection Time: 3.48813
Timestep Consumption Time: 4.01133
PPO Batch Consumption Time: 0.50288
Total Iteration Time: 7.49946

Cumulative Model Updates: 5,580
Cumulative Timesteps: 46,565,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07445
Policy Entropy: 4.31460
Value Function Loss: 0.04611

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.57950
Value Function Update Magnitude: 0.40875

Collected Steps per Second: 14,260.76180
Overall Steps per Second: 6,786.15513

Timestep Collection Time: 3.50626
Timestep Consumption Time: 3.86197
PPO Batch Consumption Time: 0.47972
Total Iteration Time: 7.36824

Cumulative Model Updates: 5,586
Cumulative Timesteps: 46,615,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 46615200...
Checkpoint 46615200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02223
Policy Entropy: 4.31059
Value Function Loss: 0.04324

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 0.62177
Value Function Update Magnitude: 0.41808

Collected Steps per Second: 14,686.74672
Overall Steps per Second: 6,890.38256

Timestep Collection Time: 3.40457
Timestep Consumption Time: 3.85222
PPO Batch Consumption Time: 0.47775
Total Iteration Time: 7.25678

Cumulative Model Updates: 5,592
Cumulative Timesteps: 46,665,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05867
Policy Entropy: 4.31681
Value Function Loss: 0.04260

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03429
Policy Update Magnitude: 0.59792
Value Function Update Magnitude: 0.39660

Collected Steps per Second: 14,307.52953
Overall Steps per Second: 6,664.54023

Timestep Collection Time: 3.49480
Timestep Consumption Time: 4.00789
PPO Batch Consumption Time: 0.49640
Total Iteration Time: 7.50269

Cumulative Model Updates: 5,598
Cumulative Timesteps: 46,715,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 46715204...
Checkpoint 46715204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00816
Policy Entropy: 4.31600
Value Function Loss: 0.03968

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04046
Policy Update Magnitude: 0.57743
Value Function Update Magnitude: 0.37733

Collected Steps per Second: 14,680.52069
Overall Steps per Second: 6,911.01577

Timestep Collection Time: 3.40764
Timestep Consumption Time: 3.83094
PPO Batch Consumption Time: 0.47469
Total Iteration Time: 7.23859

Cumulative Model Updates: 5,604
Cumulative Timesteps: 46,765,230

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13733
Policy Entropy: 4.31830
Value Function Loss: 0.03798

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03324
Policy Update Magnitude: 0.55837
Value Function Update Magnitude: 0.37915

Collected Steps per Second: 14,399.21167
Overall Steps per Second: 6,751.92956

Timestep Collection Time: 3.47325
Timestep Consumption Time: 3.93382
PPO Batch Consumption Time: 0.48634
Total Iteration Time: 7.40707

Cumulative Model Updates: 5,610
Cumulative Timesteps: 46,815,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 46815242...
Checkpoint 46815242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04361
Policy Entropy: 4.31271
Value Function Loss: 0.03473

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03318
Policy Update Magnitude: 0.54665
Value Function Update Magnitude: 0.37137

Collected Steps per Second: 14,321.35422
Overall Steps per Second: 6,807.36603

Timestep Collection Time: 3.49171
Timestep Consumption Time: 3.85416
PPO Batch Consumption Time: 0.48151
Total Iteration Time: 7.34587

Cumulative Model Updates: 5,616
Cumulative Timesteps: 46,865,248

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18422
Policy Entropy: 4.31465
Value Function Loss: 0.03251

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03733
Policy Update Magnitude: 0.54749
Value Function Update Magnitude: 0.38354

Collected Steps per Second: 14,299.60509
Overall Steps per Second: 6,706.31661

Timestep Collection Time: 3.49800
Timestep Consumption Time: 3.96064
PPO Batch Consumption Time: 0.48509
Total Iteration Time: 7.45864

Cumulative Model Updates: 5,622
Cumulative Timesteps: 46,915,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 46915268...
Checkpoint 46915268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15062
Policy Entropy: 4.31769
Value Function Loss: 0.04125

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03910
Policy Update Magnitude: 0.57127
Value Function Update Magnitude: 0.42985

Collected Steps per Second: 14,254.12009
Overall Steps per Second: 6,745.47370

Timestep Collection Time: 3.51000
Timestep Consumption Time: 3.90712
PPO Batch Consumption Time: 0.48368
Total Iteration Time: 7.41712

Cumulative Model Updates: 5,628
Cumulative Timesteps: 46,965,300

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09035
Policy Entropy: 4.31845
Value Function Loss: 0.04542

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03878
Policy Update Magnitude: 0.60392
Value Function Update Magnitude: 0.46840

Collected Steps per Second: 14,257.47188
Overall Steps per Second: 6,826.32996

Timestep Collection Time: 3.50876
Timestep Consumption Time: 3.81963
PPO Batch Consumption Time: 0.47646
Total Iteration Time: 7.32839

Cumulative Model Updates: 5,634
Cumulative Timesteps: 47,015,326

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 47015326...
Checkpoint 47015326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07905
Policy Entropy: 4.31965
Value Function Loss: 0.05696

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03797
Policy Update Magnitude: 0.63624
Value Function Update Magnitude: 0.53080

Collected Steps per Second: 14,318.77280
Overall Steps per Second: 6,738.26385

Timestep Collection Time: 3.49290
Timestep Consumption Time: 3.92949
PPO Batch Consumption Time: 0.47868
Total Iteration Time: 7.42239

Cumulative Model Updates: 5,640
Cumulative Timesteps: 47,065,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05600
Policy Entropy: 4.31140
Value Function Loss: 0.05495

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03977
Policy Update Magnitude: 0.64693
Value Function Update Magnitude: 0.55173

Collected Steps per Second: 14,346.93682
Overall Steps per Second: 6,756.54890

Timestep Collection Time: 3.48576
Timestep Consumption Time: 3.91595
PPO Batch Consumption Time: 0.49737
Total Iteration Time: 7.40171

Cumulative Model Updates: 5,646
Cumulative Timesteps: 47,115,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 47115350...
Checkpoint 47115350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07525
Policy Entropy: 4.31050
Value Function Loss: 0.05498

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03806
Policy Update Magnitude: 0.66889
Value Function Update Magnitude: 0.53082

Collected Steps per Second: 14,292.22808
Overall Steps per Second: 6,741.89277

Timestep Collection Time: 3.49938
Timestep Consumption Time: 3.91901
PPO Batch Consumption Time: 0.47816
Total Iteration Time: 7.41839

Cumulative Model Updates: 5,652
Cumulative Timesteps: 47,165,364

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17712
Policy Entropy: 4.30834
Value Function Loss: 0.05148

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03650
Policy Update Magnitude: 0.63238
Value Function Update Magnitude: 0.46677

Collected Steps per Second: 14,173.10858
Overall Steps per Second: 6,695.47758

Timestep Collection Time: 3.52795
Timestep Consumption Time: 3.94008
PPO Batch Consumption Time: 0.49039
Total Iteration Time: 7.46803

Cumulative Model Updates: 5,658
Cumulative Timesteps: 47,215,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 47215366...
Checkpoint 47215366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06155
Policy Entropy: 4.32025
Value Function Loss: 0.04403

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03495
Policy Update Magnitude: 0.59918
Value Function Update Magnitude: 0.43297

Collected Steps per Second: 14,568.65384
Overall Steps per Second: 6,773.62193

Timestep Collection Time: 3.43409
Timestep Consumption Time: 3.95192
PPO Batch Consumption Time: 0.48602
Total Iteration Time: 7.38600

Cumulative Model Updates: 5,664
Cumulative Timesteps: 47,265,396

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03691
Policy Entropy: 4.32115
Value Function Loss: 0.04280

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02648
Policy Update Magnitude: 0.56479
Value Function Update Magnitude: 0.42912

Collected Steps per Second: 14,117.05855
Overall Steps per Second: 6,672.03666

Timestep Collection Time: 3.54394
Timestep Consumption Time: 3.95452
PPO Batch Consumption Time: 0.49122
Total Iteration Time: 7.49846

Cumulative Model Updates: 5,670
Cumulative Timesteps: 47,315,426

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 47315426...
Checkpoint 47315426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03057
Policy Entropy: 4.31177
Value Function Loss: 0.04650

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03142
Policy Update Magnitude: 0.58764
Value Function Update Magnitude: 0.46961

Collected Steps per Second: 14,211.76311
Overall Steps per Second: 6,824.85231

Timestep Collection Time: 3.51863
Timestep Consumption Time: 3.80841
PPO Batch Consumption Time: 0.48283
Total Iteration Time: 7.32704

Cumulative Model Updates: 5,676
Cumulative Timesteps: 47,365,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10191
Policy Entropy: 4.31592
Value Function Loss: 0.04460

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.03988
Policy Update Magnitude: 0.59438
Value Function Update Magnitude: 0.48809

Collected Steps per Second: 14,232.55251
Overall Steps per Second: 6,636.44468

Timestep Collection Time: 3.51378
Timestep Consumption Time: 4.02189
PPO Batch Consumption Time: 0.49773
Total Iteration Time: 7.53566

Cumulative Model Updates: 5,682
Cumulative Timesteps: 47,415,442

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 47415442...
Checkpoint 47415442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05736
Policy Entropy: 4.31738
Value Function Loss: 0.04678

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03735
Policy Update Magnitude: 0.58622
Value Function Update Magnitude: 0.47107

Collected Steps per Second: 14,293.97634
Overall Steps per Second: 6,760.53402

Timestep Collection Time: 3.49896
Timestep Consumption Time: 3.89898
PPO Batch Consumption Time: 0.47737
Total Iteration Time: 7.39794

Cumulative Model Updates: 5,688
Cumulative Timesteps: 47,465,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06065
Policy Entropy: 4.31549
Value Function Loss: 0.05036

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03615
Policy Update Magnitude: 0.59789
Value Function Update Magnitude: 0.45022

Collected Steps per Second: 14,765.38581
Overall Steps per Second: 6,755.89993

Timestep Collection Time: 3.38698
Timestep Consumption Time: 4.01544
PPO Batch Consumption Time: 0.49990
Total Iteration Time: 7.40242

Cumulative Model Updates: 5,694
Cumulative Timesteps: 47,515,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 47515466...
Checkpoint 47515466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.23709
Policy Entropy: 4.30818
Value Function Loss: 0.05662

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03662
Policy Update Magnitude: 0.61290
Value Function Update Magnitude: 0.50879

Collected Steps per Second: 14,221.79705
Overall Steps per Second: 6,664.55340

Timestep Collection Time: 3.51812
Timestep Consumption Time: 3.98936
PPO Batch Consumption Time: 0.49146
Total Iteration Time: 7.50748

Cumulative Model Updates: 5,700
Cumulative Timesteps: 47,565,500

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06449
Policy Entropy: 4.30702
Value Function Loss: 0.04561

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03547
Policy Update Magnitude: 0.60173
Value Function Update Magnitude: 0.49251

Collected Steps per Second: 14,381.32726
Overall Steps per Second: 6,809.74346

Timestep Collection Time: 3.47701
Timestep Consumption Time: 3.86600
PPO Batch Consumption Time: 0.48458
Total Iteration Time: 7.34301

Cumulative Model Updates: 5,706
Cumulative Timesteps: 47,615,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 47615504...
Checkpoint 47615504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01270
Policy Entropy: 4.31085
Value Function Loss: 0.05083

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02755
Policy Update Magnitude: 0.60219
Value Function Update Magnitude: 0.46930

Collected Steps per Second: 14,168.11120
Overall Steps per Second: 6,696.22060

Timestep Collection Time: 3.53060
Timestep Consumption Time: 3.93958
PPO Batch Consumption Time: 0.48709
Total Iteration Time: 7.47018

Cumulative Model Updates: 5,712
Cumulative Timesteps: 47,665,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16102
Policy Entropy: 4.30911
Value Function Loss: 0.04227

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03007
Policy Update Magnitude: 0.60554
Value Function Update Magnitude: 0.49216

Collected Steps per Second: 14,387.62554
Overall Steps per Second: 6,784.15033

Timestep Collection Time: 3.47521
Timestep Consumption Time: 3.89491
PPO Batch Consumption Time: 0.48761
Total Iteration Time: 7.37012

Cumulative Model Updates: 5,718
Cumulative Timesteps: 47,715,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 47715526...
Checkpoint 47715526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03804
Policy Entropy: 4.30961
Value Function Loss: 0.04806

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03347
Policy Update Magnitude: 0.58607
Value Function Update Magnitude: 0.44509

Collected Steps per Second: 14,259.16853
Overall Steps per Second: 6,698.78985

Timestep Collection Time: 3.50694
Timestep Consumption Time: 3.95799
PPO Batch Consumption Time: 0.49280
Total Iteration Time: 7.46493

Cumulative Model Updates: 5,724
Cumulative Timesteps: 47,765,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02550
Policy Entropy: 4.29863
Value Function Loss: 0.05076

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03724
Policy Update Magnitude: 0.58760
Value Function Update Magnitude: 0.48077

Collected Steps per Second: 14,137.06495
Overall Steps per Second: 6,709.90833

Timestep Collection Time: 3.53694
Timestep Consumption Time: 3.91502
PPO Batch Consumption Time: 0.48337
Total Iteration Time: 7.45196

Cumulative Model Updates: 5,730
Cumulative Timesteps: 47,815,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 47815534...
Checkpoint 47815534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.20582
Policy Entropy: 4.29566
Value Function Loss: 0.05352

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03321
Policy Update Magnitude: 0.63270
Value Function Update Magnitude: 0.54649

Collected Steps per Second: 14,545.20706
Overall Steps per Second: 6,800.15734

Timestep Collection Time: 3.43825
Timestep Consumption Time: 3.91600
PPO Batch Consumption Time: 0.49016
Total Iteration Time: 7.35424

Cumulative Model Updates: 5,736
Cumulative Timesteps: 47,865,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14167
Policy Entropy: 4.29985
Value Function Loss: 0.04740

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03193
Policy Update Magnitude: 0.62497
Value Function Update Magnitude: 0.55029

Collected Steps per Second: 14,276.00615
Overall Steps per Second: 6,712.61316

Timestep Collection Time: 3.50266
Timestep Consumption Time: 3.94660
PPO Batch Consumption Time: 0.48318
Total Iteration Time: 7.44926

Cumulative Model Updates: 5,742
Cumulative Timesteps: 47,915,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 47915548...
Checkpoint 47915548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01170
Policy Entropy: 4.30996
Value Function Loss: 0.04058

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 0.57917
Value Function Update Magnitude: 0.50757

Collected Steps per Second: 14,272.25752
Overall Steps per Second: 6,771.25987

Timestep Collection Time: 3.50498
Timestep Consumption Time: 3.88271
PPO Batch Consumption Time: 0.48894
Total Iteration Time: 7.38769

Cumulative Model Updates: 5,748
Cumulative Timesteps: 47,965,572

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07110
Policy Entropy: 4.31555
Value Function Loss: 0.03088

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02943
Policy Update Magnitude: 0.53728
Value Function Update Magnitude: 0.42863

Collected Steps per Second: 14,359.18059
Overall Steps per Second: 6,674.84236

Timestep Collection Time: 3.48335
Timestep Consumption Time: 4.01016
PPO Batch Consumption Time: 0.49583
Total Iteration Time: 7.49351

Cumulative Model Updates: 5,754
Cumulative Timesteps: 48,015,590

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 48015590...
Checkpoint 48015590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06170
Policy Entropy: 4.32311
Value Function Loss: 0.03416

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02480
Policy Update Magnitude: 0.50904
Value Function Update Magnitude: 0.37581

Collected Steps per Second: 14,143.15048
Overall Steps per Second: 6,816.77789

Timestep Collection Time: 3.53641
Timestep Consumption Time: 3.80078
PPO Batch Consumption Time: 0.47300
Total Iteration Time: 7.33719

Cumulative Model Updates: 5,760
Cumulative Timesteps: 48,065,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00319
Policy Entropy: 4.32551
Value Function Loss: 0.03755

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02219
Policy Update Magnitude: 0.53563
Value Function Update Magnitude: 0.39212

Collected Steps per Second: 14,313.84446
Overall Steps per Second: 6,795.32286

Timestep Collection Time: 3.49508
Timestep Consumption Time: 3.86704
PPO Batch Consumption Time: 0.46825
Total Iteration Time: 7.36212

Cumulative Model Updates: 5,766
Cumulative Timesteps: 48,115,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 48115634...
Checkpoint 48115634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21741
Policy Entropy: 4.31737
Value Function Loss: 0.03879

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.54423
Value Function Update Magnitude: 0.40919

Collected Steps per Second: 14,085.68151
Overall Steps per Second: 6,705.40181

Timestep Collection Time: 3.54970
Timestep Consumption Time: 3.90697
PPO Batch Consumption Time: 0.48343
Total Iteration Time: 7.45667

Cumulative Model Updates: 5,772
Cumulative Timesteps: 48,165,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03490
Policy Entropy: 4.31152
Value Function Loss: 0.03653

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02538
Policy Update Magnitude: 0.52950
Value Function Update Magnitude: 0.40836

Collected Steps per Second: 14,453.35006
Overall Steps per Second: 6,726.59581

Timestep Collection Time: 3.46051
Timestep Consumption Time: 3.97505
PPO Batch Consumption Time: 0.48247
Total Iteration Time: 7.43556

Cumulative Model Updates: 5,778
Cumulative Timesteps: 48,215,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 48215650...
Checkpoint 48215650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19024
Policy Entropy: 4.31151
Value Function Loss: 0.03306

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02410
Policy Update Magnitude: 0.50115
Value Function Update Magnitude: 0.36882

Collected Steps per Second: 14,135.30601
Overall Steps per Second: 6,726.13305

Timestep Collection Time: 3.53908
Timestep Consumption Time: 3.89848
PPO Batch Consumption Time: 0.48092
Total Iteration Time: 7.43756

Cumulative Model Updates: 5,784
Cumulative Timesteps: 48,265,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01562
Policy Entropy: 4.30501
Value Function Loss: 0.03770

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02817
Policy Update Magnitude: 0.51006
Value Function Update Magnitude: 0.35262

Collected Steps per Second: 14,303.56780
Overall Steps per Second: 6,786.70335

Timestep Collection Time: 3.49591
Timestep Consumption Time: 3.87203
PPO Batch Consumption Time: 0.48221
Total Iteration Time: 7.36794

Cumulative Model Updates: 5,790
Cumulative Timesteps: 48,315,680

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 48315680...
Checkpoint 48315680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01982
Policy Entropy: 4.30864
Value Function Loss: 0.03276

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02563
Policy Update Magnitude: 0.51370
Value Function Update Magnitude: 0.38134

Collected Steps per Second: 13,912.92395
Overall Steps per Second: 6,546.27212

Timestep Collection Time: 3.59666
Timestep Consumption Time: 4.04739
PPO Batch Consumption Time: 0.49776
Total Iteration Time: 7.64405

Cumulative Model Updates: 5,796
Cumulative Timesteps: 48,365,720

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.28461
Policy Entropy: 4.31500
Value Function Loss: 0.03258

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01957
Policy Update Magnitude: 0.51227
Value Function Update Magnitude: 0.41628

Collected Steps per Second: 14,299.69674
Overall Steps per Second: 6,773.56184

Timestep Collection Time: 3.49714
Timestep Consumption Time: 3.88568
PPO Batch Consumption Time: 0.48067
Total Iteration Time: 7.38282

Cumulative Model Updates: 5,802
Cumulative Timesteps: 48,415,728

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 48415728...
Checkpoint 48415728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05230
Policy Entropy: 4.31404
Value Function Loss: 0.02862

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02412
Policy Update Magnitude: 0.50758
Value Function Update Magnitude: 0.40893

Collected Steps per Second: 14,421.68623
Overall Steps per Second: 6,713.21697

Timestep Collection Time: 3.46811
Timestep Consumption Time: 3.98227
PPO Batch Consumption Time: 0.48782
Total Iteration Time: 7.45038

Cumulative Model Updates: 5,808
Cumulative Timesteps: 48,465,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.30860
Policy Entropy: 4.31298
Value Function Loss: 0.03923

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02740
Policy Update Magnitude: 0.52121
Value Function Update Magnitude: 0.41970

Collected Steps per Second: 14,372.31575
Overall Steps per Second: 6,802.99726

Timestep Collection Time: 3.47919
Timestep Consumption Time: 3.87110
PPO Batch Consumption Time: 0.47614
Total Iteration Time: 7.35029

Cumulative Model Updates: 5,814
Cumulative Timesteps: 48,515,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 48515748...
Checkpoint 48515748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11492
Policy Entropy: 4.30723
Value Function Loss: 0.03590

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 0.53120
Value Function Update Magnitude: 0.41980

Collected Steps per Second: 14,536.83097
Overall Steps per Second: 6,966.77746

Timestep Collection Time: 3.44105
Timestep Consumption Time: 3.73902
PPO Batch Consumption Time: 0.48750
Total Iteration Time: 7.18008

Cumulative Model Updates: 5,820
Cumulative Timesteps: 48,565,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03436
Policy Entropy: 4.30618
Value Function Loss: 0.04943

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03772
Policy Update Magnitude: 0.54351
Value Function Update Magnitude: 0.43734

Collected Steps per Second: 13,519.95232
Overall Steps per Second: 6,484.27976

Timestep Collection Time: 3.69927
Timestep Consumption Time: 4.01384
PPO Batch Consumption Time: 0.49308
Total Iteration Time: 7.71312

Cumulative Model Updates: 5,826
Cumulative Timesteps: 48,615,784

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 48615784...
Checkpoint 48615784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.30014
Policy Entropy: 4.30917
Value Function Loss: 0.04609

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03684
Policy Update Magnitude: 0.56218
Value Function Update Magnitude: 0.44561

Collected Steps per Second: 14,214.40966
Overall Steps per Second: 6,834.15221

Timestep Collection Time: 3.51953
Timestep Consumption Time: 3.80077
PPO Batch Consumption Time: 0.47692
Total Iteration Time: 7.32029

Cumulative Model Updates: 5,832
Cumulative Timesteps: 48,665,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00975
Policy Entropy: 4.30867
Value Function Loss: 0.04414

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03599
Policy Update Magnitude: 0.55795
Value Function Update Magnitude: 0.44919

Collected Steps per Second: 14,158.47440
Overall Steps per Second: 6,747.86277

Timestep Collection Time: 3.53188
Timestep Consumption Time: 3.87876
PPO Batch Consumption Time: 0.47919
Total Iteration Time: 7.41064

Cumulative Model Updates: 5,838
Cumulative Timesteps: 48,715,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 48715818...
Checkpoint 48715818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12972
Policy Entropy: 4.32519
Value Function Loss: 0.03109

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03254
Policy Update Magnitude: 0.53477
Value Function Update Magnitude: 0.43827

Collected Steps per Second: 14,220.66056
Overall Steps per Second: 6,746.25474

Timestep Collection Time: 3.51784
Timestep Consumption Time: 3.89753
PPO Batch Consumption Time: 0.48085
Total Iteration Time: 7.41537

Cumulative Model Updates: 5,844
Cumulative Timesteps: 48,765,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15564
Policy Entropy: 4.32216
Value Function Loss: 0.02848

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02965
Policy Update Magnitude: 0.49567
Value Function Update Magnitude: 0.43338

Collected Steps per Second: 14,440.94827
Overall Steps per Second: 6,746.48965

Timestep Collection Time: 3.46252
Timestep Consumption Time: 3.94904
PPO Batch Consumption Time: 0.48585
Total Iteration Time: 7.41156

Cumulative Model Updates: 5,850
Cumulative Timesteps: 48,815,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 48815846...
Checkpoint 48815846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04606
Policy Entropy: 4.32308
Value Function Loss: 0.03126

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02953
Policy Update Magnitude: 0.48809
Value Function Update Magnitude: 0.43922

Collected Steps per Second: 14,387.41354
Overall Steps per Second: 6,749.14446

Timestep Collection Time: 3.47651
Timestep Consumption Time: 3.93450
PPO Batch Consumption Time: 0.48263
Total Iteration Time: 7.41101

Cumulative Model Updates: 5,856
Cumulative Timesteps: 48,865,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07254
Policy Entropy: 4.31546
Value Function Loss: 0.03930

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03023
Policy Update Magnitude: 0.53064
Value Function Update Magnitude: 0.41871

Collected Steps per Second: 14,400.55592
Overall Steps per Second: 6,833.40081

Timestep Collection Time: 3.47362
Timestep Consumption Time: 3.84660
PPO Batch Consumption Time: 0.47445
Total Iteration Time: 7.32022

Cumulative Model Updates: 5,862
Cumulative Timesteps: 48,915,886

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 48915886...
Checkpoint 48915886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03843
Policy Entropy: 4.31492
Value Function Loss: 0.04437

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02843
Policy Update Magnitude: 0.56075
Value Function Update Magnitude: 0.43476

Collected Steps per Second: 14,213.47900
Overall Steps per Second: 6,667.57600

Timestep Collection Time: 3.51793
Timestep Consumption Time: 3.98135
PPO Batch Consumption Time: 0.49011
Total Iteration Time: 7.49928

Cumulative Model Updates: 5,868
Cumulative Timesteps: 48,965,888

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00988
Policy Entropy: 4.31134
Value Function Loss: 0.05573

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03048
Policy Update Magnitude: 0.59762
Value Function Update Magnitude: 0.44676

Collected Steps per Second: 14,360.26740
Overall Steps per Second: 6,795.51405

Timestep Collection Time: 3.48294
Timestep Consumption Time: 3.87721
PPO Batch Consumption Time: 0.48218
Total Iteration Time: 7.36015

Cumulative Model Updates: 5,874
Cumulative Timesteps: 49,015,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 49015904...
Checkpoint 49015904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09591
Policy Entropy: 4.31059
Value Function Loss: 0.05130

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03242
Policy Update Magnitude: 0.61097
Value Function Update Magnitude: 0.45076

Collected Steps per Second: 14,184.83745
Overall Steps per Second: 6,703.87038

Timestep Collection Time: 3.52771
Timestep Consumption Time: 3.93663
PPO Batch Consumption Time: 0.48564
Total Iteration Time: 7.46434

Cumulative Model Updates: 5,880
Cumulative Timesteps: 49,065,944

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00671
Policy Entropy: 4.30253
Value Function Loss: 0.04497

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03387
Policy Update Magnitude: 0.57824
Value Function Update Magnitude: 0.43300

Collected Steps per Second: 14,444.25980
Overall Steps per Second: 6,793.23785

Timestep Collection Time: 3.46200
Timestep Consumption Time: 3.89915
PPO Batch Consumption Time: 0.48172
Total Iteration Time: 7.36114

Cumulative Model Updates: 5,886
Cumulative Timesteps: 49,115,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 49115950...
Checkpoint 49115950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01163
Policy Entropy: 4.30422
Value Function Loss: 0.03378

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02694
Policy Update Magnitude: 0.54004
Value Function Update Magnitude: 0.41853

Collected Steps per Second: 14,440.74629
Overall Steps per Second: 6,696.13625

Timestep Collection Time: 3.46395
Timestep Consumption Time: 4.00633
PPO Batch Consumption Time: 0.50333
Total Iteration Time: 7.47028

Cumulative Model Updates: 5,892
Cumulative Timesteps: 49,165,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.25118
Policy Entropy: 4.30378
Value Function Loss: 0.03203

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.02145
Policy Update Magnitude: 0.53342
Value Function Update Magnitude: 0.41590

Collected Steps per Second: 14,235.01599
Overall Steps per Second: 6,672.02112

Timestep Collection Time: 3.51443
Timestep Consumption Time: 3.98375
PPO Batch Consumption Time: 0.49454
Total Iteration Time: 7.49818

Cumulative Model Updates: 5,898
Cumulative Timesteps: 49,216,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 49216000...
Checkpoint 49216000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18172
Policy Entropy: 4.31225
Value Function Loss: 0.03811

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.54465
Value Function Update Magnitude: 0.39887

Collected Steps per Second: 14,424.02599
Overall Steps per Second: 6,724.27336

Timestep Collection Time: 3.46796
Timestep Consumption Time: 3.97106
PPO Batch Consumption Time: 0.49907
Total Iteration Time: 7.43902

Cumulative Model Updates: 5,904
Cumulative Timesteps: 49,266,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07859
Policy Entropy: 4.30870
Value Function Loss: 0.03644

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02636
Policy Update Magnitude: 0.54044
Value Function Update Magnitude: 0.37747

Collected Steps per Second: 14,333.80828
Overall Steps per Second: 6,760.51648

Timestep Collection Time: 3.49007
Timestep Consumption Time: 3.90966
PPO Batch Consumption Time: 0.47978
Total Iteration Time: 7.39973

Cumulative Model Updates: 5,910
Cumulative Timesteps: 49,316,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 49316048...
Checkpoint 49316048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03769
Policy Entropy: 4.30519
Value Function Loss: 0.03447

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02564
Policy Update Magnitude: 0.51898
Value Function Update Magnitude: 0.35885

Collected Steps per Second: 14,730.00885
Overall Steps per Second: 6,888.31614

Timestep Collection Time: 3.39497
Timestep Consumption Time: 3.86486
PPO Batch Consumption Time: 0.48281
Total Iteration Time: 7.25983

Cumulative Model Updates: 5,916
Cumulative Timesteps: 49,366,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02165
Policy Entropy: 4.30819
Value Function Loss: 0.02624

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02732
Policy Update Magnitude: 0.47288
Value Function Update Magnitude: 0.34836

Collected Steps per Second: 14,262.68853
Overall Steps per Second: 6,746.98439

Timestep Collection Time: 3.50663
Timestep Consumption Time: 3.90616
PPO Batch Consumption Time: 0.48637
Total Iteration Time: 7.41279

Cumulative Model Updates: 5,922
Cumulative Timesteps: 49,416,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 49416070...
Checkpoint 49416070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09209
Policy Entropy: 4.31386
Value Function Loss: 0.02516

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01944
Policy Update Magnitude: 0.46300
Value Function Update Magnitude: 0.32832

Collected Steps per Second: 14,040.54805
Overall Steps per Second: 6,610.45402

Timestep Collection Time: 3.56254
Timestep Consumption Time: 4.00426
PPO Batch Consumption Time: 0.49959
Total Iteration Time: 7.56680

Cumulative Model Updates: 5,928
Cumulative Timesteps: 49,466,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03672
Policy Entropy: 4.31560
Value Function Loss: 0.02678

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02386
Policy Update Magnitude: 0.47287
Value Function Update Magnitude: 0.35265

Collected Steps per Second: 14,387.90440
Overall Steps per Second: 6,787.87525

Timestep Collection Time: 3.47653
Timestep Consumption Time: 3.89249
PPO Batch Consumption Time: 0.47788
Total Iteration Time: 7.36902

Cumulative Model Updates: 5,934
Cumulative Timesteps: 49,516,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 49516110...
Checkpoint 49516110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04566
Policy Entropy: 4.31450
Value Function Loss: 0.03361

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03082
Policy Update Magnitude: 0.49755
Value Function Update Magnitude: 0.35244

Collected Steps per Second: 14,248.99633
Overall Steps per Second: 6,785.82586

Timestep Collection Time: 3.51253
Timestep Consumption Time: 3.86314
PPO Batch Consumption Time: 0.48294
Total Iteration Time: 7.37567

Cumulative Model Updates: 5,940
Cumulative Timesteps: 49,566,160

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13904
Policy Entropy: 4.31554
Value Function Loss: 0.03862

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03648
Policy Update Magnitude: 0.52821
Value Function Update Magnitude: 0.35306

Collected Steps per Second: 14,518.49849
Overall Steps per Second: 6,826.33589

Timestep Collection Time: 3.44512
Timestep Consumption Time: 3.88209
PPO Batch Consumption Time: 0.47301
Total Iteration Time: 7.32721

Cumulative Model Updates: 5,946
Cumulative Timesteps: 49,616,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 49616178...
Checkpoint 49616178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.23781
Policy Entropy: 4.31239
Value Function Loss: 0.04715

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04193
Policy Update Magnitude: 0.55552
Value Function Update Magnitude: 0.36439

Collected Steps per Second: 14,165.46542
Overall Steps per Second: 6,702.43837

Timestep Collection Time: 3.53169
Timestep Consumption Time: 3.93246
PPO Batch Consumption Time: 0.48169
Total Iteration Time: 7.46415

Cumulative Model Updates: 5,952
Cumulative Timesteps: 49,666,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09493
Policy Entropy: 4.30701
Value Function Loss: 0.04480

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.04699
Policy Update Magnitude: 0.58089
Value Function Update Magnitude: 0.36118

Collected Steps per Second: 14,334.28933
Overall Steps per Second: 6,821.37122

Timestep Collection Time: 3.49009
Timestep Consumption Time: 3.84392
PPO Batch Consumption Time: 0.47434
Total Iteration Time: 7.33401

Cumulative Model Updates: 5,958
Cumulative Timesteps: 49,716,234

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 49716234...
Checkpoint 49716234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02304
Policy Entropy: 4.30738
Value Function Loss: 0.04854

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04614
Policy Update Magnitude: 0.57888
Value Function Update Magnitude: 0.38689

Collected Steps per Second: 14,303.65973
Overall Steps per Second: 6,734.38167

Timestep Collection Time: 3.49743
Timestep Consumption Time: 3.93102
PPO Batch Consumption Time: 0.47837
Total Iteration Time: 7.42845

Cumulative Model Updates: 5,964
Cumulative Timesteps: 49,766,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02341
Policy Entropy: 4.31265
Value Function Loss: 0.03670

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.03750
Policy Update Magnitude: 0.56955
Value Function Update Magnitude: 0.40049

Collected Steps per Second: 15,172.76100
Overall Steps per Second: 7,168.89479

Timestep Collection Time: 3.29683
Timestep Consumption Time: 3.68082
PPO Batch Consumption Time: 0.48060
Total Iteration Time: 6.97764

Cumulative Model Updates: 5,970
Cumulative Timesteps: 49,816,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 49816282...
Checkpoint 49816282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13408
Policy Entropy: 4.31196
Value Function Loss: 0.04589

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03934
Policy Update Magnitude: 0.57042
Value Function Update Magnitude: 0.36223

Collected Steps per Second: 14,302.79399
Overall Steps per Second: 6,778.47233

Timestep Collection Time: 3.49638
Timestep Consumption Time: 3.88109
PPO Batch Consumption Time: 0.47143
Total Iteration Time: 7.37747

Cumulative Model Updates: 5,976
Cumulative Timesteps: 49,866,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10133
Policy Entropy: 4.31013
Value Function Loss: 0.04625

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04437
Policy Update Magnitude: 0.57724
Value Function Update Magnitude: 0.35937

Collected Steps per Second: 14,319.80347
Overall Steps per Second: 6,734.30003

Timestep Collection Time: 3.49516
Timestep Consumption Time: 3.93694
PPO Batch Consumption Time: 0.49034
Total Iteration Time: 7.43210

Cumulative Model Updates: 5,982
Cumulative Timesteps: 49,916,340

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 49916340...
Checkpoint 49916340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01855
Policy Entropy: 4.30759
Value Function Loss: 0.05341

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04367
Policy Update Magnitude: 0.58536
Value Function Update Magnitude: 0.39115

Collected Steps per Second: 14,412.18913
Overall Steps per Second: 6,747.24995

Timestep Collection Time: 3.47067
Timestep Consumption Time: 3.94272
PPO Batch Consumption Time: 0.48881
Total Iteration Time: 7.41339

Cumulative Model Updates: 5,988
Cumulative Timesteps: 49,966,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00004
Policy Entropy: 4.31222
Value Function Loss: 0.05400

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03229
Policy Update Magnitude: 0.59188
Value Function Update Magnitude: 0.34952

Collected Steps per Second: 14,397.92478
Overall Steps per Second: 6,722.40776

Timestep Collection Time: 3.47453
Timestep Consumption Time: 3.96715
PPO Batch Consumption Time: 0.48244
Total Iteration Time: 7.44168

Cumulative Model Updates: 5,994
Cumulative Timesteps: 50,016,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 50016386...
Checkpoint 50016386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15512
Policy Entropy: 4.30999
Value Function Loss: 0.05965

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03867
Policy Update Magnitude: 0.61364
Value Function Update Magnitude: 0.33639

Collected Steps per Second: 14,151.19043
Overall Steps per Second: 6,782.84789

Timestep Collection Time: 3.53440
Timestep Consumption Time: 3.83949
PPO Batch Consumption Time: 0.48115
Total Iteration Time: 7.37389

Cumulative Model Updates: 6,000
Cumulative Timesteps: 50,066,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05132
Policy Entropy: 4.31179
Value Function Loss: 0.06291

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03632
Policy Update Magnitude: 0.63445
Value Function Update Magnitude: 0.33212

Collected Steps per Second: 14,359.35604
Overall Steps per Second: 6,787.25953

Timestep Collection Time: 3.48205
Timestep Consumption Time: 3.88469
PPO Batch Consumption Time: 0.47133
Total Iteration Time: 7.36674

Cumulative Model Updates: 6,006
Cumulative Timesteps: 50,116,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 50116402...
Checkpoint 50116402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06140
Policy Entropy: 4.31190
Value Function Loss: 0.05591

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03515
Policy Update Magnitude: 0.61353
Value Function Update Magnitude: 0.35278

Collected Steps per Second: 14,322.03402
Overall Steps per Second: 6,855.50486

Timestep Collection Time: 3.49196
Timestep Consumption Time: 3.80320
PPO Batch Consumption Time: 0.47827
Total Iteration Time: 7.29516

Cumulative Model Updates: 6,012
Cumulative Timesteps: 50,166,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01578
Policy Entropy: 4.31286
Value Function Loss: 0.04529

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02844
Policy Update Magnitude: 0.59154
Value Function Update Magnitude: 0.36549

Collected Steps per Second: 14,238.56728
Overall Steps per Second: 6,745.71070

Timestep Collection Time: 3.51299
Timestep Consumption Time: 3.90209
PPO Batch Consumption Time: 0.48217
Total Iteration Time: 7.41508

Cumulative Model Updates: 6,018
Cumulative Timesteps: 50,216,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 50216434...
Checkpoint 50216434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16894
Policy Entropy: 4.31565
Value Function Loss: 0.04625

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02730
Policy Update Magnitude: 0.57344
Value Function Update Magnitude: 0.37124

Collected Steps per Second: 14,085.98941
Overall Steps per Second: 6,724.21732

Timestep Collection Time: 3.55161
Timestep Consumption Time: 3.88836
PPO Batch Consumption Time: 0.48422
Total Iteration Time: 7.43997

Cumulative Model Updates: 6,024
Cumulative Timesteps: 50,266,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05722
Policy Entropy: 4.31795
Value Function Loss: 0.03886

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02941
Policy Update Magnitude: 0.56506
Value Function Update Magnitude: 0.43929

Collected Steps per Second: 14,658.35862
Overall Steps per Second: 6,800.07394

Timestep Collection Time: 3.41266
Timestep Consumption Time: 3.94373
PPO Batch Consumption Time: 0.48708
Total Iteration Time: 7.35639

Cumulative Model Updates: 6,030
Cumulative Timesteps: 50,316,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 50316486...
Checkpoint 50316486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06552
Policy Entropy: 4.32114
Value Function Loss: 0.03600

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.55236
Value Function Update Magnitude: 0.42727

Collected Steps per Second: 14,294.87939
Overall Steps per Second: 6,677.69350

Timestep Collection Time: 3.49790
Timestep Consumption Time: 3.99002
PPO Batch Consumption Time: 0.49248
Total Iteration Time: 7.48791

Cumulative Model Updates: 6,036
Cumulative Timesteps: 50,366,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18209
Policy Entropy: 4.32435
Value Function Loss: 0.03759

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02057
Policy Update Magnitude: 0.53894
Value Function Update Magnitude: 0.44019

Collected Steps per Second: 14,464.06724
Overall Steps per Second: 6,784.72819

Timestep Collection Time: 3.45809
Timestep Consumption Time: 3.91406
PPO Batch Consumption Time: 0.48666
Total Iteration Time: 7.37214

Cumulative Model Updates: 6,042
Cumulative Timesteps: 50,416,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 50416506...
Checkpoint 50416506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06992
Policy Entropy: 4.32259
Value Function Loss: 0.04321

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02342
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.45782

Collected Steps per Second: 14,154.20438
Overall Steps per Second: 6,630.65378

Timestep Collection Time: 3.53421
Timestep Consumption Time: 4.01014
PPO Batch Consumption Time: 0.49919
Total Iteration Time: 7.54435

Cumulative Model Updates: 6,048
Cumulative Timesteps: 50,466,530

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11537
Policy Entropy: 4.32204
Value Function Loss: 0.04331

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.56682
Value Function Update Magnitude: 0.46039

Collected Steps per Second: 14,554.78555
Overall Steps per Second: 6,795.20878

Timestep Collection Time: 3.43722
Timestep Consumption Time: 3.92503
PPO Batch Consumption Time: 0.47828
Total Iteration Time: 7.36225

Cumulative Model Updates: 6,054
Cumulative Timesteps: 50,516,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 50516558...
Checkpoint 50516558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00384
Policy Entropy: 4.31645
Value Function Loss: 0.03904

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02544
Policy Update Magnitude: 0.57770
Value Function Update Magnitude: 0.46823

Collected Steps per Second: 14,279.88180
Overall Steps per Second: 6,766.61798

Timestep Collection Time: 3.50157
Timestep Consumption Time: 3.88794
PPO Batch Consumption Time: 0.47574
Total Iteration Time: 7.38951

Cumulative Model Updates: 6,060
Cumulative Timesteps: 50,566,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04991
Policy Entropy: 4.32088
Value Function Loss: 0.04190

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02700
Policy Update Magnitude: 0.58389
Value Function Update Magnitude: 0.43014

Collected Steps per Second: 14,664.65486
Overall Steps per Second: 6,886.54319

Timestep Collection Time: 3.41106
Timestep Consumption Time: 3.85267
PPO Batch Consumption Time: 0.47804
Total Iteration Time: 7.26373

Cumulative Model Updates: 6,066
Cumulative Timesteps: 50,616,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 50616582...
Checkpoint 50616582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15111
Policy Entropy: 4.31913
Value Function Loss: 0.04872

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03113
Policy Update Magnitude: 0.59522
Value Function Update Magnitude: 0.45254

Collected Steps per Second: 14,335.53688
Overall Steps per Second: 6,716.84351

Timestep Collection Time: 3.48798
Timestep Consumption Time: 3.95630
PPO Batch Consumption Time: 0.48636
Total Iteration Time: 7.44427

Cumulative Model Updates: 6,072
Cumulative Timesteps: 50,666,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01236
Policy Entropy: 4.31519
Value Function Loss: 0.04754

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03655
Policy Update Magnitude: 0.59017
Value Function Update Magnitude: 0.46797

Collected Steps per Second: 14,389.51068
Overall Steps per Second: 6,809.73304

Timestep Collection Time: 3.47642
Timestep Consumption Time: 3.86953
PPO Batch Consumption Time: 0.48047
Total Iteration Time: 7.34596

Cumulative Model Updates: 6,078
Cumulative Timesteps: 50,716,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 50716608...
Checkpoint 50716608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02897
Policy Entropy: 4.31511
Value Function Loss: 0.04056

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03202
Policy Update Magnitude: 0.56692
Value Function Update Magnitude: 0.43559

Collected Steps per Second: 14,375.11646
Overall Steps per Second: 6,829.23666

Timestep Collection Time: 3.48018
Timestep Consumption Time: 3.84538
PPO Batch Consumption Time: 0.46777
Total Iteration Time: 7.32556

Cumulative Model Updates: 6,084
Cumulative Timesteps: 50,766,636

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01104
Policy Entropy: 4.31504
Value Function Loss: 0.03313

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 0.53057
Value Function Update Magnitude: 0.38823

Collected Steps per Second: 14,404.81475
Overall Steps per Second: 6,838.84113

Timestep Collection Time: 3.47189
Timestep Consumption Time: 3.84104
PPO Batch Consumption Time: 0.47961
Total Iteration Time: 7.31293

Cumulative Model Updates: 6,090
Cumulative Timesteps: 50,816,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 50816648...
Checkpoint 50816648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.42239
Policy Entropy: 4.31873
Value Function Loss: 0.03912

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.52662
Value Function Update Magnitude: 0.43264

Collected Steps per Second: 14,297.31457
Overall Steps per Second: 6,751.49297

Timestep Collection Time: 3.49856
Timestep Consumption Time: 3.91017
PPO Batch Consumption Time: 0.49438
Total Iteration Time: 7.40873

Cumulative Model Updates: 6,096
Cumulative Timesteps: 50,866,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14003
Policy Entropy: 4.31191
Value Function Loss: 0.03539

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.56163
Value Function Update Magnitude: 0.48680

Collected Steps per Second: 14,431.98360
Overall Steps per Second: 6,777.53208

Timestep Collection Time: 3.46467
Timestep Consumption Time: 3.91295
PPO Batch Consumption Time: 0.47861
Total Iteration Time: 7.37761

Cumulative Model Updates: 6,102
Cumulative Timesteps: 50,916,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 50916670...
Checkpoint 50916670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11426
Policy Entropy: 4.30918
Value Function Loss: 0.04067

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03196
Policy Update Magnitude: 0.57985
Value Function Update Magnitude: 0.49871

Collected Steps per Second: 14,530.08967
Overall Steps per Second: 6,882.71627

Timestep Collection Time: 3.44237
Timestep Consumption Time: 3.82482
PPO Batch Consumption Time: 0.48368
Total Iteration Time: 7.26719

Cumulative Model Updates: 6,108
Cumulative Timesteps: 50,966,688

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01009
Policy Entropy: 4.30320
Value Function Loss: 0.04690

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03216
Policy Update Magnitude: 0.59400
Value Function Update Magnitude: 0.49035

Collected Steps per Second: 14,596.99029
Overall Steps per Second: 6,736.75859

Timestep Collection Time: 3.42673
Timestep Consumption Time: 3.99820
PPO Batch Consumption Time: 0.49327
Total Iteration Time: 7.42494

Cumulative Model Updates: 6,114
Cumulative Timesteps: 51,016,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 51016708...
Checkpoint 51016708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09767
Policy Entropy: 4.30568
Value Function Loss: 0.05027

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.03448
Policy Update Magnitude: 0.62276
Value Function Update Magnitude: 0.50542

Collected Steps per Second: 14,384.01383
Overall Steps per Second: 6,750.63692

Timestep Collection Time: 3.47705
Timestep Consumption Time: 3.93173
PPO Batch Consumption Time: 0.48839
Total Iteration Time: 7.40878

Cumulative Model Updates: 6,120
Cumulative Timesteps: 51,066,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03115
Policy Entropy: 4.30291
Value Function Loss: 0.04605

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03433
Policy Update Magnitude: 0.61548
Value Function Update Magnitude: 0.50325

Collected Steps per Second: 14,506.09317
Overall Steps per Second: 6,791.06323

Timestep Collection Time: 3.44807
Timestep Consumption Time: 3.91720
PPO Batch Consumption Time: 0.48515
Total Iteration Time: 7.36527

Cumulative Model Updates: 6,126
Cumulative Timesteps: 51,116,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 51116740...
Checkpoint 51116740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04599
Policy Entropy: 4.30787
Value Function Loss: 0.03898

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.58835
Value Function Update Magnitude: 0.47638

Collected Steps per Second: 14,456.51119
Overall Steps per Second: 6,780.34117

Timestep Collection Time: 3.46003
Timestep Consumption Time: 3.91718
PPO Batch Consumption Time: 0.48014
Total Iteration Time: 7.37721

Cumulative Model Updates: 6,132
Cumulative Timesteps: 51,166,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02812
Policy Entropy: 4.30861
Value Function Loss: 0.03280

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02907
Policy Update Magnitude: 0.56428
Value Function Update Magnitude: 0.45743

Collected Steps per Second: 14,446.92663
Overall Steps per Second: 6,722.44900

Timestep Collection Time: 3.46344
Timestep Consumption Time: 3.97969
PPO Batch Consumption Time: 0.50466
Total Iteration Time: 7.44312

Cumulative Model Updates: 6,138
Cumulative Timesteps: 51,216,796

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 51216796...
Checkpoint 51216796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01592
Policy Entropy: 4.31389
Value Function Loss: 0.02979

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02722
Policy Update Magnitude: 0.53581
Value Function Update Magnitude: 0.42074

Collected Steps per Second: 14,426.92457
Overall Steps per Second: 6,782.07193

Timestep Collection Time: 3.46616
Timestep Consumption Time: 3.90710
PPO Batch Consumption Time: 0.48154
Total Iteration Time: 7.37326

Cumulative Model Updates: 6,144
Cumulative Timesteps: 51,266,802

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16809
Policy Entropy: 4.31082
Value Function Loss: 0.03786

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02533
Policy Update Magnitude: 0.53178
Value Function Update Magnitude: 0.42791

Collected Steps per Second: 14,509.67076
Overall Steps per Second: 6,770.02099

Timestep Collection Time: 3.44749
Timestep Consumption Time: 3.94126
PPO Batch Consumption Time: 0.48504
Total Iteration Time: 7.38875

Cumulative Model Updates: 6,150
Cumulative Timesteps: 51,316,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 51316824...
Checkpoint 51316824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08467
Policy Entropy: 4.30825
Value Function Loss: 0.03652

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.56639
Value Function Update Magnitude: 0.45545

Collected Steps per Second: 14,691.91448
Overall Steps per Second: 6,808.19138

Timestep Collection Time: 3.40350
Timestep Consumption Time: 3.94118
PPO Batch Consumption Time: 0.49183
Total Iteration Time: 7.34468

Cumulative Model Updates: 6,156
Cumulative Timesteps: 51,366,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06987
Policy Entropy: 4.31308
Value Function Loss: 0.03546

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.56701
Value Function Update Magnitude: 0.45075

Collected Steps per Second: 14,379.58087
Overall Steps per Second: 6,754.67775

Timestep Collection Time: 3.47924
Timestep Consumption Time: 3.92748
PPO Batch Consumption Time: 0.47885
Total Iteration Time: 7.40672

Cumulative Model Updates: 6,162
Cumulative Timesteps: 51,416,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 51416858...
Checkpoint 51416858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15464
Policy Entropy: 4.31941
Value Function Loss: 0.03662

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02333
Policy Update Magnitude: 0.57272
Value Function Update Magnitude: 0.49187

Collected Steps per Second: 14,311.66829
Overall Steps per Second: 6,798.57849

Timestep Collection Time: 3.49365
Timestep Consumption Time: 3.86083
PPO Batch Consumption Time: 0.48843
Total Iteration Time: 7.35448

Cumulative Model Updates: 6,168
Cumulative Timesteps: 51,466,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12383
Policy Entropy: 4.32117
Value Function Loss: 0.04342

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02627
Policy Update Magnitude: 0.61496
Value Function Update Magnitude: 0.50485

Collected Steps per Second: 14,466.65595
Overall Steps per Second: 6,698.35635

Timestep Collection Time: 3.45747
Timestep Consumption Time: 4.00974
PPO Batch Consumption Time: 0.49908
Total Iteration Time: 7.46720

Cumulative Model Updates: 6,174
Cumulative Timesteps: 51,516,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 51516876...
Checkpoint 51516876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17063
Policy Entropy: 4.30651
Value Function Loss: 0.04433

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02954
Policy Update Magnitude: 0.64302
Value Function Update Magnitude: 0.53167

Collected Steps per Second: 14,231.24773
Overall Steps per Second: 6,771.75977

Timestep Collection Time: 3.51466
Timestep Consumption Time: 3.87160
PPO Batch Consumption Time: 0.49220
Total Iteration Time: 7.38626

Cumulative Model Updates: 6,180
Cumulative Timesteps: 51,566,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07430
Policy Entropy: 4.30203
Value Function Loss: 0.04081

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03306
Policy Update Magnitude: 0.62168
Value Function Update Magnitude: 0.54552

Collected Steps per Second: 14,429.38376
Overall Steps per Second: 6,777.30805

Timestep Collection Time: 3.46640
Timestep Consumption Time: 3.91382
PPO Batch Consumption Time: 0.47572
Total Iteration Time: 7.38022

Cumulative Model Updates: 6,186
Cumulative Timesteps: 51,616,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 51616912...
Checkpoint 51616912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13674
Policy Entropy: 4.30425
Value Function Loss: 0.03762

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03093
Policy Update Magnitude: 0.61664
Value Function Update Magnitude: 0.51423

Collected Steps per Second: 14,294.47837
Overall Steps per Second: 6,759.11419

Timestep Collection Time: 3.49967
Timestep Consumption Time: 3.90159
PPO Batch Consumption Time: 0.48808
Total Iteration Time: 7.40127

Cumulative Model Updates: 6,192
Cumulative Timesteps: 51,666,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06596
Policy Entropy: 4.30969
Value Function Loss: 0.04196

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03229
Policy Update Magnitude: 0.62969
Value Function Update Magnitude: 0.51567

Collected Steps per Second: 14,378.33604
Overall Steps per Second: 6,854.05427

Timestep Collection Time: 3.48121
Timestep Consumption Time: 3.82162
PPO Batch Consumption Time: 0.48464
Total Iteration Time: 7.30283

Cumulative Model Updates: 6,198
Cumulative Timesteps: 51,716,992

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 51716992...
Checkpoint 51716992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04760
Policy Entropy: 4.30989
Value Function Loss: 0.04470

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03274
Policy Update Magnitude: 0.64423
Value Function Update Magnitude: 0.52374

Collected Steps per Second: 14,326.41572
Overall Steps per Second: 6,716.77638

Timestep Collection Time: 3.49131
Timestep Consumption Time: 3.95541
PPO Batch Consumption Time: 0.49178
Total Iteration Time: 7.44673

Cumulative Model Updates: 6,204
Cumulative Timesteps: 51,767,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19820
Policy Entropy: 4.30691
Value Function Loss: 0.04230

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03531
Policy Update Magnitude: 0.62350
Value Function Update Magnitude: 0.49791

Collected Steps per Second: 14,244.84140
Overall Steps per Second: 6,846.63436

Timestep Collection Time: 3.51089
Timestep Consumption Time: 3.79373
PPO Batch Consumption Time: 0.47762
Total Iteration Time: 7.30461

Cumulative Model Updates: 6,210
Cumulative Timesteps: 51,817,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 51817022...
Checkpoint 51817022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02519
Policy Entropy: 4.30953
Value Function Loss: 0.03798

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03050
Policy Update Magnitude: 0.60065
Value Function Update Magnitude: 0.48583

Collected Steps per Second: 14,395.12245
Overall Steps per Second: 6,680.84460

Timestep Collection Time: 3.47368
Timestep Consumption Time: 4.01101
PPO Batch Consumption Time: 0.49957
Total Iteration Time: 7.48468

Cumulative Model Updates: 6,216
Cumulative Timesteps: 51,867,026

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03750
Policy Entropy: 4.31380
Value Function Loss: 0.03310

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03012
Policy Update Magnitude: 0.58250
Value Function Update Magnitude: 0.42906

Collected Steps per Second: 14,376.39202
Overall Steps per Second: 6,738.04117

Timestep Collection Time: 3.47890
Timestep Consumption Time: 3.94373
PPO Batch Consumption Time: 0.49399
Total Iteration Time: 7.42263

Cumulative Model Updates: 6,222
Cumulative Timesteps: 51,917,040

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 51917040...
Checkpoint 51917040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10031
Policy Entropy: 4.31215
Value Function Loss: 0.03418

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04370
Policy Update Magnitude: 0.57154
Value Function Update Magnitude: 0.42162

Collected Steps per Second: 14,673.92538
Overall Steps per Second: 6,864.70357

Timestep Collection Time: 3.40890
Timestep Consumption Time: 3.87794
PPO Batch Consumption Time: 0.47365
Total Iteration Time: 7.28684

Cumulative Model Updates: 6,228
Cumulative Timesteps: 51,967,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16184
Policy Entropy: 4.31260
Value Function Loss: 0.03216

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03245
Policy Update Magnitude: 0.56294
Value Function Update Magnitude: 0.41257

Collected Steps per Second: 14,031.14364
Overall Steps per Second: 6,690.06961

Timestep Collection Time: 3.56635
Timestep Consumption Time: 3.91339
PPO Batch Consumption Time: 0.48658
Total Iteration Time: 7.47974

Cumulative Model Updates: 6,234
Cumulative Timesteps: 52,017,102

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 52017102...
Checkpoint 52017102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01780
Policy Entropy: 4.31150
Value Function Loss: 0.02947

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03083
Policy Update Magnitude: 0.53592
Value Function Update Magnitude: 0.39653

Collected Steps per Second: 14,281.68650
Overall Steps per Second: 6,829.05687

Timestep Collection Time: 3.50281
Timestep Consumption Time: 3.82265
PPO Batch Consumption Time: 0.47550
Total Iteration Time: 7.32546

Cumulative Model Updates: 6,240
Cumulative Timesteps: 52,067,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09529
Policy Entropy: 4.31174
Value Function Loss: 0.02581

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03566
Policy Update Magnitude: 0.51652
Value Function Update Magnitude: 0.40686

Collected Steps per Second: 14,366.39754
Overall Steps per Second: 6,801.39435

Timestep Collection Time: 3.48118
Timestep Consumption Time: 3.87202
PPO Batch Consumption Time: 0.46976
Total Iteration Time: 7.35320

Cumulative Model Updates: 6,246
Cumulative Timesteps: 52,117,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 52117140...
Checkpoint 52117140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06061
Policy Entropy: 4.31366
Value Function Loss: 0.02452

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02878
Policy Update Magnitude: 0.50980
Value Function Update Magnitude: 0.40137

Collected Steps per Second: 14,140.82407
Overall Steps per Second: 6,639.69071

Timestep Collection Time: 3.53699
Timestep Consumption Time: 3.99589
PPO Batch Consumption Time: 0.50179
Total Iteration Time: 7.53288

Cumulative Model Updates: 6,252
Cumulative Timesteps: 52,167,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08832
Policy Entropy: 4.32390
Value Function Loss: 0.02631

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.51967
Value Function Update Magnitude: 0.41094

Collected Steps per Second: 14,510.51243
Overall Steps per Second: 6,811.90236

Timestep Collection Time: 3.44716
Timestep Consumption Time: 3.89587
PPO Batch Consumption Time: 0.47772
Total Iteration Time: 7.34303

Cumulative Model Updates: 6,258
Cumulative Timesteps: 52,217,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 52217176...
Checkpoint 52217176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08234
Policy Entropy: 4.32263
Value Function Loss: 0.03410

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02239
Policy Update Magnitude: 0.54029
Value Function Update Magnitude: 0.42662

Collected Steps per Second: 14,247.26052
Overall Steps per Second: 6,736.51871

Timestep Collection Time: 3.50945
Timestep Consumption Time: 3.91278
PPO Batch Consumption Time: 0.47781
Total Iteration Time: 7.42223

Cumulative Model Updates: 6,264
Cumulative Timesteps: 52,267,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04671
Policy Entropy: 4.32440
Value Function Loss: 0.03347

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.55345
Value Function Update Magnitude: 0.42598

Collected Steps per Second: 14,110.01762
Overall Steps per Second: 6,743.97829

Timestep Collection Time: 3.54429
Timestep Consumption Time: 3.87121
PPO Batch Consumption Time: 0.48479
Total Iteration Time: 7.41550

Cumulative Model Updates: 6,270
Cumulative Timesteps: 52,317,186

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 52317186...
Checkpoint 52317186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15226
Policy Entropy: 4.31870
Value Function Loss: 0.03532

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02414
Policy Update Magnitude: 0.56592
Value Function Update Magnitude: 0.41469

Collected Steps per Second: 14,088.44039
Overall Steps per Second: 6,742.61435

Timestep Collection Time: 3.55071
Timestep Consumption Time: 3.86837
PPO Batch Consumption Time: 0.47717
Total Iteration Time: 7.41908

Cumulative Model Updates: 6,276
Cumulative Timesteps: 52,367,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03531
Policy Entropy: 4.31805
Value Function Loss: 0.03390

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02583
Policy Update Magnitude: 0.56445
Value Function Update Magnitude: 0.43551

Collected Steps per Second: 14,237.11114
Overall Steps per Second: 6,763.53647

Timestep Collection Time: 3.51209
Timestep Consumption Time: 3.88079
PPO Batch Consumption Time: 0.48157
Total Iteration Time: 7.39288

Cumulative Model Updates: 6,282
Cumulative Timesteps: 52,417,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 52417212...
Checkpoint 52417212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05430
Policy Entropy: 4.31320
Value Function Loss: 0.03665

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02523
Policy Update Magnitude: 0.56994
Value Function Update Magnitude: 0.46737

Collected Steps per Second: 14,541.81015
Overall Steps per Second: 6,691.08068

Timestep Collection Time: 3.43960
Timestep Consumption Time: 4.03573
PPO Batch Consumption Time: 0.50368
Total Iteration Time: 7.47532

Cumulative Model Updates: 6,288
Cumulative Timesteps: 52,467,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05183
Policy Entropy: 4.31269
Value Function Loss: 0.03367

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.58926
Value Function Update Magnitude: 0.52583

Collected Steps per Second: 14,185.17021
Overall Steps per Second: 6,700.89015

Timestep Collection Time: 3.52664
Timestep Consumption Time: 3.93893
PPO Batch Consumption Time: 0.49368
Total Iteration Time: 7.46558

Cumulative Model Updates: 6,294
Cumulative Timesteps: 52,517,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 52517256...
Checkpoint 52517256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00674
Policy Entropy: 4.31501
Value Function Loss: 0.03490

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.60923
Value Function Update Magnitude: 0.51114

Collected Steps per Second: 14,048.86307
Overall Steps per Second: 6,707.10638

Timestep Collection Time: 3.56100
Timestep Consumption Time: 3.89795
PPO Batch Consumption Time: 0.49304
Total Iteration Time: 7.45895

Cumulative Model Updates: 6,300
Cumulative Timesteps: 52,567,284

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07587
Policy Entropy: 4.32181
Value Function Loss: 0.02709

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03221
Policy Update Magnitude: 0.58931
Value Function Update Magnitude: 0.45546

Collected Steps per Second: 14,183.18101
Overall Steps per Second: 6,778.57347

Timestep Collection Time: 3.52699
Timestep Consumption Time: 3.85273
PPO Batch Consumption Time: 0.47361
Total Iteration Time: 7.37972

Cumulative Model Updates: 6,306
Cumulative Timesteps: 52,617,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 52617308...
Checkpoint 52617308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19472
Policy Entropy: 4.33049
Value Function Loss: 0.03055

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02631
Policy Update Magnitude: 0.53347
Value Function Update Magnitude: 0.41192

Collected Steps per Second: 14,158.89854
Overall Steps per Second: 6,743.87209

Timestep Collection Time: 3.53361
Timestep Consumption Time: 3.88528
PPO Batch Consumption Time: 0.47742
Total Iteration Time: 7.41888

Cumulative Model Updates: 6,312
Cumulative Timesteps: 52,667,340

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00173
Policy Entropy: 4.32928
Value Function Loss: 0.03377

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02271
Policy Update Magnitude: 0.54846
Value Function Update Magnitude: 0.43900

Collected Steps per Second: 14,476.03158
Overall Steps per Second: 6,721.36127

Timestep Collection Time: 3.45426
Timestep Consumption Time: 3.98530
PPO Batch Consumption Time: 0.48792
Total Iteration Time: 7.43956

Cumulative Model Updates: 6,318
Cumulative Timesteps: 52,717,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 52717344...
Checkpoint 52717344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08576
Policy Entropy: 4.32727
Value Function Loss: 0.03797

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03206
Policy Update Magnitude: 0.58841
Value Function Update Magnitude: 0.47533

Collected Steps per Second: 14,053.10564
Overall Steps per Second: 6,692.15005

Timestep Collection Time: 3.55950
Timestep Consumption Time: 3.91523
PPO Batch Consumption Time: 0.48824
Total Iteration Time: 7.47473

Cumulative Model Updates: 6,324
Cumulative Timesteps: 52,767,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01138
Policy Entropy: 4.32077
Value Function Loss: 0.03943

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03771
Policy Update Magnitude: 0.61034
Value Function Update Magnitude: 0.46112

Collected Steps per Second: 14,087.94606
Overall Steps per Second: 6,771.32534

Timestep Collection Time: 3.54999
Timestep Consumption Time: 3.83587
PPO Batch Consumption Time: 0.48986
Total Iteration Time: 7.38585

Cumulative Model Updates: 6,330
Cumulative Timesteps: 52,817,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 52817378...
Checkpoint 52817378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09688
Policy Entropy: 4.32199
Value Function Loss: 0.03574

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03399
Policy Update Magnitude: 0.59014
Value Function Update Magnitude: 0.40395

Collected Steps per Second: 14,113.40812
Overall Steps per Second: 6,670.56112

Timestep Collection Time: 3.54273
Timestep Consumption Time: 3.95289
PPO Batch Consumption Time: 0.49130
Total Iteration Time: 7.49562

Cumulative Model Updates: 6,336
Cumulative Timesteps: 52,867,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02412
Policy Entropy: 4.31387
Value Function Loss: 0.03258

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04024
Policy Update Magnitude: 0.55078
Value Function Update Magnitude: 0.34351

Collected Steps per Second: 14,328.40738
Overall Steps per Second: 6,760.25976

Timestep Collection Time: 3.49167
Timestep Consumption Time: 3.90894
PPO Batch Consumption Time: 0.49497
Total Iteration Time: 7.40060

Cumulative Model Updates: 6,342
Cumulative Timesteps: 52,917,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 52917408...
Checkpoint 52917408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04197
Policy Entropy: 4.31857
Value Function Loss: 0.03113

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03426
Policy Update Magnitude: 0.53493
Value Function Update Magnitude: 0.33816

Collected Steps per Second: 14,141.24340
Overall Steps per Second: 6,679.41641

Timestep Collection Time: 3.53774
Timestep Consumption Time: 3.95214
PPO Batch Consumption Time: 0.48828
Total Iteration Time: 7.48988

Cumulative Model Updates: 6,348
Cumulative Timesteps: 52,967,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12518
Policy Entropy: 4.32161
Value Function Loss: 0.02898

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.52011
Value Function Update Magnitude: 0.40597

Collected Steps per Second: 14,219.71004
Overall Steps per Second: 6,776.33705

Timestep Collection Time: 3.51709
Timestep Consumption Time: 3.86330
PPO Batch Consumption Time: 0.48326
Total Iteration Time: 7.38039

Cumulative Model Updates: 6,354
Cumulative Timesteps: 53,017,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 53017448...
Checkpoint 53017448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00823
Policy Entropy: 4.32530
Value Function Loss: 0.02776

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02329
Policy Update Magnitude: 0.51451
Value Function Update Magnitude: 0.42389

Collected Steps per Second: 14,560.78342
Overall Steps per Second: 6,751.87796

Timestep Collection Time: 3.43471
Timestep Consumption Time: 3.97242
PPO Batch Consumption Time: 0.48590
Total Iteration Time: 7.40712

Cumulative Model Updates: 6,360
Cumulative Timesteps: 53,067,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11344
Policy Entropy: 4.32750
Value Function Loss: 0.02573

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02513
Policy Update Magnitude: 0.50659
Value Function Update Magnitude: 0.39956

Collected Steps per Second: 14,311.34055
Overall Steps per Second: 6,748.31420

Timestep Collection Time: 3.49541
Timestep Consumption Time: 3.91740
PPO Batch Consumption Time: 0.48612
Total Iteration Time: 7.41281

Cumulative Model Updates: 6,366
Cumulative Timesteps: 53,117,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 53117484...
Checkpoint 53117484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15366
Policy Entropy: 4.32863
Value Function Loss: 0.02538

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01929
Policy Update Magnitude: 0.50200
Value Function Update Magnitude: 0.40502

Collected Steps per Second: 14,142.98700
Overall Steps per Second: 6,727.57098

Timestep Collection Time: 3.53560
Timestep Consumption Time: 3.89709
PPO Batch Consumption Time: 0.48991
Total Iteration Time: 7.43270

Cumulative Model Updates: 6,372
Cumulative Timesteps: 53,167,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05383
Policy Entropy: 4.32650
Value Function Loss: 0.02774

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.01999
Policy Update Magnitude: 0.53312
Value Function Update Magnitude: 0.44291

Collected Steps per Second: 14,188.22554
Overall Steps per Second: 6,664.26442

Timestep Collection Time: 3.52574
Timestep Consumption Time: 3.98056
PPO Batch Consumption Time: 0.49511
Total Iteration Time: 7.50630

Cumulative Model Updates: 6,378
Cumulative Timesteps: 53,217,512

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 53217512...
Checkpoint 53217512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00078
Policy Entropy: 4.31606
Value Function Loss: 0.02689

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02275
Policy Update Magnitude: 0.53767
Value Function Update Magnitude: 0.42054

Collected Steps per Second: 14,239.47829
Overall Steps per Second: 6,738.21570

Timestep Collection Time: 3.51291
Timestep Consumption Time: 3.91072
PPO Batch Consumption Time: 0.47783
Total Iteration Time: 7.42363

Cumulative Model Updates: 6,384
Cumulative Timesteps: 53,267,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11188
Policy Entropy: 4.31963
Value Function Loss: 0.02675

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.52026
Value Function Update Magnitude: 0.37849

Collected Steps per Second: 14,637.64054
Overall Steps per Second: 6,745.77584

Timestep Collection Time: 3.41640
Timestep Consumption Time: 3.99683
PPO Batch Consumption Time: 0.49829
Total Iteration Time: 7.41323

Cumulative Model Updates: 6,390
Cumulative Timesteps: 53,317,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 53317542...
Checkpoint 53317542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22090
Policy Entropy: 4.31818
Value Function Loss: 0.02832

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02082
Policy Update Magnitude: 0.52250
Value Function Update Magnitude: 0.37210

Collected Steps per Second: 14,172.84677
Overall Steps per Second: 6,697.19390

Timestep Collection Time: 3.52830
Timestep Consumption Time: 3.93841
PPO Batch Consumption Time: 0.48361
Total Iteration Time: 7.46671

Cumulative Model Updates: 6,396
Cumulative Timesteps: 53,367,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09345
Policy Entropy: 4.31779
Value Function Loss: 0.03210

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02268
Policy Update Magnitude: 0.54697
Value Function Update Magnitude: 0.40079

Collected Steps per Second: 14,258.93820
Overall Steps per Second: 6,776.93933

Timestep Collection Time: 3.50755
Timestep Consumption Time: 3.87247
PPO Batch Consumption Time: 0.48617
Total Iteration Time: 7.38003

Cumulative Model Updates: 6,402
Cumulative Timesteps: 53,417,562

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 53417562...
Checkpoint 53417562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16404
Policy Entropy: 4.31625
Value Function Loss: 0.03813

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.55891
Value Function Update Magnitude: 0.40789

Collected Steps per Second: 14,227.79719
Overall Steps per Second: 6,864.31926

Timestep Collection Time: 3.51495
Timestep Consumption Time: 3.77055
PPO Batch Consumption Time: 0.46118
Total Iteration Time: 7.28550

Cumulative Model Updates: 6,408
Cumulative Timesteps: 53,467,572

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09413
Policy Entropy: 4.31687
Value Function Loss: 0.04511

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03002
Policy Update Magnitude: 0.58247
Value Function Update Magnitude: 0.41451

Collected Steps per Second: 14,278.47624
Overall Steps per Second: 6,899.12182

Timestep Collection Time: 3.50331
Timestep Consumption Time: 3.74717
PPO Batch Consumption Time: 0.47140
Total Iteration Time: 7.25049

Cumulative Model Updates: 6,414
Cumulative Timesteps: 53,517,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 53517594...
Checkpoint 53517594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11568
Policy Entropy: 4.31784
Value Function Loss: 0.04117

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03209
Policy Update Magnitude: 0.58661
Value Function Update Magnitude: 0.41420

Collected Steps per Second: 14,247.26526
Overall Steps per Second: 6,739.78495

Timestep Collection Time: 3.51029
Timestep Consumption Time: 3.91013
PPO Batch Consumption Time: 0.47747
Total Iteration Time: 7.42041

Cumulative Model Updates: 6,420
Cumulative Timesteps: 53,567,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02519
Policy Entropy: 4.31236
Value Function Loss: 0.03426

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03375
Policy Update Magnitude: 0.54078
Value Function Update Magnitude: 0.40792

Collected Steps per Second: 14,104.58997
Overall Steps per Second: 6,791.29267

Timestep Collection Time: 3.54537
Timestep Consumption Time: 3.81788
PPO Batch Consumption Time: 0.47121
Total Iteration Time: 7.36325

Cumulative Model Updates: 6,426
Cumulative Timesteps: 53,617,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 53617612...
Checkpoint 53617612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02530
Policy Entropy: 4.32186
Value Function Loss: 0.02453

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02979
Policy Update Magnitude: 0.50790
Value Function Update Magnitude: 0.39276

Collected Steps per Second: 14,964.76980
Overall Steps per Second: 7,085.18450

Timestep Collection Time: 3.34345
Timestep Consumption Time: 3.71833
PPO Batch Consumption Time: 0.48298
Total Iteration Time: 7.06178

Cumulative Model Updates: 6,432
Cumulative Timesteps: 53,667,646

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10259
Policy Entropy: 4.32254
Value Function Loss: 0.02225

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02819
Policy Update Magnitude: 0.49561
Value Function Update Magnitude: 0.38234

Collected Steps per Second: 13,910.11899
Overall Steps per Second: 6,575.36799

Timestep Collection Time: 3.59637
Timestep Consumption Time: 4.01172
PPO Batch Consumption Time: 0.49858
Total Iteration Time: 7.60809

Cumulative Model Updates: 6,438
Cumulative Timesteps: 53,717,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 53717672...
Checkpoint 53717672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09872
Policy Entropy: 4.32488
Value Function Loss: 0.02223

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02326
Policy Update Magnitude: 0.50583
Value Function Update Magnitude: 0.37046

Collected Steps per Second: 13,825.29378
Overall Steps per Second: 6,688.11516

Timestep Collection Time: 3.61685
Timestep Consumption Time: 3.85970
PPO Batch Consumption Time: 0.48933
Total Iteration Time: 7.47655

Cumulative Model Updates: 6,444
Cumulative Timesteps: 53,767,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00437
Policy Entropy: 4.32653
Value Function Loss: 0.01715

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02016
Policy Update Magnitude: 0.46636
Value Function Update Magnitude: 0.34261

Collected Steps per Second: 14,339.83529
Overall Steps per Second: 6,378.41723

Timestep Collection Time: 3.48777
Timestep Consumption Time: 4.35336
PPO Batch Consumption Time: 0.56090
Total Iteration Time: 7.84113

Cumulative Model Updates: 6,450
Cumulative Timesteps: 53,817,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 53817690...
Checkpoint 53817690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02854
Policy Entropy: 4.32888
Value Function Loss: 0.01890

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01617
Policy Update Magnitude: 0.45080
Value Function Update Magnitude: 0.34639

Collected Steps per Second: 13,962.90227
Overall Steps per Second: 6,359.24381

Timestep Collection Time: 3.58278
Timestep Consumption Time: 4.28388
PPO Batch Consumption Time: 0.54365
Total Iteration Time: 7.86666

Cumulative Model Updates: 6,456
Cumulative Timesteps: 53,867,716

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03779
Policy Entropy: 4.32814
Value Function Loss: 0.02603

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.01508
Policy Update Magnitude: 0.48290
Value Function Update Magnitude: 0.42048

Collected Steps per Second: 13,660.83292
Overall Steps per Second: 6,529.57168

Timestep Collection Time: 3.66259
Timestep Consumption Time: 4.00009
PPO Batch Consumption Time: 0.49206
Total Iteration Time: 7.66268

Cumulative Model Updates: 6,462
Cumulative Timesteps: 53,917,750

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 53917750...
Checkpoint 53917750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00520
Policy Entropy: 4.33056
Value Function Loss: 0.03456

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.01969
Policy Update Magnitude: 0.54878
Value Function Update Magnitude: 0.46177

Collected Steps per Second: 14,244.39148
Overall Steps per Second: 6,745.73148

Timestep Collection Time: 3.51114
Timestep Consumption Time: 3.90303
PPO Batch Consumption Time: 0.48451
Total Iteration Time: 7.41417

Cumulative Model Updates: 6,468
Cumulative Timesteps: 53,967,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14125
Policy Entropy: 4.32286
Value Function Loss: 0.03658

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.58177
Value Function Update Magnitude: 0.45674

Collected Steps per Second: 14,370.33989
Overall Steps per Second: 6,788.41602

Timestep Collection Time: 3.47953
Timestep Consumption Time: 3.88626
PPO Batch Consumption Time: 0.48869
Total Iteration Time: 7.36578

Cumulative Model Updates: 6,474
Cumulative Timesteps: 54,017,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 54017766...
Checkpoint 54017766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.25607
Policy Entropy: 4.32555
Value Function Loss: 0.03069

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02294
Policy Update Magnitude: 0.55700
Value Function Update Magnitude: 0.40717

Collected Steps per Second: 14,306.11318
Overall Steps per Second: 6,359.27695

Timestep Collection Time: 3.49585
Timestep Consumption Time: 4.36857
PPO Batch Consumption Time: 0.55203
Total Iteration Time: 7.86442

Cumulative Model Updates: 6,480
Cumulative Timesteps: 54,067,778

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08035
Policy Entropy: 4.31919
Value Function Loss: 0.02759

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02159
Policy Update Magnitude: 0.52482
Value Function Update Magnitude: 0.36295

Collected Steps per Second: 13,354.30048
Overall Steps per Second: 6,330.97110

Timestep Collection Time: 3.74516
Timestep Consumption Time: 4.15473
PPO Batch Consumption Time: 0.54864
Total Iteration Time: 7.89989

Cumulative Model Updates: 6,486
Cumulative Timesteps: 54,117,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 54117792...
Checkpoint 54117792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04601
Policy Entropy: 4.31700
Value Function Loss: 0.02461

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02145
Policy Update Magnitude: 0.49917
Value Function Update Magnitude: 0.33710

Collected Steps per Second: 12,856.71175
Overall Steps per Second: 6,384.62345

Timestep Collection Time: 3.89135
Timestep Consumption Time: 3.94466
PPO Batch Consumption Time: 0.49289
Total Iteration Time: 7.83601

Cumulative Model Updates: 6,492
Cumulative Timesteps: 54,167,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12506
Policy Entropy: 4.31578
Value Function Loss: 0.02735

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02884
Policy Update Magnitude: 0.48210
Value Function Update Magnitude: 0.31517

Collected Steps per Second: 13,458.61251
Overall Steps per Second: 6,548.28343

Timestep Collection Time: 3.71851
Timestep Consumption Time: 3.92410
PPO Batch Consumption Time: 0.50942
Total Iteration Time: 7.64261

Cumulative Model Updates: 6,498
Cumulative Timesteps: 54,217,868

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 54217868...
Checkpoint 54217868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06615
Policy Entropy: 4.31432
Value Function Loss: 0.02967

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03599
Policy Update Magnitude: 0.49608
Value Function Update Magnitude: 0.35920

Collected Steps per Second: 14,080.56607
Overall Steps per Second: 6,639.43286

Timestep Collection Time: 3.55099
Timestep Consumption Time: 3.97977
PPO Batch Consumption Time: 0.49823
Total Iteration Time: 7.53076

Cumulative Model Updates: 6,504
Cumulative Timesteps: 54,267,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02357
Policy Entropy: 4.31285
Value Function Loss: 0.04171

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03340
Policy Update Magnitude: 0.56000
Value Function Update Magnitude: 0.38134

Collected Steps per Second: 14,036.51891
Overall Steps per Second: 6,586.16939

Timestep Collection Time: 3.56370
Timestep Consumption Time: 4.03130
PPO Batch Consumption Time: 0.50289
Total Iteration Time: 7.59501

Cumulative Model Updates: 6,510
Cumulative Timesteps: 54,317,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 54317890...
Checkpoint 54317890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17074
Policy Entropy: 4.30643
Value Function Loss: 0.04521

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03605
Policy Update Magnitude: 0.62163
Value Function Update Magnitude: 0.43345

Collected Steps per Second: 14,455.59300
Overall Steps per Second: 6,732.53729

Timestep Collection Time: 3.45956
Timestep Consumption Time: 3.96855
PPO Batch Consumption Time: 0.48446
Total Iteration Time: 7.42811

Cumulative Model Updates: 6,516
Cumulative Timesteps: 54,367,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09933
Policy Entropy: 4.31377
Value Function Loss: 0.04038

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03095
Policy Update Magnitude: 0.62590
Value Function Update Magnitude: 0.42422

Collected Steps per Second: 13,980.49332
Overall Steps per Second: 6,565.49477

Timestep Collection Time: 3.57841
Timestep Consumption Time: 4.04142
PPO Batch Consumption Time: 0.50167
Total Iteration Time: 7.61984

Cumulative Model Updates: 6,522
Cumulative Timesteps: 54,417,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 54417928...
Checkpoint 54417928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07935
Policy Entropy: 4.31763
Value Function Loss: 0.03884

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03341
Policy Update Magnitude: 0.61106
Value Function Update Magnitude: 0.41929

Collected Steps per Second: 14,035.29519
Overall Steps per Second: 6,669.35664

Timestep Collection Time: 3.56515
Timestep Consumption Time: 3.93752
PPO Batch Consumption Time: 0.49885
Total Iteration Time: 7.50267

Cumulative Model Updates: 6,528
Cumulative Timesteps: 54,467,966

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02563
Policy Entropy: 4.32091
Value Function Loss: 0.03441

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03520
Policy Update Magnitude: 0.60402
Value Function Update Magnitude: 0.39772

Collected Steps per Second: 14,263.75567
Overall Steps per Second: 6,638.55911

Timestep Collection Time: 3.50861
Timestep Consumption Time: 4.03007
PPO Batch Consumption Time: 0.49390
Total Iteration Time: 7.53868

Cumulative Model Updates: 6,534
Cumulative Timesteps: 54,518,012

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 54518012...
Checkpoint 54518012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01762
Policy Entropy: 4.31659
Value Function Loss: 0.03436

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03735
Policy Update Magnitude: 0.56553
Value Function Update Magnitude: 0.39151

Collected Steps per Second: 13,983.97427
Overall Steps per Second: 6,582.24103

Timestep Collection Time: 3.57652
Timestep Consumption Time: 4.02180
PPO Batch Consumption Time: 0.50509
Total Iteration Time: 7.59832

Cumulative Model Updates: 6,540
Cumulative Timesteps: 54,568,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02402
Policy Entropy: 4.31373
Value Function Loss: 0.02938

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03110
Policy Update Magnitude: 0.53837
Value Function Update Magnitude: 0.38300

Collected Steps per Second: 14,229.89242
Overall Steps per Second: 6,748.03989

Timestep Collection Time: 3.51485
Timestep Consumption Time: 3.89708
PPO Batch Consumption Time: 0.49279
Total Iteration Time: 7.41193

Cumulative Model Updates: 6,546
Cumulative Timesteps: 54,618,042

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 54618042...
Checkpoint 54618042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11103
Policy Entropy: 4.31611
Value Function Loss: 0.02950

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03402
Policy Update Magnitude: 0.53180
Value Function Update Magnitude: 0.35768

Collected Steps per Second: 13,971.83203
Overall Steps per Second: 6,584.56428

Timestep Collection Time: 3.57906
Timestep Consumption Time: 4.01537
PPO Batch Consumption Time: 0.49646
Total Iteration Time: 7.59443

Cumulative Model Updates: 6,552
Cumulative Timesteps: 54,668,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16510
Policy Entropy: 4.31506
Value Function Loss: 0.03116

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02705
Policy Update Magnitude: 0.51501
Value Function Update Magnitude: 0.35318

Collected Steps per Second: 14,012.57215
Overall Steps per Second: 6,677.86953

Timestep Collection Time: 3.56937
Timestep Consumption Time: 3.92045
PPO Batch Consumption Time: 0.50131
Total Iteration Time: 7.48981

Cumulative Model Updates: 6,558
Cumulative Timesteps: 54,718,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 54718064...
Checkpoint 54718064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10995
Policy Entropy: 4.31615
Value Function Loss: 0.03336

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 0.52104
Value Function Update Magnitude: 0.37587

Collected Steps per Second: 14,042.68248
Overall Steps per Second: 6,511.59140

Timestep Collection Time: 3.56257
Timestep Consumption Time: 4.12035
PPO Batch Consumption Time: 0.51359
Total Iteration Time: 7.68291

Cumulative Model Updates: 6,564
Cumulative Timesteps: 54,768,092

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07923
Policy Entropy: 4.31116
Value Function Loss: 0.04275

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03829
Policy Update Magnitude: 0.56741
Value Function Update Magnitude: 0.41114

Collected Steps per Second: 14,371.50519
Overall Steps per Second: 6,658.22510

Timestep Collection Time: 3.47911
Timestep Consumption Time: 4.03040
PPO Batch Consumption Time: 0.50194
Total Iteration Time: 7.50951

Cumulative Model Updates: 6,570
Cumulative Timesteps: 54,818,092

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 54818092...
Checkpoint 54818092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04974
Policy Entropy: 4.31249
Value Function Loss: 0.04504

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04287
Policy Update Magnitude: 0.60048
Value Function Update Magnitude: 0.38677

Collected Steps per Second: 14,474.68046
Overall Steps per Second: 6,746.23724

Timestep Collection Time: 3.45624
Timestep Consumption Time: 3.95945
PPO Batch Consumption Time: 0.49759
Total Iteration Time: 7.41569

Cumulative Model Updates: 6,576
Cumulative Timesteps: 54,868,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00796
Policy Entropy: 4.31262
Value Function Loss: 0.04483

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03776
Policy Update Magnitude: 0.59082
Value Function Update Magnitude: 0.35217

Collected Steps per Second: 13,924.73553
Overall Steps per Second: 6,618.14437

Timestep Collection Time: 3.59088
Timestep Consumption Time: 3.96441
PPO Batch Consumption Time: 0.49577
Total Iteration Time: 7.55529

Cumulative Model Updates: 6,582
Cumulative Timesteps: 54,918,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 54918122...
Checkpoint 54918122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.20411
Policy Entropy: 4.31730
Value Function Loss: 0.03936

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03154
Policy Update Magnitude: 0.57463
Value Function Update Magnitude: 0.35282

Collected Steps per Second: 14,138.41744
Overall Steps per Second: 6,696.48986

Timestep Collection Time: 3.53816
Timestep Consumption Time: 3.93202
PPO Batch Consumption Time: 0.49728
Total Iteration Time: 7.47018

Cumulative Model Updates: 6,588
Cumulative Timesteps: 54,968,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12732
Policy Entropy: 4.31613
Value Function Loss: 0.03060

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.03819
Policy Update Magnitude: 0.55884
Value Function Update Magnitude: 0.35082

Collected Steps per Second: 14,183.18524
Overall Steps per Second: 6,666.28210

Timestep Collection Time: 3.52643
Timestep Consumption Time: 3.97640
PPO Batch Consumption Time: 0.49005
Total Iteration Time: 7.50283

Cumulative Model Updates: 6,594
Cumulative Timesteps: 55,018,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 55018162...
Checkpoint 55018162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.26083
Policy Entropy: 4.31345
Value Function Loss: 0.03221

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03518
Policy Update Magnitude: 0.54189
Value Function Update Magnitude: 0.34208

Collected Steps per Second: 14,192.48160
Overall Steps per Second: 6,617.48697

Timestep Collection Time: 3.52327
Timestep Consumption Time: 4.03307
PPO Batch Consumption Time: 0.50840
Total Iteration Time: 7.55634

Cumulative Model Updates: 6,600
Cumulative Timesteps: 55,068,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17588
Policy Entropy: 4.31347
Value Function Loss: 0.03564

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 0.55447
Value Function Update Magnitude: 0.36073

Collected Steps per Second: 14,477.82245
Overall Steps per Second: 6,738.43252

Timestep Collection Time: 3.45411
Timestep Consumption Time: 3.96720
PPO Batch Consumption Time: 0.48784
Total Iteration Time: 7.42131

Cumulative Model Updates: 6,606
Cumulative Timesteps: 55,118,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 55118174...
Checkpoint 55118174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05276
Policy Entropy: 4.31925
Value Function Loss: 0.03384

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04161
Policy Update Magnitude: 0.54884
Value Function Update Magnitude: 0.37936

Collected Steps per Second: 13,772.93574
Overall Steps per Second: 6,479.44817

Timestep Collection Time: 3.63045
Timestep Consumption Time: 4.08656
PPO Batch Consumption Time: 0.50476
Total Iteration Time: 7.71702

Cumulative Model Updates: 6,612
Cumulative Timesteps: 55,168,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.28167
Policy Entropy: 4.32609
Value Function Loss: 0.03076

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03368
Policy Update Magnitude: 0.53734
Value Function Update Magnitude: 0.39787

Collected Steps per Second: 14,033.25022
Overall Steps per Second: 6,716.77672

Timestep Collection Time: 3.56396
Timestep Consumption Time: 3.88217
PPO Batch Consumption Time: 0.48785
Total Iteration Time: 7.44613

Cumulative Model Updates: 6,618
Cumulative Timesteps: 55,218,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 55218190...
Checkpoint 55218190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08256
Policy Entropy: 4.31863
Value Function Loss: 0.02629

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 0.52677
Value Function Update Magnitude: 0.39819

Collected Steps per Second: 14,090.25695
Overall Steps per Second: 6,622.37867

Timestep Collection Time: 3.55082
Timestep Consumption Time: 4.00417
PPO Batch Consumption Time: 0.49970
Total Iteration Time: 7.55499

Cumulative Model Updates: 6,624
Cumulative Timesteps: 55,268,222

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07644
Policy Entropy: 4.31753
Value Function Loss: 0.03103

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02822
Policy Update Magnitude: 0.53788
Value Function Update Magnitude: 0.36549

Collected Steps per Second: 13,979.22878
Overall Steps per Second: 6,616.63209

Timestep Collection Time: 3.58060
Timestep Consumption Time: 3.98428
PPO Batch Consumption Time: 0.49717
Total Iteration Time: 7.56488

Cumulative Model Updates: 6,630
Cumulative Timesteps: 55,318,276

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 55318276...
Checkpoint 55318276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08867
Policy Entropy: 4.31408
Value Function Loss: 0.03785

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02927
Policy Update Magnitude: 0.54829
Value Function Update Magnitude: 0.36788

Collected Steps per Second: 14,144.28717
Overall Steps per Second: 6,545.61725

Timestep Collection Time: 3.53528
Timestep Consumption Time: 4.10403
PPO Batch Consumption Time: 0.50778
Total Iteration Time: 7.63931

Cumulative Model Updates: 6,636
Cumulative Timesteps: 55,368,280

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02589
Policy Entropy: 4.31083
Value Function Loss: 0.04264

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.57801
Value Function Update Magnitude: 0.41105

Collected Steps per Second: 14,117.30947
Overall Steps per Second: 6,579.35700

Timestep Collection Time: 3.54345
Timestep Consumption Time: 4.05972
PPO Batch Consumption Time: 0.50551
Total Iteration Time: 7.60317

Cumulative Model Updates: 6,642
Cumulative Timesteps: 55,418,304

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 55418304...
Checkpoint 55418304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18239
Policy Entropy: 4.30506
Value Function Loss: 0.04209

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03035
Policy Update Magnitude: 0.60025
Value Function Update Magnitude: 0.48148

Collected Steps per Second: 14,042.71355
Overall Steps per Second: 6,661.19907

Timestep Collection Time: 3.56057
Timestep Consumption Time: 3.94559
PPO Batch Consumption Time: 0.49919
Total Iteration Time: 7.50616

Cumulative Model Updates: 6,648
Cumulative Timesteps: 55,468,304

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02324
Policy Entropy: 4.31033
Value Function Loss: 0.04007

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02514
Policy Update Magnitude: 0.57854
Value Function Update Magnitude: 0.48402

Collected Steps per Second: 14,016.06558
Overall Steps per Second: 6,622.84330

Timestep Collection Time: 3.56748
Timestep Consumption Time: 3.98245
PPO Batch Consumption Time: 0.49059
Total Iteration Time: 7.54993

Cumulative Model Updates: 6,654
Cumulative Timesteps: 55,518,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 55518306...
Checkpoint 55518306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09615
Policy Entropy: 4.31151
Value Function Loss: 0.03761

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02889
Policy Update Magnitude: 0.57942
Value Function Update Magnitude: 0.46228

Collected Steps per Second: 13,936.14311
Overall Steps per Second: 6,780.50151

Timestep Collection Time: 3.58980
Timestep Consumption Time: 3.78841
PPO Batch Consumption Time: 0.47082
Total Iteration Time: 7.37822

Cumulative Model Updates: 6,660
Cumulative Timesteps: 55,568,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03689
Policy Entropy: 4.31886
Value Function Loss: 0.03274

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.03565
Policy Update Magnitude: 0.58423
Value Function Update Magnitude: 0.43687

Collected Steps per Second: 14,486.35468
Overall Steps per Second: 6,788.91959

Timestep Collection Time: 3.45415
Timestep Consumption Time: 3.91639
PPO Batch Consumption Time: 0.47978
Total Iteration Time: 7.37054

Cumulative Model Updates: 6,666
Cumulative Timesteps: 55,618,372

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 55618372...
Checkpoint 55618372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01385
Policy Entropy: 4.31155
Value Function Loss: 0.04004

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03591
Policy Update Magnitude: 0.59303
Value Function Update Magnitude: 0.40782

Collected Steps per Second: 14,292.17035
Overall Steps per Second: 6,680.91953

Timestep Collection Time: 3.49926
Timestep Consumption Time: 3.98654
PPO Batch Consumption Time: 0.50154
Total Iteration Time: 7.48580

Cumulative Model Updates: 6,672
Cumulative Timesteps: 55,668,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17715
Policy Entropy: 4.31290
Value Function Loss: 0.04343

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03642
Policy Update Magnitude: 0.60603
Value Function Update Magnitude: 0.40502

Collected Steps per Second: 14,320.22875
Overall Steps per Second: 6,769.92867

Timestep Collection Time: 3.49282
Timestep Consumption Time: 3.89544
PPO Batch Consumption Time: 0.48940
Total Iteration Time: 7.38826

Cumulative Model Updates: 6,678
Cumulative Timesteps: 55,718,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 55718402...
Checkpoint 55718402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03400
Policy Entropy: 4.31213
Value Function Loss: 0.04589

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03856
Policy Update Magnitude: 0.61938
Value Function Update Magnitude: 0.42007

Collected Steps per Second: 14,245.86081
Overall Steps per Second: 6,776.06315

Timestep Collection Time: 3.51007
Timestep Consumption Time: 3.86943
PPO Batch Consumption Time: 0.47446
Total Iteration Time: 7.37951

Cumulative Model Updates: 6,684
Cumulative Timesteps: 55,768,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09806
Policy Entropy: 4.31460
Value Function Loss: 0.04898

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03739
Policy Update Magnitude: 0.65685
Value Function Update Magnitude: 0.43450

Collected Steps per Second: 14,309.14837
Overall Steps per Second: 6,827.70957

Timestep Collection Time: 3.49595
Timestep Consumption Time: 3.83067
PPO Batch Consumption Time: 0.46955
Total Iteration Time: 7.32662

Cumulative Model Updates: 6,690
Cumulative Timesteps: 55,818,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 55818430...
Checkpoint 55818430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01366
Policy Entropy: 4.30992
Value Function Loss: 0.04761

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03826
Policy Update Magnitude: 0.66040
Value Function Update Magnitude: 0.45468

Collected Steps per Second: 14,565.19110
Overall Steps per Second: 6,773.28794

Timestep Collection Time: 3.43367
Timestep Consumption Time: 3.95004
PPO Batch Consumption Time: 0.49407
Total Iteration Time: 7.38371

Cumulative Model Updates: 6,696
Cumulative Timesteps: 55,868,442

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03385
Policy Entropy: 4.30627
Value Function Loss: 0.04897

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03767
Policy Update Magnitude: 0.65374
Value Function Update Magnitude: 0.45719

Collected Steps per Second: 13,955.01468
Overall Steps per Second: 6,573.23801

Timestep Collection Time: 3.58366
Timestep Consumption Time: 4.02446
PPO Batch Consumption Time: 0.49837
Total Iteration Time: 7.60812

Cumulative Model Updates: 6,702
Cumulative Timesteps: 55,918,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 55918452...
Checkpoint 55918452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04526
Policy Entropy: 4.30484
Value Function Loss: 0.05284

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03378
Policy Update Magnitude: 0.65789
Value Function Update Magnitude: 0.43205

Collected Steps per Second: 14,021.67625
Overall Steps per Second: 6,700.74467

Timestep Collection Time: 3.56605
Timestep Consumption Time: 3.89611
PPO Batch Consumption Time: 0.49565
Total Iteration Time: 7.46216

Cumulative Model Updates: 6,708
Cumulative Timesteps: 55,968,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16147
Policy Entropy: 4.30155
Value Function Loss: 0.05988

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03292
Policy Update Magnitude: 0.68409
Value Function Update Magnitude: 0.43367

Collected Steps per Second: 13,982.98148
Overall Steps per Second: 6,629.06046

Timestep Collection Time: 3.57663
Timestep Consumption Time: 3.96772
PPO Batch Consumption Time: 0.49485
Total Iteration Time: 7.54436

Cumulative Model Updates: 6,714
Cumulative Timesteps: 56,018,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 56018466...
Checkpoint 56018466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14674
Policy Entropy: 4.29957
Value Function Loss: 0.06032

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03769
Policy Update Magnitude: 0.70616
Value Function Update Magnitude: 0.45645

Collected Steps per Second: 14,090.68160
Overall Steps per Second: 6,742.17166

Timestep Collection Time: 3.55001
Timestep Consumption Time: 3.86927
PPO Batch Consumption Time: 0.49278
Total Iteration Time: 7.41927

Cumulative Model Updates: 6,720
Cumulative Timesteps: 56,068,488

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00411
Policy Entropy: 4.30438
Value Function Loss: 0.04751

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03101
Policy Update Magnitude: 0.66906
Value Function Update Magnitude: 0.46027

Collected Steps per Second: 14,011.26912
Overall Steps per Second: 6,540.27110

Timestep Collection Time: 3.57055
Timestep Consumption Time: 4.07867
PPO Batch Consumption Time: 0.50608
Total Iteration Time: 7.64922

Cumulative Model Updates: 6,726
Cumulative Timesteps: 56,118,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 56118516...
Checkpoint 56118516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.20023
Policy Entropy: 4.30406
Value Function Loss: 0.04422

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 0.64860
Value Function Update Magnitude: 0.45655

Collected Steps per Second: 13,807.60587
Overall Steps per Second: 6,661.62569

Timestep Collection Time: 3.62337
Timestep Consumption Time: 3.88681
PPO Batch Consumption Time: 0.48465
Total Iteration Time: 7.51018

Cumulative Model Updates: 6,732
Cumulative Timesteps: 56,168,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06239
Policy Entropy: 4.29735
Value Function Loss: 0.04177

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03525
Policy Update Magnitude: 0.65555
Value Function Update Magnitude: 0.43846

Collected Steps per Second: 14,456.02989
Overall Steps per Second: 6,715.38520

Timestep Collection Time: 3.46070
Timestep Consumption Time: 3.98906
PPO Batch Consumption Time: 0.49623
Total Iteration Time: 7.44976

Cumulative Model Updates: 6,738
Cumulative Timesteps: 56,218,574

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 56218574...
Checkpoint 56218574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04353
Policy Entropy: 4.29365
Value Function Loss: 0.04995

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04146
Policy Update Magnitude: 0.64881
Value Function Update Magnitude: 0.43004

Collected Steps per Second: 13,919.79013
Overall Steps per Second: 6,616.96901

Timestep Collection Time: 3.59258
Timestep Consumption Time: 3.96496
PPO Batch Consumption Time: 0.48780
Total Iteration Time: 7.55754

Cumulative Model Updates: 6,744
Cumulative Timesteps: 56,268,582

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07170
Policy Entropy: 4.28719
Value Function Loss: 0.04791

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.04157
Policy Update Magnitude: 0.65620
Value Function Update Magnitude: 0.46137

Collected Steps per Second: 14,000.18503
Overall Steps per Second: 6,704.65210

Timestep Collection Time: 3.57352
Timestep Consumption Time: 3.88846
PPO Batch Consumption Time: 0.49641
Total Iteration Time: 7.46198

Cumulative Model Updates: 6,750
Cumulative Timesteps: 56,318,612

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 56318612...
Checkpoint 56318612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13959
Policy Entropy: 4.28465
Value Function Loss: 0.05353

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04267
Policy Update Magnitude: 0.67527
Value Function Update Magnitude: 0.44373

Collected Steps per Second: 13,921.01565
Overall Steps per Second: 6,605.06274

Timestep Collection Time: 3.59241
Timestep Consumption Time: 3.97905
PPO Batch Consumption Time: 0.49097
Total Iteration Time: 7.57146

Cumulative Model Updates: 6,756
Cumulative Timesteps: 56,368,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14090
Policy Entropy: 4.28661
Value Function Loss: 0.05817

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04176
Policy Update Magnitude: 0.68127
Value Function Update Magnitude: 0.44095

Collected Steps per Second: 14,229.28391
Overall Steps per Second: 6,671.93273

Timestep Collection Time: 3.51599
Timestep Consumption Time: 3.98259
PPO Batch Consumption Time: 0.50805
Total Iteration Time: 7.49858

Cumulative Model Updates: 6,762
Cumulative Timesteps: 56,418,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 56418652...
Checkpoint 56418652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11902
Policy Entropy: 4.28603
Value Function Loss: 0.06213

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04222
Policy Update Magnitude: 0.68870
Value Function Update Magnitude: 0.43875

Collected Steps per Second: 14,082.76087
Overall Steps per Second: 6,595.11980

Timestep Collection Time: 3.55143
Timestep Consumption Time: 4.03205
PPO Batch Consumption Time: 0.50188
Total Iteration Time: 7.58349

Cumulative Model Updates: 6,768
Cumulative Timesteps: 56,468,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12324
Policy Entropy: 4.28380
Value Function Loss: 0.05574

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03770
Policy Update Magnitude: 0.69637
Value Function Update Magnitude: 0.43903

Collected Steps per Second: 14,287.49970
Overall Steps per Second: 6,582.90649

Timestep Collection Time: 3.50138
Timestep Consumption Time: 4.09800
PPO Batch Consumption Time: 0.50850
Total Iteration Time: 7.59938

Cumulative Model Updates: 6,774
Cumulative Timesteps: 56,518,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 56518692...
Checkpoint 56518692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14399
Policy Entropy: 4.27978
Value Function Loss: 0.05558

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03606
Policy Update Magnitude: 0.68528
Value Function Update Magnitude: 0.41723

Collected Steps per Second: 14,234.55871
Overall Steps per Second: 6,652.21356

Timestep Collection Time: 3.51455
Timestep Consumption Time: 4.00596
PPO Batch Consumption Time: 0.49244
Total Iteration Time: 7.52050

Cumulative Model Updates: 6,780
Cumulative Timesteps: 56,568,720

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11448
Policy Entropy: 4.28352
Value Function Loss: 0.04760

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03841
Policy Update Magnitude: 0.65549
Value Function Update Magnitude: 0.42932

Collected Steps per Second: 14,089.32351
Overall Steps per Second: 6,529.26441

Timestep Collection Time: 3.55120
Timestep Consumption Time: 4.11184
PPO Batch Consumption Time: 0.50936
Total Iteration Time: 7.66304

Cumulative Model Updates: 6,786
Cumulative Timesteps: 56,618,754

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 56618754...
Checkpoint 56618754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17978
Policy Entropy: 4.28235
Value Function Loss: 0.04850

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03137
Policy Update Magnitude: 0.64884
Value Function Update Magnitude: 0.40450

Collected Steps per Second: 14,176.36943
Overall Steps per Second: 6,702.37820

Timestep Collection Time: 3.52855
Timestep Consumption Time: 3.93477
PPO Batch Consumption Time: 0.50000
Total Iteration Time: 7.46332

Cumulative Model Updates: 6,792
Cumulative Timesteps: 56,668,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04181
Policy Entropy: 4.28209
Value Function Loss: 0.04184

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03461
Policy Update Magnitude: 0.63514
Value Function Update Magnitude: 0.37672

Collected Steps per Second: 14,016.18338
Overall Steps per Second: 6,578.49859

Timestep Collection Time: 3.56959
Timestep Consumption Time: 4.03579
PPO Batch Consumption Time: 0.50751
Total Iteration Time: 7.60538

Cumulative Model Updates: 6,798
Cumulative Timesteps: 56,718,808

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 56718808...
Checkpoint 56718808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15027
Policy Entropy: 4.28121
Value Function Loss: 0.04172

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03579
Policy Update Magnitude: 0.61200
Value Function Update Magnitude: 0.34664

Collected Steps per Second: 14,049.04123
Overall Steps per Second: 6,578.42081

Timestep Collection Time: 3.55939
Timestep Consumption Time: 4.04213
PPO Batch Consumption Time: 0.50532
Total Iteration Time: 7.60152

Cumulative Model Updates: 6,804
Cumulative Timesteps: 56,768,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09929
Policy Entropy: 4.28246
Value Function Loss: 0.03767

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03030
Policy Update Magnitude: 0.60056
Value Function Update Magnitude: 0.34544

Collected Steps per Second: 14,657.46526
Overall Steps per Second: 6,734.68051

Timestep Collection Time: 3.41287
Timestep Consumption Time: 4.01495
PPO Batch Consumption Time: 0.49856
Total Iteration Time: 7.42782

Cumulative Model Updates: 6,810
Cumulative Timesteps: 56,818,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 56818838...
Checkpoint 56818838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15507
Policy Entropy: 4.27903
Value Function Loss: 0.05012

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02830
Policy Update Magnitude: 0.62809
Value Function Update Magnitude: 0.37849

Collected Steps per Second: 14,221.31508
Overall Steps per Second: 6,662.77654

Timestep Collection Time: 3.51894
Timestep Consumption Time: 3.99204
PPO Batch Consumption Time: 0.49604
Total Iteration Time: 7.51098

Cumulative Model Updates: 6,816
Cumulative Timesteps: 56,868,882

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00646
Policy Entropy: 4.27578
Value Function Loss: 0.05217

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03727
Policy Update Magnitude: 0.65210
Value Function Update Magnitude: 0.40780

Collected Steps per Second: 14,478.63471
Overall Steps per Second: 6,813.05009

Timestep Collection Time: 3.45502
Timestep Consumption Time: 3.88736
PPO Batch Consumption Time: 0.49066
Total Iteration Time: 7.34238

Cumulative Model Updates: 6,822
Cumulative Timesteps: 56,918,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 56918906...
Checkpoint 56918906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07390
Policy Entropy: 4.27355
Value Function Loss: 0.05383

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04088
Policy Update Magnitude: 0.66196
Value Function Update Magnitude: 0.40866

Collected Steps per Second: 14,122.48263
Overall Steps per Second: 6,555.00552

Timestep Collection Time: 3.54130
Timestep Consumption Time: 4.08829
PPO Batch Consumption Time: 0.51249
Total Iteration Time: 7.62959

Cumulative Model Updates: 6,828
Cumulative Timesteps: 56,968,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06964
Policy Entropy: 4.27185
Value Function Loss: 0.05299

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03965
Policy Update Magnitude: 0.67323
Value Function Update Magnitude: 0.39041

Collected Steps per Second: 14,123.71872
Overall Steps per Second: 6,684.62329

Timestep Collection Time: 3.54170
Timestep Consumption Time: 3.94144
PPO Batch Consumption Time: 0.48801
Total Iteration Time: 7.48314

Cumulative Model Updates: 6,834
Cumulative Timesteps: 57,018,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 57018940...
Checkpoint 57018940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00912
Policy Entropy: 4.27490
Value Function Loss: 0.04820

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.03783
Policy Update Magnitude: 0.66556
Value Function Update Magnitude: 0.40052

Collected Steps per Second: 14,437.93829
Overall Steps per Second: 6,698.29888

Timestep Collection Time: 3.46407
Timestep Consumption Time: 4.00260
PPO Batch Consumption Time: 0.49742
Total Iteration Time: 7.46667

Cumulative Model Updates: 6,840
Cumulative Timesteps: 57,068,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16161
Policy Entropy: 4.27637
Value Function Loss: 0.04986

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03275
Policy Update Magnitude: 0.65243
Value Function Update Magnitude: 0.37225

Collected Steps per Second: 14,115.92287
Overall Steps per Second: 6,692.57859

Timestep Collection Time: 3.54267
Timestep Consumption Time: 3.92949
PPO Batch Consumption Time: 0.49362
Total Iteration Time: 7.47216

Cumulative Model Updates: 6,846
Cumulative Timesteps: 57,118,962

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 57118962...
Checkpoint 57118962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17688
Policy Entropy: 4.28283
Value Function Loss: 0.04039

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03582
Policy Update Magnitude: 0.63200
Value Function Update Magnitude: 0.38868

Collected Steps per Second: 14,039.35454
Overall Steps per Second: 6,701.34203

Timestep Collection Time: 3.56270
Timestep Consumption Time: 3.90118
PPO Batch Consumption Time: 0.49970
Total Iteration Time: 7.46388

Cumulative Model Updates: 6,852
Cumulative Timesteps: 57,168,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00568
Policy Entropy: 4.29083
Value Function Loss: 0.03257

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03546
Policy Update Magnitude: 0.58769
Value Function Update Magnitude: 0.38478

Collected Steps per Second: 14,073.95294
Overall Steps per Second: 6,624.10573

Timestep Collection Time: 3.55579
Timestep Consumption Time: 3.99904
PPO Batch Consumption Time: 0.49606
Total Iteration Time: 7.55483

Cumulative Model Updates: 6,858
Cumulative Timesteps: 57,219,024

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 57219024...
Checkpoint 57219024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10697
Policy Entropy: 4.28873
Value Function Loss: 0.03131

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03858
Policy Update Magnitude: 0.54803
Value Function Update Magnitude: 0.38098

Collected Steps per Second: 14,185.91513
Overall Steps per Second: 6,617.21542

Timestep Collection Time: 3.52561
Timestep Consumption Time: 4.03255
PPO Batch Consumption Time: 0.50511
Total Iteration Time: 7.55816

Cumulative Model Updates: 6,864
Cumulative Timesteps: 57,269,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06646
Policy Entropy: 4.29366
Value Function Loss: 0.03259

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03607
Policy Update Magnitude: 0.55031
Value Function Update Magnitude: 0.39433

Collected Steps per Second: 14,428.60425
Overall Steps per Second: 6,666.66098

Timestep Collection Time: 3.46686
Timestep Consumption Time: 4.03644
PPO Batch Consumption Time: 0.50564
Total Iteration Time: 7.50331

Cumulative Model Updates: 6,870
Cumulative Timesteps: 57,319,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 57319060...
Checkpoint 57319060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00717
Policy Entropy: 4.29307
Value Function Loss: 0.03447

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03508
Policy Update Magnitude: 0.58558
Value Function Update Magnitude: 0.38092

Collected Steps per Second: 13,933.25540
Overall Steps per Second: 6,632.02726

Timestep Collection Time: 3.58882
Timestep Consumption Time: 3.95095
PPO Batch Consumption Time: 0.49210
Total Iteration Time: 7.53978

Cumulative Model Updates: 6,876
Cumulative Timesteps: 57,369,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10417
Policy Entropy: 4.29158
Value Function Loss: 0.03593

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02970
Policy Update Magnitude: 0.59140
Value Function Update Magnitude: 0.35849

Collected Steps per Second: 14,261.23183
Overall Steps per Second: 6,789.98492

Timestep Collection Time: 3.50601
Timestep Consumption Time: 3.85778
PPO Batch Consumption Time: 0.48745
Total Iteration Time: 7.36379

Cumulative Model Updates: 6,882
Cumulative Timesteps: 57,419,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 57419064...
Checkpoint 57419064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17076
Policy Entropy: 4.29422
Value Function Loss: 0.03322

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03081
Policy Update Magnitude: 0.57279
Value Function Update Magnitude: 0.36708

Collected Steps per Second: 14,288.77633
Overall Steps per Second: 6,680.46598

Timestep Collection Time: 3.50093
Timestep Consumption Time: 3.98717
PPO Batch Consumption Time: 0.49788
Total Iteration Time: 7.48810

Cumulative Model Updates: 6,888
Cumulative Timesteps: 57,469,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08233
Policy Entropy: 4.29817
Value Function Loss: 0.03405

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03745
Policy Update Magnitude: 0.55011
Value Function Update Magnitude: 0.35540

Collected Steps per Second: 14,223.01652
Overall Steps per Second: 6,621.85355

Timestep Collection Time: 3.51571
Timestep Consumption Time: 4.03565
PPO Batch Consumption Time: 0.49730
Total Iteration Time: 7.55136

Cumulative Model Updates: 6,894
Cumulative Timesteps: 57,519,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 57519092...
Checkpoint 57519092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14297
Policy Entropy: 4.29734
Value Function Loss: 0.02943

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03076
Policy Update Magnitude: 0.53056
Value Function Update Magnitude: 0.33778

Collected Steps per Second: 14,411.01683
Overall Steps per Second: 6,709.69087

Timestep Collection Time: 3.47040
Timestep Consumption Time: 3.98330
PPO Batch Consumption Time: 0.49639
Total Iteration Time: 7.45370

Cumulative Model Updates: 6,900
Cumulative Timesteps: 57,569,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09246
Policy Entropy: 4.30020
Value Function Loss: 0.03184

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03363
Policy Update Magnitude: 0.51334
Value Function Update Magnitude: 0.33154

Collected Steps per Second: 13,970.01688
Overall Steps per Second: 6,540.82210

Timestep Collection Time: 3.58282
Timestep Consumption Time: 4.06943
PPO Batch Consumption Time: 0.51087
Total Iteration Time: 7.65225

Cumulative Model Updates: 6,906
Cumulative Timesteps: 57,619,156

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 57619156...
Checkpoint 57619156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01178
Policy Entropy: 4.29477
Value Function Loss: 0.03942

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03304
Policy Update Magnitude: 0.54147
Value Function Update Magnitude: 0.37195

Collected Steps per Second: 13,657.73867
Overall Steps per Second: 6,602.13078

Timestep Collection Time: 3.66151
Timestep Consumption Time: 3.91301
PPO Batch Consumption Time: 0.49815
Total Iteration Time: 7.57452

Cumulative Model Updates: 6,912
Cumulative Timesteps: 57,669,164

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03036
Policy Entropy: 4.29253
Value Function Loss: 0.04656

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.03948
Policy Update Magnitude: 0.60556
Value Function Update Magnitude: 0.40088

Collected Steps per Second: 14,020.67301
Overall Steps per Second: 6,622.29452

Timestep Collection Time: 3.56702
Timestep Consumption Time: 3.98505
PPO Batch Consumption Time: 0.49592
Total Iteration Time: 7.55207

Cumulative Model Updates: 6,918
Cumulative Timesteps: 57,719,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 57719176...
Checkpoint 57719176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10451
Policy Entropy: 4.29289
Value Function Loss: 0.04710

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03432
Policy Update Magnitude: 0.63640
Value Function Update Magnitude: 0.39948

Collected Steps per Second: 14,063.04229
Overall Steps per Second: 6,599.31087

Timestep Collection Time: 3.55755
Timestep Consumption Time: 4.02354
PPO Batch Consumption Time: 0.49702
Total Iteration Time: 7.58109

Cumulative Model Updates: 6,924
Cumulative Timesteps: 57,769,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12050
Policy Entropy: 4.29514
Value Function Loss: 0.05189

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03132
Policy Update Magnitude: 0.63402
Value Function Update Magnitude: 0.39574

Collected Steps per Second: 14,408.81839
Overall Steps per Second: 6,728.02299

Timestep Collection Time: 3.47093
Timestep Consumption Time: 3.96246
PPO Batch Consumption Time: 0.49466
Total Iteration Time: 7.43339

Cumulative Model Updates: 6,930
Cumulative Timesteps: 57,819,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 57819218...
Checkpoint 57819218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06824
Policy Entropy: 4.29600
Value Function Loss: 0.04617

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03392
Policy Update Magnitude: 0.64217
Value Function Update Magnitude: 0.38857

Collected Steps per Second: 14,026.81631
Overall Steps per Second: 6,606.68944

Timestep Collection Time: 3.56688
Timestep Consumption Time: 4.00605
PPO Batch Consumption Time: 0.48849
Total Iteration Time: 7.57293

Cumulative Model Updates: 6,936
Cumulative Timesteps: 57,869,250

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00021
Policy Entropy: 4.30081
Value Function Loss: 0.04653

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02953
Policy Update Magnitude: 0.63064
Value Function Update Magnitude: 0.42931

Collected Steps per Second: 14,280.36917
Overall Steps per Second: 6,784.67270

Timestep Collection Time: 3.50173
Timestep Consumption Time: 3.86871
PPO Batch Consumption Time: 0.48634
Total Iteration Time: 7.37044

Cumulative Model Updates: 6,942
Cumulative Timesteps: 57,919,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 57919256...
Checkpoint 57919256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07971
Policy Entropy: 4.30394
Value Function Loss: 0.04070

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03054
Policy Update Magnitude: 0.62675
Value Function Update Magnitude: 0.43350

Collected Steps per Second: 14,058.23722
Overall Steps per Second: 6,675.86053

Timestep Collection Time: 3.55820
Timestep Consumption Time: 3.93477
PPO Batch Consumption Time: 0.49470
Total Iteration Time: 7.49297

Cumulative Model Updates: 6,948
Cumulative Timesteps: 57,969,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.28702
Policy Entropy: 4.30008
Value Function Loss: 0.04920

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03611
Policy Update Magnitude: 0.62431
Value Function Update Magnitude: 0.41600

Collected Steps per Second: 14,193.44715
Overall Steps per Second: 6,675.12512

Timestep Collection Time: 3.52275
Timestep Consumption Time: 3.96774
PPO Batch Consumption Time: 0.50476
Total Iteration Time: 7.49050

Cumulative Model Updates: 6,954
Cumulative Timesteps: 58,019,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 58019278...
Checkpoint 58019278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13836
Policy Entropy: 4.29710
Value Function Loss: 0.04219

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03468
Policy Update Magnitude: 0.61957
Value Function Update Magnitude: 0.40723

Collected Steps per Second: 14,227.00557
Overall Steps per Second: 6,617.73805

Timestep Collection Time: 3.51627
Timestep Consumption Time: 4.04311
PPO Batch Consumption Time: 0.50519
Total Iteration Time: 7.55938

Cumulative Model Updates: 6,960
Cumulative Timesteps: 58,069,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04206
Policy Entropy: 4.29622
Value Function Loss: 0.03780

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03417
Policy Update Magnitude: 0.58417
Value Function Update Magnitude: 0.36772

Collected Steps per Second: 14,172.10227
Overall Steps per Second: 6,704.59623

Timestep Collection Time: 3.53130
Timestep Consumption Time: 3.93313
PPO Batch Consumption Time: 0.48679
Total Iteration Time: 7.46443

Cumulative Model Updates: 6,966
Cumulative Timesteps: 58,119,350

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 58119350...
Checkpoint 58119350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12545
Policy Entropy: 4.30549
Value Function Loss: 0.02937

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03094
Policy Update Magnitude: 0.56279
Value Function Update Magnitude: 0.37340

Collected Steps per Second: 14,425.92468
Overall Steps per Second: 6,728.12379

Timestep Collection Time: 3.46765
Timestep Consumption Time: 3.96741
PPO Batch Consumption Time: 0.48948
Total Iteration Time: 7.43506

Cumulative Model Updates: 6,972
Cumulative Timesteps: 58,169,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16146
Policy Entropy: 4.30002
Value Function Loss: 0.03203

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02831
Policy Update Magnitude: 0.55815
Value Function Update Magnitude: 0.42354

Collected Steps per Second: 13,903.78164
Overall Steps per Second: 6,586.83544

Timestep Collection Time: 3.59729
Timestep Consumption Time: 3.99603
PPO Batch Consumption Time: 0.49031
Total Iteration Time: 7.59333

Cumulative Model Updates: 6,978
Cumulative Timesteps: 58,219,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 58219390...
Checkpoint 58219390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12397
Policy Entropy: 4.30290
Value Function Loss: 0.03113

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02488
Policy Update Magnitude: 0.55815
Value Function Update Magnitude: 0.39305

Collected Steps per Second: 14,219.81797
Overall Steps per Second: 6,663.15135

Timestep Collection Time: 3.51763
Timestep Consumption Time: 3.98933
PPO Batch Consumption Time: 0.50215
Total Iteration Time: 7.50696

Cumulative Model Updates: 6,984
Cumulative Timesteps: 58,269,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.24721
Policy Entropy: 4.30473
Value Function Loss: 0.03177

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02887
Policy Update Magnitude: 0.55867
Value Function Update Magnitude: 0.38789

Collected Steps per Second: 14,090.13595
Overall Steps per Second: 6,666.52071

Timestep Collection Time: 3.54858
Timestep Consumption Time: 3.95158
PPO Batch Consumption Time: 0.48642
Total Iteration Time: 7.50016

Cumulative Model Updates: 6,990
Cumulative Timesteps: 58,319,410

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 58319410...
Checkpoint 58319410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01058
Policy Entropy: 4.29887
Value Function Loss: 0.03936

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.58734
Value Function Update Magnitude: 0.40136

Collected Steps per Second: 14,131.76466
Overall Steps per Second: 6,729.65581

Timestep Collection Time: 3.53954
Timestep Consumption Time: 3.89323
PPO Batch Consumption Time: 0.49073
Total Iteration Time: 7.43277

Cumulative Model Updates: 6,996
Cumulative Timesteps: 58,369,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17203
Policy Entropy: 4.29499
Value Function Loss: 0.03429

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03417
Policy Update Magnitude: 0.58062
Value Function Update Magnitude: 0.42656

Collected Steps per Second: 14,265.30147
Overall Steps per Second: 6,598.06543

Timestep Collection Time: 3.50641
Timestep Consumption Time: 4.07460
PPO Batch Consumption Time: 0.50744
Total Iteration Time: 7.58101

Cumulative Model Updates: 7,002
Cumulative Timesteps: 58,419,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 58419450...
Checkpoint 58419450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04845
Policy Entropy: 4.29492
Value Function Loss: 0.03783

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02717
Policy Update Magnitude: 0.57167
Value Function Update Magnitude: 0.41874

Collected Steps per Second: 14,169.25256
Overall Steps per Second: 6,673.98443

Timestep Collection Time: 3.52947
Timestep Consumption Time: 3.96380
PPO Batch Consumption Time: 0.49886
Total Iteration Time: 7.49327

Cumulative Model Updates: 7,008
Cumulative Timesteps: 58,469,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10467
Policy Entropy: 4.29750
Value Function Loss: 0.03143

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02670
Policy Update Magnitude: 0.57096
Value Function Update Magnitude: 0.46430

Collected Steps per Second: 14,411.92631
Overall Steps per Second: 6,658.59895

Timestep Collection Time: 3.46963
Timestep Consumption Time: 4.04006
PPO Batch Consumption Time: 0.50733
Total Iteration Time: 7.50969

Cumulative Model Updates: 7,014
Cumulative Timesteps: 58,519,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 58519464...
Checkpoint 58519464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00294
Policy Entropy: 4.29824
Value Function Loss: 0.03117

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.55160
Value Function Update Magnitude: 0.43972

Collected Steps per Second: 13,863.63847
Overall Steps per Second: 6,543.02647

Timestep Collection Time: 3.60858
Timestep Consumption Time: 4.03743
PPO Batch Consumption Time: 0.49696
Total Iteration Time: 7.64600

Cumulative Model Updates: 7,020
Cumulative Timesteps: 58,569,492

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14503
Policy Entropy: 4.30279
Value Function Loss: 0.02792

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02292
Policy Update Magnitude: 0.53816
Value Function Update Magnitude: 0.40800

Collected Steps per Second: 14,210.91763
Overall Steps per Second: 6,754.13255

Timestep Collection Time: 3.51983
Timestep Consumption Time: 3.88601
PPO Batch Consumption Time: 0.49413
Total Iteration Time: 7.40584

Cumulative Model Updates: 7,026
Cumulative Timesteps: 58,619,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 58619512...
Checkpoint 58619512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08263
Policy Entropy: 4.30241
Value Function Loss: 0.03017

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02614
Policy Update Magnitude: 0.51493
Value Function Update Magnitude: 0.41294

Collected Steps per Second: 13,880.17445
Overall Steps per Second: 6,599.68636

Timestep Collection Time: 3.60226
Timestep Consumption Time: 3.97386
PPO Batch Consumption Time: 0.48817
Total Iteration Time: 7.57612

Cumulative Model Updates: 7,032
Cumulative Timesteps: 58,669,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05214
Policy Entropy: 4.30298
Value Function Loss: 0.03638

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02170
Policy Update Magnitude: 0.54845
Value Function Update Magnitude: 0.45317

Collected Steps per Second: 14,360.23192
Overall Steps per Second: 6,683.28206

Timestep Collection Time: 3.48351
Timestep Consumption Time: 4.00144
PPO Batch Consumption Time: 0.49868
Total Iteration Time: 7.48495

Cumulative Model Updates: 7,038
Cumulative Timesteps: 58,719,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 58719536...
Checkpoint 58719536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03616
Policy Entropy: 4.30208
Value Function Loss: 0.03203

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.57683
Value Function Update Magnitude: 0.48461

Collected Steps per Second: 14,505.71478
Overall Steps per Second: 6,755.58360

Timestep Collection Time: 3.45078
Timestep Consumption Time: 3.95880
PPO Batch Consumption Time: 0.49255
Total Iteration Time: 7.40957

Cumulative Model Updates: 7,044
Cumulative Timesteps: 58,769,592

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10276
Policy Entropy: 4.29517
Value Function Loss: 0.03930

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02914
Policy Update Magnitude: 0.60151
Value Function Update Magnitude: 0.46347

Collected Steps per Second: 14,052.25238
Overall Steps per Second: 6,623.91282

Timestep Collection Time: 3.55843
Timestep Consumption Time: 3.99058
PPO Batch Consumption Time: 0.49513
Total Iteration Time: 7.54901

Cumulative Model Updates: 7,050
Cumulative Timesteps: 58,819,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 58819596...
Checkpoint 58819596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08663
Policy Entropy: 4.29502
Value Function Loss: 0.04077

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02961
Policy Update Magnitude: 0.62025
Value Function Update Magnitude: 0.46397

Collected Steps per Second: 14,043.36358
Overall Steps per Second: 6,772.16668

Timestep Collection Time: 3.56225
Timestep Consumption Time: 3.82475
PPO Batch Consumption Time: 0.48603
Total Iteration Time: 7.38700

Cumulative Model Updates: 7,056
Cumulative Timesteps: 58,869,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04927
Policy Entropy: 4.29443
Value Function Loss: 0.04196

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02905
Policy Update Magnitude: 0.62712
Value Function Update Magnitude: 0.47332

Collected Steps per Second: 14,259.42326
Overall Steps per Second: 6,622.21660

Timestep Collection Time: 3.50772
Timestep Consumption Time: 4.04534
PPO Batch Consumption Time: 0.50608
Total Iteration Time: 7.55306

Cumulative Model Updates: 7,062
Cumulative Timesteps: 58,919,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 58919640...
Checkpoint 58919640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07181
Policy Entropy: 4.29450
Value Function Loss: 0.03573

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02930
Policy Update Magnitude: 0.63396
Value Function Update Magnitude: 0.43437

Collected Steps per Second: 14,000.89714
Overall Steps per Second: 6,584.99885

Timestep Collection Time: 3.57291
Timestep Consumption Time: 4.02375
PPO Batch Consumption Time: 0.50376
Total Iteration Time: 7.59666

Cumulative Model Updates: 7,068
Cumulative Timesteps: 58,969,664

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04093
Policy Entropy: 4.29129
Value Function Loss: 0.03993

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02711
Policy Update Magnitude: 0.62088
Value Function Update Magnitude: 0.41021

Collected Steps per Second: 14,556.71712
Overall Steps per Second: 6,703.57595

Timestep Collection Time: 3.43690
Timestep Consumption Time: 4.02628
PPO Batch Consumption Time: 0.49665
Total Iteration Time: 7.46318

Cumulative Model Updates: 7,074
Cumulative Timesteps: 59,019,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 59019694...
Checkpoint 59019694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12099
Policy Entropy: 4.28923
Value Function Loss: 0.04128

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03072
Policy Update Magnitude: 0.62756
Value Function Update Magnitude: 0.45228

Collected Steps per Second: 14,006.04545
Overall Steps per Second: 6,612.56607

Timestep Collection Time: 3.57089
Timestep Consumption Time: 3.99259
PPO Batch Consumption Time: 0.50212
Total Iteration Time: 7.56348

Cumulative Model Updates: 7,080
Cumulative Timesteps: 59,069,708

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08876
Policy Entropy: 4.28955
Value Function Loss: 0.04452

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03479
Policy Update Magnitude: 0.61394
Value Function Update Magnitude: 0.45085

Collected Steps per Second: 14,200.26353
Overall Steps per Second: 6,758.27067

Timestep Collection Time: 3.52134
Timestep Consumption Time: 3.87759
PPO Batch Consumption Time: 0.48671
Total Iteration Time: 7.39893

Cumulative Model Updates: 7,086
Cumulative Timesteps: 59,119,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 59119712...
Checkpoint 59119712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06384
Policy Entropy: 4.29226
Value Function Loss: 0.04228

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03201
Policy Update Magnitude: 0.62303
Value Function Update Magnitude: 0.45779

Collected Steps per Second: 14,159.83600
Overall Steps per Second: 6,696.29077

Timestep Collection Time: 3.53224
Timestep Consumption Time: 3.93697
PPO Batch Consumption Time: 0.49063
Total Iteration Time: 7.46921

Cumulative Model Updates: 7,092
Cumulative Timesteps: 59,169,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04911
Policy Entropy: 4.29294
Value Function Loss: 0.04128

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03383
Policy Update Magnitude: 0.64448
Value Function Update Magnitude: 0.46105

Collected Steps per Second: 14,306.20240
Overall Steps per Second: 6,706.45575

Timestep Collection Time: 3.49527
Timestep Consumption Time: 3.96083
PPO Batch Consumption Time: 0.49527
Total Iteration Time: 7.45610

Cumulative Model Updates: 7,098
Cumulative Timesteps: 59,219,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 59219732...
Checkpoint 59219732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.23473
Policy Entropy: 4.29075
Value Function Loss: 0.03774

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03416
Policy Update Magnitude: 0.64181
Value Function Update Magnitude: 0.42621

Collected Steps per Second: 14,026.67311
Overall Steps per Second: 6,628.04758

Timestep Collection Time: 3.56606
Timestep Consumption Time: 3.98065
PPO Batch Consumption Time: 0.49333
Total Iteration Time: 7.54672

Cumulative Model Updates: 7,104
Cumulative Timesteps: 59,269,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02196
Policy Entropy: 4.28833
Value Function Loss: 0.03529

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03846
Policy Update Magnitude: 0.62881
Value Function Update Magnitude: 0.41405

Collected Steps per Second: 13,917.85234
Overall Steps per Second: 6,581.98805

Timestep Collection Time: 3.59366
Timestep Consumption Time: 4.00526
PPO Batch Consumption Time: 0.49704
Total Iteration Time: 7.59892

Cumulative Model Updates: 7,110
Cumulative Timesteps: 59,319,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 59319768...
Checkpoint 59319768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10364
Policy Entropy: 4.29195
Value Function Loss: 0.03189

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03741
Policy Update Magnitude: 0.61866
Value Function Update Magnitude: 0.40539

Collected Steps per Second: 13,990.63670
Overall Steps per Second: 6,718.35176

Timestep Collection Time: 3.57553
Timestep Consumption Time: 3.87034
PPO Batch Consumption Time: 0.48996
Total Iteration Time: 7.44587

Cumulative Model Updates: 7,116
Cumulative Timesteps: 59,369,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10262
Policy Entropy: 4.28690
Value Function Loss: 0.03451

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03185
Policy Update Magnitude: 0.61795
Value Function Update Magnitude: 0.40796

Collected Steps per Second: 14,174.03802
Overall Steps per Second: 6,675.09731

Timestep Collection Time: 3.52955
Timestep Consumption Time: 3.96517
PPO Batch Consumption Time: 0.48713
Total Iteration Time: 7.49472

Cumulative Model Updates: 7,122
Cumulative Timesteps: 59,419,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 59419820...
Checkpoint 59419820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03637
Policy Entropy: 4.28527
Value Function Loss: 0.03782

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.61393
Value Function Update Magnitude: 0.41794

Collected Steps per Second: 13,972.16295
Overall Steps per Second: 6,688.15048

Timestep Collection Time: 3.57955
Timestep Consumption Time: 3.89846
PPO Batch Consumption Time: 0.49213
Total Iteration Time: 7.47800

Cumulative Model Updates: 7,128
Cumulative Timesteps: 59,469,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13233
Policy Entropy: 4.28358
Value Function Loss: 0.03888

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03674
Policy Update Magnitude: 0.62520
Value Function Update Magnitude: 0.43073

Collected Steps per Second: 14,082.47545
Overall Steps per Second: 6,643.14391

Timestep Collection Time: 3.55165
Timestep Consumption Time: 3.97732
PPO Batch Consumption Time: 0.48695
Total Iteration Time: 7.52897

Cumulative Model Updates: 7,134
Cumulative Timesteps: 59,519,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 59519850...
Checkpoint 59519850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00372
Policy Entropy: 4.28917
Value Function Loss: 0.03548

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02980
Policy Update Magnitude: 0.61193
Value Function Update Magnitude: 0.39557

Collected Steps per Second: 14,024.35352
Overall Steps per Second: 6,528.97648

Timestep Collection Time: 3.56637
Timestep Consumption Time: 4.09425
PPO Batch Consumption Time: 0.52082
Total Iteration Time: 7.66062

Cumulative Model Updates: 7,140
Cumulative Timesteps: 59,569,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09322
Policy Entropy: 4.29421
Value Function Loss: 0.03020

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03085
Policy Update Magnitude: 0.59145
Value Function Update Magnitude: 0.35610

Collected Steps per Second: 13,891.75774
Overall Steps per Second: 6,563.30707

Timestep Collection Time: 3.60142
Timestep Consumption Time: 4.02127
PPO Batch Consumption Time: 0.49898
Total Iteration Time: 7.62268

Cumulative Model Updates: 7,146
Cumulative Timesteps: 59,619,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 59619896...
Checkpoint 59619896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06281
Policy Entropy: 4.29846
Value Function Loss: 0.02882

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.56756
Value Function Update Magnitude: 0.34056

Collected Steps per Second: 13,886.36768
Overall Steps per Second: 6,387.81232

Timestep Collection Time: 3.60166
Timestep Consumption Time: 4.22794
PPO Batch Consumption Time: 0.53285
Total Iteration Time: 7.82960

Cumulative Model Updates: 7,152
Cumulative Timesteps: 59,669,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07730
Policy Entropy: 4.30232
Value Function Loss: 0.02247

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02410
Policy Update Magnitude: 0.53276
Value Function Update Magnitude: 0.35805

Collected Steps per Second: 13,227.04616
Overall Steps per Second: 6,357.39457

Timestep Collection Time: 3.78074
Timestep Consumption Time: 4.08538
PPO Batch Consumption Time: 0.50758
Total Iteration Time: 7.86612

Cumulative Model Updates: 7,158
Cumulative Timesteps: 59,719,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 59719918...
Checkpoint 59719918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18148
Policy Entropy: 4.30312
Value Function Loss: 0.02396

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02086
Policy Update Magnitude: 0.52808
Value Function Update Magnitude: 0.38807

Collected Steps per Second: 13,993.02414
Overall Steps per Second: 6,654.07459

Timestep Collection Time: 3.57364
Timestep Consumption Time: 3.94146
PPO Batch Consumption Time: 0.48946
Total Iteration Time: 7.51509

Cumulative Model Updates: 7,164
Cumulative Timesteps: 59,769,924

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00056
Policy Entropy: 4.30374
Value Function Loss: 0.02179

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.54679
Value Function Update Magnitude: 0.40925

Collected Steps per Second: 14,073.22394
Overall Steps per Second: 6,549.29747

Timestep Collection Time: 3.55299
Timestep Consumption Time: 4.08172
PPO Batch Consumption Time: 0.50684
Total Iteration Time: 7.63471

Cumulative Model Updates: 7,170
Cumulative Timesteps: 59,819,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 59819926...
Checkpoint 59819926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02725
Policy Entropy: 4.30574
Value Function Loss: 0.02817

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02605
Policy Update Magnitude: 0.54488
Value Function Update Magnitude: 0.38670

Collected Steps per Second: 14,071.37532
Overall Steps per Second: 6,599.86067

Timestep Collection Time: 3.55445
Timestep Consumption Time: 4.02389
PPO Batch Consumption Time: 0.49632
Total Iteration Time: 7.57834

Cumulative Model Updates: 7,176
Cumulative Timesteps: 59,869,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05185
Policy Entropy: 4.30256
Value Function Loss: 0.03030

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.54653
Value Function Update Magnitude: 0.38245

Collected Steps per Second: 13,889.69102
Overall Steps per Second: 6,614.57149

Timestep Collection Time: 3.60152
Timestep Consumption Time: 3.96118
PPO Batch Consumption Time: 0.49116
Total Iteration Time: 7.56270

Cumulative Model Updates: 7,182
Cumulative Timesteps: 59,919,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 59919966...
Checkpoint 59919966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.20415
Policy Entropy: 4.29919
Value Function Loss: 0.03237

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02456
Policy Update Magnitude: 0.57111
Value Function Update Magnitude: 0.41709

Collected Steps per Second: 13,751.90419
Overall Steps per Second: 6,532.70111

Timestep Collection Time: 3.63790
Timestep Consumption Time: 4.02019
PPO Batch Consumption Time: 0.51040
Total Iteration Time: 7.65809

Cumulative Model Updates: 7,188
Cumulative Timesteps: 59,969,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06115
Policy Entropy: 4.29711
Value Function Loss: 0.03117

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02488
Policy Update Magnitude: 0.58510
Value Function Update Magnitude: 0.39385

Collected Steps per Second: 13,201.82594
Overall Steps per Second: 6,168.36031

Timestep Collection Time: 3.78963
Timestep Consumption Time: 4.32112
PPO Batch Consumption Time: 0.56251
Total Iteration Time: 8.11075

Cumulative Model Updates: 7,194
Cumulative Timesteps: 60,020,024

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 60020024...
Checkpoint 60020024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01425
Policy Entropy: 4.30189
Value Function Loss: 0.03015

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02517
Policy Update Magnitude: 0.59118
Value Function Update Magnitude: 0.41706

Collected Steps per Second: 13,517.79191
Overall Steps per Second: 6,481.47954

Timestep Collection Time: 3.69898
Timestep Consumption Time: 4.01562
PPO Batch Consumption Time: 0.50037
Total Iteration Time: 7.71460

Cumulative Model Updates: 7,200
Cumulative Timesteps: 60,070,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01647
Policy Entropy: 4.29952
Value Function Loss: 0.02850

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.57885
Value Function Update Magnitude: 0.41705

Collected Steps per Second: 13,752.54736
Overall Steps per Second: 6,354.66881

Timestep Collection Time: 3.63685
Timestep Consumption Time: 4.23390
PPO Batch Consumption Time: 0.55087
Total Iteration Time: 7.87075

Cumulative Model Updates: 7,206
Cumulative Timesteps: 60,120,042

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 60120042...
Checkpoint 60120042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17670
Policy Entropy: 4.29668
Value Function Loss: 0.03673

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.61110
Value Function Update Magnitude: 0.43268

Collected Steps per Second: 13,624.96926
Overall Steps per Second: 6,483.19263

Timestep Collection Time: 3.67179
Timestep Consumption Time: 4.04478
PPO Batch Consumption Time: 0.49734
Total Iteration Time: 7.71657

Cumulative Model Updates: 7,212
Cumulative Timesteps: 60,170,070

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00759
Policy Entropy: 4.29497
Value Function Loss: 0.03380

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02955
Policy Update Magnitude: 0.64065
Value Function Update Magnitude: 0.48253

Collected Steps per Second: 14,128.82971
Overall Steps per Second: 6,471.32287

Timestep Collection Time: 3.53985
Timestep Consumption Time: 4.18870
PPO Batch Consumption Time: 0.56157
Total Iteration Time: 7.72856

Cumulative Model Updates: 7,218
Cumulative Timesteps: 60,220,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 60220084...
Checkpoint 60220084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07576
Policy Entropy: 4.29729
Value Function Loss: 0.03710

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.63952
Value Function Update Magnitude: 0.48957

Collected Steps per Second: 13,124.16964
Overall Steps per Second: 6,347.17366

Timestep Collection Time: 3.81357
Timestep Consumption Time: 4.07182
PPO Batch Consumption Time: 0.50398
Total Iteration Time: 7.88540

Cumulative Model Updates: 7,224
Cumulative Timesteps: 60,270,134

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00482
Policy Entropy: 4.30088
Value Function Loss: 0.02627

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.60468
Value Function Update Magnitude: 0.48876

Collected Steps per Second: 14,268.09538
Overall Steps per Second: 6,566.44475

Timestep Collection Time: 3.50516
Timestep Consumption Time: 4.11114
PPO Batch Consumption Time: 0.52451
Total Iteration Time: 7.61630

Cumulative Model Updates: 7,230
Cumulative Timesteps: 60,320,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 60320146...
Checkpoint 60320146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02363
Policy Entropy: 4.30330
Value Function Loss: 0.03237

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02876
Policy Update Magnitude: 0.59092
Value Function Update Magnitude: 0.44455

Collected Steps per Second: 13,725.29832
Overall Steps per Second: 6,253.75879

Timestep Collection Time: 3.64407
Timestep Consumption Time: 4.35368
PPO Batch Consumption Time: 0.55557
Total Iteration Time: 7.99775

Cumulative Model Updates: 7,236
Cumulative Timesteps: 60,370,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09320
Policy Entropy: 4.30027
Value Function Loss: 0.03147

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03445
Policy Update Magnitude: 0.60285
Value Function Update Magnitude: 0.45046

Collected Steps per Second: 13,957.07107
Overall Steps per Second: 6,532.50849

Timestep Collection Time: 3.58299
Timestep Consumption Time: 4.07227
PPO Batch Consumption Time: 0.50968
Total Iteration Time: 7.65525

Cumulative Model Updates: 7,242
Cumulative Timesteps: 60,420,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 60420170...
Checkpoint 60420170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08484
Policy Entropy: 4.29998
Value Function Loss: 0.03443

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02571
Policy Update Magnitude: 0.58817
Value Function Update Magnitude: 0.40362

Collected Steps per Second: 13,592.16988
Overall Steps per Second: 6,499.91887

Timestep Collection Time: 3.67888
Timestep Consumption Time: 4.01414
PPO Batch Consumption Time: 0.51040
Total Iteration Time: 7.69302

Cumulative Model Updates: 7,248
Cumulative Timesteps: 60,470,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19779
Policy Entropy: 4.29985
Value Function Loss: 0.03350

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02868
Policy Update Magnitude: 0.57927
Value Function Update Magnitude: 0.42716

Collected Steps per Second: 13,941.08003
Overall Steps per Second: 6,540.14024

Timestep Collection Time: 3.58652
Timestep Consumption Time: 4.05857
PPO Batch Consumption Time: 0.50208
Total Iteration Time: 7.64510

Cumulative Model Updates: 7,254
Cumulative Timesteps: 60,520,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 60520174...
Checkpoint 60520174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22254
Policy Entropy: 4.30225
Value Function Loss: 0.02975

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02999
Policy Update Magnitude: 0.58512
Value Function Update Magnitude: 0.43232

Collected Steps per Second: 13,889.10754
Overall Steps per Second: 6,671.96869

Timestep Collection Time: 3.60167
Timestep Consumption Time: 3.89597
PPO Batch Consumption Time: 0.47827
Total Iteration Time: 7.49764

Cumulative Model Updates: 7,260
Cumulative Timesteps: 60,570,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08536
Policy Entropy: 4.30245
Value Function Loss: 0.02700

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.57589
Value Function Update Magnitude: 0.42477

Collected Steps per Second: 13,649.51619
Overall Steps per Second: 6,519.09776

Timestep Collection Time: 3.66313
Timestep Consumption Time: 4.00664
PPO Batch Consumption Time: 0.49796
Total Iteration Time: 7.66977

Cumulative Model Updates: 7,266
Cumulative Timesteps: 60,620,198

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 60620198...
Checkpoint 60620198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15503
Policy Entropy: 4.30589
Value Function Loss: 0.02309

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02195
Policy Update Magnitude: 0.57043
Value Function Update Magnitude: 0.39388

Collected Steps per Second: 13,462.31738
Overall Steps per Second: 6,225.53709

Timestep Collection Time: 3.71571
Timestep Consumption Time: 4.31926
PPO Batch Consumption Time: 0.56188
Total Iteration Time: 8.03497

Cumulative Model Updates: 7,272
Cumulative Timesteps: 60,670,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21046
Policy Entropy: 4.30029
Value Function Loss: 0.02804

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.55039
Value Function Update Magnitude: 0.40921

Collected Steps per Second: 13,628.29566
Overall Steps per Second: 6,170.25844

Timestep Collection Time: 3.66928
Timestep Consumption Time: 4.43508
PPO Batch Consumption Time: 0.56558
Total Iteration Time: 8.10436

Cumulative Model Updates: 7,278
Cumulative Timesteps: 60,720,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 60720226...
Checkpoint 60720226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08696
Policy Entropy: 4.29593
Value Function Loss: 0.03423

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02876
Policy Update Magnitude: 0.57490
Value Function Update Magnitude: 0.44725

Collected Steps per Second: 13,931.51241
Overall Steps per Second: 6,609.16532

Timestep Collection Time: 3.58999
Timestep Consumption Time: 3.97738
PPO Batch Consumption Time: 0.49019
Total Iteration Time: 7.56737

Cumulative Model Updates: 7,284
Cumulative Timesteps: 60,770,240

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.29697
Policy Entropy: 4.29636
Value Function Loss: 0.03159

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 0.59706
Value Function Update Magnitude: 0.46068

Collected Steps per Second: 14,161.59741
Overall Steps per Second: 6,481.96329

Timestep Collection Time: 3.53096
Timestep Consumption Time: 4.18337
PPO Batch Consumption Time: 0.52400
Total Iteration Time: 7.71433

Cumulative Model Updates: 7,290
Cumulative Timesteps: 60,820,244

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 60820244...
Checkpoint 60820244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05171
Policy Entropy: 4.30149
Value Function Loss: 0.03664

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03052
Policy Update Magnitude: 0.61666
Value Function Update Magnitude: 0.47209

Collected Steps per Second: 14,182.60859
Overall Steps per Second: 6,644.73965

Timestep Collection Time: 3.52671
Timestep Consumption Time: 4.00074
PPO Batch Consumption Time: 0.49619
Total Iteration Time: 7.52746

Cumulative Model Updates: 7,296
Cumulative Timesteps: 60,870,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05071
Policy Entropy: 4.30082
Value Function Loss: 0.03561

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03746
Policy Update Magnitude: 0.63391
Value Function Update Magnitude: 0.50545

Collected Steps per Second: 14,113.59659
Overall Steps per Second: 6,721.41181

Timestep Collection Time: 3.54282
Timestep Consumption Time: 3.89639
PPO Batch Consumption Time: 0.49035
Total Iteration Time: 7.43921

Cumulative Model Updates: 7,302
Cumulative Timesteps: 60,920,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 60920264...
Checkpoint 60920264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04845
Policy Entropy: 4.29615
Value Function Loss: 0.04217

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.03547
Policy Update Magnitude: 0.66114
Value Function Update Magnitude: 0.50450

Collected Steps per Second: 13,681.83646
Overall Steps per Second: 6,549.09932

Timestep Collection Time: 3.65565
Timestep Consumption Time: 3.98143
PPO Batch Consumption Time: 0.49017
Total Iteration Time: 7.63708

Cumulative Model Updates: 7,308
Cumulative Timesteps: 60,970,280

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19915
Policy Entropy: 4.29722
Value Function Loss: 0.03278

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03324
Policy Update Magnitude: 0.64144
Value Function Update Magnitude: 0.45117

Collected Steps per Second: 13,899.00530
Overall Steps per Second: 6,565.28710

Timestep Collection Time: 3.59839
Timestep Consumption Time: 4.01956
PPO Batch Consumption Time: 0.49867
Total Iteration Time: 7.61795

Cumulative Model Updates: 7,314
Cumulative Timesteps: 61,020,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 61020294...
Checkpoint 61020294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00999
Policy Entropy: 4.30028
Value Function Loss: 0.02701

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03608
Policy Update Magnitude: 0.58826
Value Function Update Magnitude: 0.40766

Collected Steps per Second: 13,022.90268
Overall Steps per Second: 6,441.53919

Timestep Collection Time: 3.84016
Timestep Consumption Time: 3.92351
PPO Batch Consumption Time: 0.49352
Total Iteration Time: 7.76367

Cumulative Model Updates: 7,320
Cumulative Timesteps: 61,070,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14923
Policy Entropy: 4.30103
Value Function Loss: 0.02640

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.03593
Policy Update Magnitude: 0.55167
Value Function Update Magnitude: 0.40650

Collected Steps per Second: 14,038.88432
Overall Steps per Second: 6,447.93047

Timestep Collection Time: 3.56182
Timestep Consumption Time: 4.19322
PPO Batch Consumption Time: 0.52387
Total Iteration Time: 7.75505

Cumulative Model Updates: 7,326
Cumulative Timesteps: 61,120,308

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 61120308...
Checkpoint 61120308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18271
Policy Entropy: 4.30074
Value Function Loss: 0.03222

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03649
Policy Update Magnitude: 0.57869
Value Function Update Magnitude: 0.43417

Collected Steps per Second: 13,742.26369
Overall Steps per Second: 6,600.10967

Timestep Collection Time: 3.63899
Timestep Consumption Time: 3.93785
PPO Batch Consumption Time: 0.49913
Total Iteration Time: 7.57684

Cumulative Model Updates: 7,332
Cumulative Timesteps: 61,170,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00340
Policy Entropy: 4.29629
Value Function Loss: 0.03355

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03472
Policy Update Magnitude: 0.62204
Value Function Update Magnitude: 0.47262

Collected Steps per Second: 13,066.18912
Overall Steps per Second: 6,260.34990

Timestep Collection Time: 3.82790
Timestep Consumption Time: 4.16143
PPO Batch Consumption Time: 0.51625
Total Iteration Time: 7.98933

Cumulative Model Updates: 7,338
Cumulative Timesteps: 61,220,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 61220332...
Checkpoint 61220332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05699
Policy Entropy: 4.29384
Value Function Loss: 0.03374

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03213
Policy Update Magnitude: 0.62858
Value Function Update Magnitude: 0.49395

Collected Steps per Second: 13,101.60028
Overall Steps per Second: 6,328.52518

Timestep Collection Time: 3.81663
Timestep Consumption Time: 4.08473
PPO Batch Consumption Time: 0.51346
Total Iteration Time: 7.90137

Cumulative Model Updates: 7,344
Cumulative Timesteps: 61,270,336

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05035
Policy Entropy: 4.29376
Value Function Loss: 0.02970

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.61422
Value Function Update Magnitude: 0.47015

Collected Steps per Second: 14,129.60801
Overall Steps per Second: 6,454.40564

Timestep Collection Time: 3.54023
Timestep Consumption Time: 4.20983
PPO Batch Consumption Time: 0.52161
Total Iteration Time: 7.75006

Cumulative Model Updates: 7,350
Cumulative Timesteps: 61,320,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 61320358...
Checkpoint 61320358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01657
Policy Entropy: 4.29785
Value Function Loss: 0.03295

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.60003
Value Function Update Magnitude: 0.45794

Collected Steps per Second: 14,044.05047
Overall Steps per Second: 6,582.44203

Timestep Collection Time: 3.56094
Timestep Consumption Time: 4.03655
PPO Batch Consumption Time: 0.49928
Total Iteration Time: 7.59748

Cumulative Model Updates: 7,356
Cumulative Timesteps: 61,370,368

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14808
Policy Entropy: 4.30144
Value Function Loss: 0.03389

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02616
Policy Update Magnitude: 0.59167
Value Function Update Magnitude: 0.44958

Collected Steps per Second: 14,245.47690
Overall Steps per Second: 6,682.05045

Timestep Collection Time: 3.51003
Timestep Consumption Time: 3.97301
PPO Batch Consumption Time: 0.50178
Total Iteration Time: 7.48303

Cumulative Model Updates: 7,362
Cumulative Timesteps: 61,420,370

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 61420370...
Checkpoint 61420370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04049
Policy Entropy: 4.30255
Value Function Loss: 0.03522

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02717
Policy Update Magnitude: 0.61656
Value Function Update Magnitude: 0.46834

Collected Steps per Second: 14,128.63866
Overall Steps per Second: 6,677.43133

Timestep Collection Time: 3.54174
Timestep Consumption Time: 3.95216
PPO Batch Consumption Time: 0.48447
Total Iteration Time: 7.49390

Cumulative Model Updates: 7,368
Cumulative Timesteps: 61,470,410

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07791
Policy Entropy: 4.30340
Value Function Loss: 0.02852

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02649
Policy Update Magnitude: 0.59124
Value Function Update Magnitude: 0.44852

Collected Steps per Second: 14,360.58513
Overall Steps per Second: 6,719.04094

Timestep Collection Time: 3.48259
Timestep Consumption Time: 3.96074
PPO Batch Consumption Time: 0.49095
Total Iteration Time: 7.44332

Cumulative Model Updates: 7,374
Cumulative Timesteps: 61,520,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 61520422...
Checkpoint 61520422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03740
Policy Entropy: 4.30883
Value Function Loss: 0.02494

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.56654
Value Function Update Magnitude: 0.45727

Collected Steps per Second: 14,338.28954
Overall Steps per Second: 6,767.75127

Timestep Collection Time: 3.48814
Timestep Consumption Time: 3.90190
PPO Batch Consumption Time: 0.48126
Total Iteration Time: 7.39005

Cumulative Model Updates: 7,380
Cumulative Timesteps: 61,570,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.23240
Policy Entropy: 4.29947
Value Function Loss: 0.02809

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02110
Policy Update Magnitude: 0.59599
Value Function Update Magnitude: 0.43437

Collected Steps per Second: 14,222.10566
Overall Steps per Second: 6,489.30412

Timestep Collection Time: 3.51720
Timestep Consumption Time: 4.19118
PPO Batch Consumption Time: 0.52418
Total Iteration Time: 7.70838

Cumulative Model Updates: 7,386
Cumulative Timesteps: 61,620,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 61620458...
Checkpoint 61620458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00358
Policy Entropy: 4.29424
Value Function Loss: 0.02876

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03385
Policy Update Magnitude: 0.60004
Value Function Update Magnitude: 0.43441

Collected Steps per Second: 13,498.44140
Overall Steps per Second: 6,419.31042

Timestep Collection Time: 3.70606
Timestep Consumption Time: 4.08699
PPO Batch Consumption Time: 0.52742
Total Iteration Time: 7.79305

Cumulative Model Updates: 7,392
Cumulative Timesteps: 61,670,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03441
Policy Entropy: 4.30011
Value Function Loss: 0.03179

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.59799
Value Function Update Magnitude: 0.41717

Collected Steps per Second: 14,321.23448
Overall Steps per Second: 6,686.27073

Timestep Collection Time: 3.49202
Timestep Consumption Time: 3.98749
PPO Batch Consumption Time: 0.49067
Total Iteration Time: 7.47951

Cumulative Model Updates: 7,398
Cumulative Timesteps: 61,720,494

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 61720494...
Checkpoint 61720494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22093
Policy Entropy: 4.30056
Value Function Loss: 0.03040

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02465
Policy Update Magnitude: 0.58953
Value Function Update Magnitude: 0.42159

Collected Steps per Second: 14,208.90706
Overall Steps per Second: 6,622.38200

Timestep Collection Time: 3.52117
Timestep Consumption Time: 4.03381
PPO Batch Consumption Time: 0.52200
Total Iteration Time: 7.55499

Cumulative Model Updates: 7,404
Cumulative Timesteps: 61,770,526

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12624
Policy Entropy: 4.29628
Value Function Loss: 0.03363

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.61199
Value Function Update Magnitude: 0.43951

Collected Steps per Second: 13,726.21529
Overall Steps per Second: 6,157.58022

Timestep Collection Time: 3.64470
Timestep Consumption Time: 4.47992
PPO Batch Consumption Time: 0.56711
Total Iteration Time: 8.12462

Cumulative Model Updates: 7,410
Cumulative Timesteps: 61,820,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 61820554...
Checkpoint 61820554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08006
Policy Entropy: 4.29560
Value Function Loss: 0.03086

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 0.61964
Value Function Update Magnitude: 0.46726

Collected Steps per Second: 13,455.20512
Overall Steps per Second: 6,433.81664

Timestep Collection Time: 3.71811
Timestep Consumption Time: 4.05767
PPO Batch Consumption Time: 0.50559
Total Iteration Time: 7.77579

Cumulative Model Updates: 7,416
Cumulative Timesteps: 61,870,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00475
Policy Entropy: 4.29891
Value Function Loss: 0.02351

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01992
Policy Update Magnitude: 0.57600
Value Function Update Magnitude: 0.44685

Collected Steps per Second: 14,149.87915
Overall Steps per Second: 6,837.63160

Timestep Collection Time: 3.53558
Timestep Consumption Time: 3.78099
PPO Batch Consumption Time: 0.47591
Total Iteration Time: 7.31657

Cumulative Model Updates: 7,422
Cumulative Timesteps: 61,920,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 61920610...
Checkpoint 61920610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04241
Policy Entropy: 4.30615
Value Function Loss: 0.02245

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02210
Policy Update Magnitude: 0.53508
Value Function Update Magnitude: 0.44061

Collected Steps per Second: 14,242.96124
Overall Steps per Second: 6,738.63869

Timestep Collection Time: 3.51233
Timestep Consumption Time: 3.91142
PPO Batch Consumption Time: 0.47790
Total Iteration Time: 7.42375

Cumulative Model Updates: 7,428
Cumulative Timesteps: 61,970,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12748
Policy Entropy: 4.30395
Value Function Loss: 0.03071

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02537
Policy Update Magnitude: 0.57418
Value Function Update Magnitude: 0.42604

Collected Steps per Second: 14,158.67271
Overall Steps per Second: 6,715.46763

Timestep Collection Time: 3.53225
Timestep Consumption Time: 3.91503
PPO Batch Consumption Time: 0.48918
Total Iteration Time: 7.44728

Cumulative Model Updates: 7,434
Cumulative Timesteps: 62,020,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 62020648...
Checkpoint 62020648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02008
Policy Entropy: 4.30329
Value Function Loss: 0.02957

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02685
Policy Update Magnitude: 0.59424
Value Function Update Magnitude: 0.44816

Collected Steps per Second: 14,119.87097
Overall Steps per Second: 6,718.61422

Timestep Collection Time: 3.54224
Timestep Consumption Time: 3.90215
PPO Batch Consumption Time: 0.48635
Total Iteration Time: 7.44439

Cumulative Model Updates: 7,440
Cumulative Timesteps: 62,070,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.29370
Policy Entropy: 4.30450
Value Function Loss: 0.02947

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02947
Policy Update Magnitude: 0.57294
Value Function Update Magnitude: 0.44055

Collected Steps per Second: 14,231.04750
Overall Steps per Second: 6,727.27781

Timestep Collection Time: 3.51415
Timestep Consumption Time: 3.91977
PPO Batch Consumption Time: 0.49502
Total Iteration Time: 7.43391

Cumulative Model Updates: 7,446
Cumulative Timesteps: 62,120,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 62120674...
Checkpoint 62120674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21919
Policy Entropy: 4.30430
Value Function Loss: 0.02538

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02240
Policy Update Magnitude: 0.56820
Value Function Update Magnitude: 0.43630

Collected Steps per Second: 14,474.66234
Overall Steps per Second: 6,792.24292

Timestep Collection Time: 3.45638
Timestep Consumption Time: 3.90937
PPO Batch Consumption Time: 0.48680
Total Iteration Time: 7.36576

Cumulative Model Updates: 7,452
Cumulative Timesteps: 62,170,704

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08148
Policy Entropy: 4.30203
Value Function Loss: 0.02760

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02521
Policy Update Magnitude: 0.57698
Value Function Update Magnitude: 0.42374

Collected Steps per Second: 14,400.75397
Overall Steps per Second: 6,753.83581

Timestep Collection Time: 3.47301
Timestep Consumption Time: 3.93226
PPO Batch Consumption Time: 0.48998
Total Iteration Time: 7.40527

Cumulative Model Updates: 7,458
Cumulative Timesteps: 62,220,718

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 62220718...
Checkpoint 62220718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13337
Policy Entropy: 4.30326
Value Function Loss: 0.02940

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.58157
Value Function Update Magnitude: 0.41183

Collected Steps per Second: 14,546.28856
Overall Steps per Second: 6,742.61675

Timestep Collection Time: 3.43923
Timestep Consumption Time: 3.98044
PPO Batch Consumption Time: 0.49194
Total Iteration Time: 7.41967

Cumulative Model Updates: 7,464
Cumulative Timesteps: 62,270,746

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08216
Policy Entropy: 4.30437
Value Function Loss: 0.03371

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02980
Policy Update Magnitude: 0.59795
Value Function Update Magnitude: 0.47590

Collected Steps per Second: 14,402.00026
Overall Steps per Second: 6,840.57427

Timestep Collection Time: 3.47299
Timestep Consumption Time: 3.83897
PPO Batch Consumption Time: 0.47558
Total Iteration Time: 7.31196

Cumulative Model Updates: 7,470
Cumulative Timesteps: 62,320,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 62320764...
Checkpoint 62320764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03763
Policy Entropy: 4.30131
Value Function Loss: 0.03609

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02897
Policy Update Magnitude: 0.62316
Value Function Update Magnitude: 0.48369

Collected Steps per Second: 14,064.94327
Overall Steps per Second: 6,738.58152

Timestep Collection Time: 3.55536
Timestep Consumption Time: 3.86549
PPO Batch Consumption Time: 0.48195
Total Iteration Time: 7.42085

Cumulative Model Updates: 7,476
Cumulative Timesteps: 62,370,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03192
Policy Entropy: 4.30124
Value Function Loss: 0.03223

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03504
Policy Update Magnitude: 0.62130
Value Function Update Magnitude: 0.45496

Collected Steps per Second: 13,193.56729
Overall Steps per Second: 6,285.26817

Timestep Collection Time: 3.79139
Timestep Consumption Time: 4.16722
PPO Batch Consumption Time: 0.50929
Total Iteration Time: 7.95861

Cumulative Model Updates: 7,482
Cumulative Timesteps: 62,420,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 62420792...
Checkpoint 62420792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11532
Policy Entropy: 4.30054
Value Function Loss: 0.03968

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03603
Policy Update Magnitude: 0.62160
Value Function Update Magnitude: 0.44418

Collected Steps per Second: 13,939.55133
Overall Steps per Second: 6,740.47248

Timestep Collection Time: 3.58950
Timestep Consumption Time: 3.83372
PPO Batch Consumption Time: 0.47270
Total Iteration Time: 7.42322

Cumulative Model Updates: 7,488
Cumulative Timesteps: 62,470,828

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19774
Policy Entropy: 4.30279
Value Function Loss: 0.03308

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03060
Policy Update Magnitude: 0.63051
Value Function Update Magnitude: 0.46366

Collected Steps per Second: 14,175.69209
Overall Steps per Second: 6,710.71944

Timestep Collection Time: 3.52872
Timestep Consumption Time: 3.92533
PPO Batch Consumption Time: 0.49149
Total Iteration Time: 7.45404

Cumulative Model Updates: 7,494
Cumulative Timesteps: 62,520,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 62520850...
Checkpoint 62520850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04658
Policy Entropy: 4.29306
Value Function Loss: 0.03486

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03792
Policy Update Magnitude: 0.61229
Value Function Update Magnitude: 0.45838

Collected Steps per Second: 14,161.72646
Overall Steps per Second: 6,654.38876

Timestep Collection Time: 3.53135
Timestep Consumption Time: 3.98399
PPO Batch Consumption Time: 0.49705
Total Iteration Time: 7.51534

Cumulative Model Updates: 7,500
Cumulative Timesteps: 62,570,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.22398
Policy Entropy: 4.30170
Value Function Loss: 0.02577

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02898
Policy Update Magnitude: 0.59842
Value Function Update Magnitude: 0.41611

Collected Steps per Second: 13,692.41253
Overall Steps per Second: 6,583.75037

Timestep Collection Time: 3.65180
Timestep Consumption Time: 3.94296
PPO Batch Consumption Time: 0.50016
Total Iteration Time: 7.59476

Cumulative Model Updates: 7,506
Cumulative Timesteps: 62,620,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 62620862...
Checkpoint 62620862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05692
Policy Entropy: 4.29206
Value Function Loss: 0.03327

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02879
Policy Update Magnitude: 0.58777
Value Function Update Magnitude: 0.38493

Collected Steps per Second: 13,800.42624
Overall Steps per Second: 6,631.26449

Timestep Collection Time: 3.62496
Timestep Consumption Time: 3.91900
PPO Batch Consumption Time: 0.48778
Total Iteration Time: 7.54396

Cumulative Model Updates: 7,512
Cumulative Timesteps: 62,670,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06042
Policy Entropy: 4.29042
Value Function Loss: 0.03190

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02997
Policy Update Magnitude: 0.60136
Value Function Update Magnitude: 0.40302

Collected Steps per Second: 14,229.85799
Overall Steps per Second: 6,766.23276

Timestep Collection Time: 3.51683
Timestep Consumption Time: 3.87931
PPO Batch Consumption Time: 0.48560
Total Iteration Time: 7.39614

Cumulative Model Updates: 7,518
Cumulative Timesteps: 62,720,932

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 62720932...
Checkpoint 62720932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07172
Policy Entropy: 4.28911
Value Function Loss: 0.03247

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03762
Policy Update Magnitude: 0.60751
Value Function Update Magnitude: 0.40478

Collected Steps per Second: 14,483.95977
Overall Steps per Second: 6,843.28161

Timestep Collection Time: 3.45251
Timestep Consumption Time: 3.85480
PPO Batch Consumption Time: 0.48653
Total Iteration Time: 7.30731

Cumulative Model Updates: 7,524
Cumulative Timesteps: 62,770,938

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09809
Policy Entropy: 4.29345
Value Function Loss: 0.02323

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02773
Policy Update Magnitude: 0.59014
Value Function Update Magnitude: 0.43633

Collected Steps per Second: 14,326.06198
Overall Steps per Second: 6,668.38140

Timestep Collection Time: 3.49126
Timestep Consumption Time: 4.00921
PPO Batch Consumption Time: 0.49227
Total Iteration Time: 7.50047

Cumulative Model Updates: 7,530
Cumulative Timesteps: 62,820,954

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 62820954...
Checkpoint 62820954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02103
Policy Entropy: 4.29027
Value Function Loss: 0.02362

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03150
Policy Update Magnitude: 0.57609
Value Function Update Magnitude: 0.40389

Collected Steps per Second: 14,276.01733
Overall Steps per Second: 6,730.19654

Timestep Collection Time: 3.50434
Timestep Consumption Time: 3.92903
PPO Batch Consumption Time: 0.49274
Total Iteration Time: 7.43336

Cumulative Model Updates: 7,536
Cumulative Timesteps: 62,870,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15797
Policy Entropy: 4.29245
Value Function Loss: 0.02240

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.02804
Policy Update Magnitude: 0.58430
Value Function Update Magnitude: 0.40853

Collected Steps per Second: 14,438.74404
Overall Steps per Second: 6,769.71332

Timestep Collection Time: 3.46484
Timestep Consumption Time: 3.92513
PPO Batch Consumption Time: 0.48982
Total Iteration Time: 7.38997

Cumulative Model Updates: 7,542
Cumulative Timesteps: 62,921,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 62921010...
Checkpoint 62921010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.45538
Policy Entropy: 4.29568
Value Function Loss: 0.03003

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03198
Policy Update Magnitude: 0.61553
Value Function Update Magnitude: 0.46835

Collected Steps per Second: 14,136.53175
Overall Steps per Second: 6,767.43570

Timestep Collection Time: 3.53962
Timestep Consumption Time: 3.85431
PPO Batch Consumption Time: 0.48579
Total Iteration Time: 7.39394

Cumulative Model Updates: 7,548
Cumulative Timesteps: 62,971,048

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.31595
Policy Entropy: 4.29888
Value Function Loss: 0.03212

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03100
Policy Update Magnitude: 0.64906
Value Function Update Magnitude: 0.46166

Collected Steps per Second: 14,091.43785
Overall Steps per Second: 6,632.32446

Timestep Collection Time: 3.54896
Timestep Consumption Time: 3.99138
PPO Batch Consumption Time: 0.49625
Total Iteration Time: 7.54034

Cumulative Model Updates: 7,554
Cumulative Timesteps: 63,021,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 63021058...
Checkpoint 63021058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17470
Policy Entropy: 4.29895
Value Function Loss: 0.03284

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03548
Policy Update Magnitude: 0.63814
Value Function Update Magnitude: 0.47119

Collected Steps per Second: 14,069.20198
Overall Steps per Second: 6,717.41359

Timestep Collection Time: 3.55429
Timestep Consumption Time: 3.88995
PPO Batch Consumption Time: 0.48357
Total Iteration Time: 7.44423

Cumulative Model Updates: 7,560
Cumulative Timesteps: 63,071,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03205
Policy Entropy: 4.29793
Value Function Loss: 0.03292

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03564
Policy Update Magnitude: 0.61162
Value Function Update Magnitude: 0.45421

Collected Steps per Second: 14,636.46350
Overall Steps per Second: 6,847.32364

Timestep Collection Time: 3.41777
Timestep Consumption Time: 3.88786
PPO Batch Consumption Time: 0.47313
Total Iteration Time: 7.30563

Cumulative Model Updates: 7,566
Cumulative Timesteps: 63,121,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 63121088...
Checkpoint 63121088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10809
Policy Entropy: 4.29394
Value Function Loss: 0.03315

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03037
Policy Update Magnitude: 0.61405
Value Function Update Magnitude: 0.42880

Collected Steps per Second: 14,186.61144
Overall Steps per Second: 6,656.54692

Timestep Collection Time: 3.52515
Timestep Consumption Time: 3.98775
PPO Batch Consumption Time: 0.49353
Total Iteration Time: 7.51290

Cumulative Model Updates: 7,572
Cumulative Timesteps: 63,171,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13661
Policy Entropy: 4.29508
Value Function Loss: 0.03149

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03383
Policy Update Magnitude: 0.62399
Value Function Update Magnitude: 0.45317

Collected Steps per Second: 14,322.75298
Overall Steps per Second: 6,783.17065

Timestep Collection Time: 3.49137
Timestep Consumption Time: 3.88070
PPO Batch Consumption Time: 0.48204
Total Iteration Time: 7.37207

Cumulative Model Updates: 7,578
Cumulative Timesteps: 63,221,104

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 63221104...
Checkpoint 63221104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05483
Policy Entropy: 4.29717
Value Function Loss: 0.02369

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03259
Policy Update Magnitude: 0.60295
Value Function Update Magnitude: 0.43362

Collected Steps per Second: 14,234.48741
Overall Steps per Second: 6,698.43870

Timestep Collection Time: 3.51442
Timestep Consumption Time: 3.95389
PPO Batch Consumption Time: 0.49021
Total Iteration Time: 7.46831

Cumulative Model Updates: 7,584
Cumulative Timesteps: 63,271,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01673
Policy Entropy: 4.30057
Value Function Loss: 0.02821

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.61084
Value Function Update Magnitude: 0.41323

Collected Steps per Second: 14,734.69418
Overall Steps per Second: 6,754.07013

Timestep Collection Time: 3.39362
Timestep Consumption Time: 4.00991
PPO Batch Consumption Time: 0.49592
Total Iteration Time: 7.40354

Cumulative Model Updates: 7,590
Cumulative Timesteps: 63,321,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 63321134...
Checkpoint 63321134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01921
Policy Entropy: 4.29679
Value Function Loss: 0.03338

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02778
Policy Update Magnitude: 0.62648
Value Function Update Magnitude: 0.43055

Collected Steps per Second: 14,178.45267
Overall Steps per Second: 6,618.39904

Timestep Collection Time: 3.52648
Timestep Consumption Time: 4.02822
PPO Batch Consumption Time: 0.50392
Total Iteration Time: 7.55470

Cumulative Model Updates: 7,596
Cumulative Timesteps: 63,371,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13767
Policy Entropy: 4.30114
Value Function Loss: 0.03476

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.62453
Value Function Update Magnitude: 0.42504

Collected Steps per Second: 14,410.83514
Overall Steps per Second: 6,726.28923

Timestep Collection Time: 3.47003
Timestep Consumption Time: 3.96438
PPO Batch Consumption Time: 0.48993
Total Iteration Time: 7.43441

Cumulative Model Updates: 7,602
Cumulative Timesteps: 63,421,140

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 63421140...
Checkpoint 63421140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.31726
Policy Entropy: 4.29571
Value Function Loss: 0.03087

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02895
Policy Update Magnitude: 0.62035
Value Function Update Magnitude: 0.42923

Collected Steps per Second: 14,384.43322
Overall Steps per Second: 6,727.82091

Timestep Collection Time: 3.47723
Timestep Consumption Time: 3.95727
PPO Batch Consumption Time: 0.49095
Total Iteration Time: 7.43450

Cumulative Model Updates: 7,608
Cumulative Timesteps: 63,471,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08192
Policy Entropy: 4.29524
Value Function Loss: 0.03357

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02915
Policy Update Magnitude: 0.62409
Value Function Update Magnitude: 0.46806

Collected Steps per Second: 14,312.50895
Overall Steps per Second: 6,769.73503

Timestep Collection Time: 3.49457
Timestep Consumption Time: 3.89361
PPO Batch Consumption Time: 0.49192
Total Iteration Time: 7.38818

Cumulative Model Updates: 7,614
Cumulative Timesteps: 63,521,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 63521174...
Checkpoint 63521174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10765
Policy Entropy: 4.29172
Value Function Loss: 0.03751

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03133
Policy Update Magnitude: 0.66610
Value Function Update Magnitude: 0.47212

Collected Steps per Second: 14,240.10762
Overall Steps per Second: 6,795.13323

Timestep Collection Time: 3.51289
Timestep Consumption Time: 3.84884
PPO Batch Consumption Time: 0.47855
Total Iteration Time: 7.36174

Cumulative Model Updates: 7,620
Cumulative Timesteps: 63,571,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.23770
Policy Entropy: 4.29574
Value Function Loss: 0.03085

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02808
Policy Update Magnitude: 0.65192
Value Function Update Magnitude: 0.45348

Collected Steps per Second: 14,171.80968
Overall Steps per Second: 6,753.96241

Timestep Collection Time: 3.52855
Timestep Consumption Time: 3.87540
PPO Batch Consumption Time: 0.48224
Total Iteration Time: 7.40395

Cumulative Model Updates: 7,626
Cumulative Timesteps: 63,621,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 63621204...
Checkpoint 63621204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05267
Policy Entropy: 4.29920
Value Function Loss: 0.02950

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.61258
Value Function Update Magnitude: 0.42246

Collected Steps per Second: 14,225.02288
Overall Steps per Second: 6,784.66922

Timestep Collection Time: 3.51676
Timestep Consumption Time: 3.85663
PPO Batch Consumption Time: 0.48042
Total Iteration Time: 7.37339

Cumulative Model Updates: 7,632
Cumulative Timesteps: 63,671,230

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06177
Policy Entropy: 4.30167
Value Function Loss: 0.02869

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02772
Policy Update Magnitude: 0.59670
Value Function Update Magnitude: 0.44520

Collected Steps per Second: 14,670.05988
Overall Steps per Second: 6,754.67605

Timestep Collection Time: 3.40967
Timestep Consumption Time: 3.99557
PPO Batch Consumption Time: 0.50071
Total Iteration Time: 7.40524

Cumulative Model Updates: 7,638
Cumulative Timesteps: 63,721,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 63721250...
Checkpoint 63721250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18259
Policy Entropy: 4.30314
Value Function Loss: 0.02731

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02875
Policy Update Magnitude: 0.57922
Value Function Update Magnitude: 0.46621

Collected Steps per Second: 14,171.23313
Overall Steps per Second: 6,793.90818

Timestep Collection Time: 3.53025
Timestep Consumption Time: 3.83341
PPO Batch Consumption Time: 0.48205
Total Iteration Time: 7.36366

Cumulative Model Updates: 7,644
Cumulative Timesteps: 63,771,278

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09794
Policy Entropy: 4.30166
Value Function Loss: 0.02380

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02224
Policy Update Magnitude: 0.56393
Value Function Update Magnitude: 0.41095

Collected Steps per Second: 14,291.66367
Overall Steps per Second: 6,660.16754

Timestep Collection Time: 3.49952
Timestep Consumption Time: 4.00990
PPO Batch Consumption Time: 0.49488
Total Iteration Time: 7.50942

Cumulative Model Updates: 7,650
Cumulative Timesteps: 63,821,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 63821292...
Checkpoint 63821292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02356
Policy Entropy: 4.30075
Value Function Loss: 0.02514

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.55668
Value Function Update Magnitude: 0.43300

Collected Steps per Second: 12,479.87056
Overall Steps per Second: 6,259.07627

Timestep Collection Time: 4.00725
Timestep Consumption Time: 3.98274
PPO Batch Consumption Time: 0.48802
Total Iteration Time: 7.99000

Cumulative Model Updates: 7,656
Cumulative Timesteps: 63,871,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07206
Policy Entropy: 4.29894
Value Function Loss: 0.02877

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.57855
Value Function Update Magnitude: 0.41040

Collected Steps per Second: 14,650.39365
Overall Steps per Second: 6,785.84267

Timestep Collection Time: 3.41397
Timestep Consumption Time: 3.95667
PPO Batch Consumption Time: 0.48626
Total Iteration Time: 7.37064

Cumulative Model Updates: 7,662
Cumulative Timesteps: 63,921,318

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 63921318...
Checkpoint 63921318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21660
Policy Entropy: 4.29673
Value Function Loss: 0.03018

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.60085
Value Function Update Magnitude: 0.41774

Collected Steps per Second: 14,241.98860
Overall Steps per Second: 6,461.58426

Timestep Collection Time: 3.51271
Timestep Consumption Time: 4.22966
PPO Batch Consumption Time: 0.53624
Total Iteration Time: 7.74237

Cumulative Model Updates: 7,668
Cumulative Timesteps: 63,971,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15986
Policy Entropy: 4.29347
Value Function Loss: 0.03030

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02771
Policy Update Magnitude: 0.59574
Value Function Update Magnitude: 0.39900

Collected Steps per Second: 14,000.15717
Overall Steps per Second: 6,491.42543

Timestep Collection Time: 3.57325
Timestep Consumption Time: 4.13323
PPO Batch Consumption Time: 0.52606
Total Iteration Time: 7.70647

Cumulative Model Updates: 7,674
Cumulative Timesteps: 64,021,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 64021372...
Checkpoint 64021372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05045
Policy Entropy: 4.29477
Value Function Loss: 0.02608

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02655
Policy Update Magnitude: 0.59186
Value Function Update Magnitude: 0.39388

Collected Steps per Second: 13,400.06351
Overall Steps per Second: 6,600.90929

Timestep Collection Time: 3.73133
Timestep Consumption Time: 3.84339
PPO Batch Consumption Time: 0.48666
Total Iteration Time: 7.57471

Cumulative Model Updates: 7,680
Cumulative Timesteps: 64,071,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02883
Policy Entropy: 4.29498
Value Function Loss: 0.03132

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.59579
Value Function Update Magnitude: 0.40061

Collected Steps per Second: 14,311.62347
Overall Steps per Second: 6,705.86096

Timestep Collection Time: 3.49534
Timestep Consumption Time: 3.96440
PPO Batch Consumption Time: 0.49898
Total Iteration Time: 7.45974

Cumulative Model Updates: 7,686
Cumulative Timesteps: 64,121,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 64121396...
Checkpoint 64121396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01138
Policy Entropy: 4.29882
Value Function Loss: 0.02837

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02848
Policy Update Magnitude: 0.62497
Value Function Update Magnitude: 0.40126

Collected Steps per Second: 14,107.23166
Overall Steps per Second: 6,589.78279

Timestep Collection Time: 3.54570
Timestep Consumption Time: 4.04484
PPO Batch Consumption Time: 0.49792
Total Iteration Time: 7.59054

Cumulative Model Updates: 7,692
Cumulative Timesteps: 64,171,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04419
Policy Entropy: 4.30146
Value Function Loss: 0.02966

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03615
Policy Update Magnitude: 0.62719
Value Function Update Magnitude: 0.43484

Collected Steps per Second: 13,740.64823
Overall Steps per Second: 6,535.04555

Timestep Collection Time: 3.64233
Timestep Consumption Time: 4.01607
PPO Batch Consumption Time: 0.50252
Total Iteration Time: 7.65840

Cumulative Model Updates: 7,698
Cumulative Timesteps: 64,221,464

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 64221464...
Checkpoint 64221464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.37562
Policy Entropy: 4.30935
Value Function Loss: 0.02700

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04054
Policy Update Magnitude: 0.59715
Value Function Update Magnitude: 0.41111

Collected Steps per Second: 15,079.47840
Overall Steps per Second: 6,516.71346

Timestep Collection Time: 3.31683
Timestep Consumption Time: 4.35821
PPO Batch Consumption Time: 0.55978
Total Iteration Time: 7.67503

Cumulative Model Updates: 7,704
Cumulative Timesteps: 64,271,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03198
Policy Entropy: 4.31291
Value Function Loss: 0.02965

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.03740
Policy Update Magnitude: 0.59416
Value Function Update Magnitude: 0.42267

Collected Steps per Second: 14,023.89484
Overall Steps per Second: 6,541.11528

Timestep Collection Time: 3.56705
Timestep Consumption Time: 4.08057
PPO Batch Consumption Time: 0.51510
Total Iteration Time: 7.64763

Cumulative Model Updates: 7,710
Cumulative Timesteps: 64,321,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 64321504...
Checkpoint 64321504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18267
Policy Entropy: 4.31631
Value Function Loss: 0.02837

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03299
Policy Update Magnitude: 0.59407
Value Function Update Magnitude: 0.40994

Collected Steps per Second: 14,586.85771
Overall Steps per Second: 6,536.47862

Timestep Collection Time: 3.42857
Timestep Consumption Time: 4.22265
PPO Batch Consumption Time: 0.55231
Total Iteration Time: 7.65121

Cumulative Model Updates: 7,716
Cumulative Timesteps: 64,371,516

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03667
Policy Entropy: 4.31408
Value Function Loss: 0.02836

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03315
Policy Update Magnitude: 0.56973
Value Function Update Magnitude: 0.40739

Collected Steps per Second: 14,181.98612
Overall Steps per Second: 6,444.41025

Timestep Collection Time: 3.52574
Timestep Consumption Time: 4.23323
PPO Batch Consumption Time: 0.53884
Total Iteration Time: 7.75897

Cumulative Model Updates: 7,722
Cumulative Timesteps: 64,421,518

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 64421518...
Checkpoint 64421518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.25204
Policy Entropy: 4.31638
Value Function Loss: 0.02425

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02626
Policy Update Magnitude: 0.56231
Value Function Update Magnitude: 0.38693

Collected Steps per Second: 14,369.36957
Overall Steps per Second: 6,645.87500

Timestep Collection Time: 3.48032
Timestep Consumption Time: 4.04465
PPO Batch Consumption Time: 0.50449
Total Iteration Time: 7.52497

Cumulative Model Updates: 7,728
Cumulative Timesteps: 64,471,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00212
Policy Entropy: 4.31228
Value Function Loss: 0.02690

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.55871
Value Function Update Magnitude: 0.39954

Collected Steps per Second: 14,763.73435
Overall Steps per Second: 6,865.06580

Timestep Collection Time: 3.38763
Timestep Consumption Time: 3.89767
PPO Batch Consumption Time: 0.48702
Total Iteration Time: 7.28529

Cumulative Model Updates: 7,734
Cumulative Timesteps: 64,521,542

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 64521542...
Checkpoint 64521542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00310
Policy Entropy: 4.31012
Value Function Loss: 0.03008

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01726
Policy Update Magnitude: 0.58904
Value Function Update Magnitude: 0.41735

Collected Steps per Second: 14,072.61366
Overall Steps per Second: 6,676.66546

Timestep Collection Time: 3.55328
Timestep Consumption Time: 3.93608
PPO Batch Consumption Time: 0.49100
Total Iteration Time: 7.48937

Cumulative Model Updates: 7,740
Cumulative Timesteps: 64,571,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14975
Policy Entropy: 4.30047
Value Function Loss: 0.03586

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03088
Policy Update Magnitude: 0.60303
Value Function Update Magnitude: 0.41990

Collected Steps per Second: 14,352.99418
Overall Steps per Second: 6,762.67253

Timestep Collection Time: 3.48457
Timestep Consumption Time: 3.91103
PPO Batch Consumption Time: 0.50041
Total Iteration Time: 7.39560

Cumulative Model Updates: 7,746
Cumulative Timesteps: 64,621,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 64621560...
Checkpoint 64621560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07446
Policy Entropy: 4.29709
Value Function Loss: 0.04184

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04165
Policy Update Magnitude: 0.62997
Value Function Update Magnitude: 0.43546

Collected Steps per Second: 14,895.07683
Overall Steps per Second: 6,596.95406

Timestep Collection Time: 3.35749
Timestep Consumption Time: 4.22329
PPO Batch Consumption Time: 0.52843
Total Iteration Time: 7.58077

Cumulative Model Updates: 7,752
Cumulative Timesteps: 64,671,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09459
Policy Entropy: 4.29177
Value Function Loss: 0.04360

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04017
Policy Update Magnitude: 0.65709
Value Function Update Magnitude: 0.43561

Collected Steps per Second: 14,098.68641
Overall Steps per Second: 6,470.08448

Timestep Collection Time: 3.54870
Timestep Consumption Time: 4.18412
PPO Batch Consumption Time: 0.54370
Total Iteration Time: 7.73282

Cumulative Model Updates: 7,758
Cumulative Timesteps: 64,721,602

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 64721602...
Checkpoint 64721602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16650
Policy Entropy: 4.28897
Value Function Loss: 0.04935

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05306
Policy Update Magnitude: 0.67742
Value Function Update Magnitude: 0.39212

Collected Steps per Second: 13,522.14777
Overall Steps per Second: 6,276.17344

Timestep Collection Time: 3.69897
Timestep Consumption Time: 4.27054
PPO Batch Consumption Time: 0.54309
Total Iteration Time: 7.96951

Cumulative Model Updates: 7,764
Cumulative Timesteps: 64,771,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14721
Policy Entropy: 4.28943
Value Function Loss: 0.05676

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.71388
Value Function Update Magnitude: 0.40352

Collected Steps per Second: 13,790.85475
Overall Steps per Second: 6,401.22805

Timestep Collection Time: 3.62632
Timestep Consumption Time: 4.18625
PPO Batch Consumption Time: 0.52821
Total Iteration Time: 7.81256

Cumulative Model Updates: 7,770
Cumulative Timesteps: 64,821,630

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 64821630...
Checkpoint 64821630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03223
Policy Entropy: 4.28926
Value Function Loss: 0.05394

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.06817
Policy Update Magnitude: 0.69892
Value Function Update Magnitude: 0.42325

Collected Steps per Second: 14,342.27918
Overall Steps per Second: 6,544.13905

Timestep Collection Time: 3.48661
Timestep Consumption Time: 4.15473
PPO Batch Consumption Time: 0.52056
Total Iteration Time: 7.64134

Cumulative Model Updates: 7,776
Cumulative Timesteps: 64,871,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.28563
Policy Entropy: 4.29063
Value Function Loss: 0.05668

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.05608
Policy Update Magnitude: 0.68985
Value Function Update Magnitude: 0.39108

Collected Steps per Second: 14,210.24960
Overall Steps per Second: 6,493.41900

Timestep Collection Time: 3.52042
Timestep Consumption Time: 4.18369
PPO Batch Consumption Time: 0.52865
Total Iteration Time: 7.70411

Cumulative Model Updates: 7,782
Cumulative Timesteps: 64,921,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 64921662...
Checkpoint 64921662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03097
Policy Entropy: 4.28922
Value Function Loss: 0.04723

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04916
Policy Update Magnitude: 0.67066
Value Function Update Magnitude: 0.39032

Collected Steps per Second: 13,966.97376
Overall Steps per Second: 6,485.88447

Timestep Collection Time: 3.58145
Timestep Consumption Time: 4.13099
PPO Batch Consumption Time: 0.53151
Total Iteration Time: 7.71244

Cumulative Model Updates: 7,788
Cumulative Timesteps: 64,971,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03056
Policy Entropy: 4.29280
Value Function Loss: 0.05375

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05275
Policy Update Magnitude: 0.65420
Value Function Update Magnitude: 0.37294

Collected Steps per Second: 14,228.85440
Overall Steps per Second: 6,483.06270

Timestep Collection Time: 3.51413
Timestep Consumption Time: 4.19859
PPO Batch Consumption Time: 0.53257
Total Iteration Time: 7.71271

Cumulative Model Updates: 7,794
Cumulative Timesteps: 65,021,686

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 65021686...
Checkpoint 65021686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09469
Policy Entropy: 4.29674
Value Function Loss: 0.04619

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04686
Policy Update Magnitude: 0.65127
Value Function Update Magnitude: 0.39570

Collected Steps per Second: 13,910.79403
Overall Steps per Second: 6,427.71098

Timestep Collection Time: 3.59663
Timestep Consumption Time: 4.18717
PPO Batch Consumption Time: 0.53439
Total Iteration Time: 7.78380

Cumulative Model Updates: 7,800
Cumulative Timesteps: 65,071,718

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09346
Policy Entropy: 4.30316
Value Function Loss: 0.04264

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04060
Policy Update Magnitude: 0.62781
Value Function Update Magnitude: 0.40986

Collected Steps per Second: 14,358.97542
Overall Steps per Second: 6,547.76402

Timestep Collection Time: 3.48312
Timestep Consumption Time: 4.15522
PPO Batch Consumption Time: 0.51963
Total Iteration Time: 7.63833

Cumulative Model Updates: 7,806
Cumulative Timesteps: 65,121,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 65121732...
Checkpoint 65121732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02098
Policy Entropy: 4.30501
Value Function Loss: 0.03486

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03222
Policy Update Magnitude: 0.59750
Value Function Update Magnitude: 0.38754

Collected Steps per Second: 13,827.60919
Overall Steps per Second: 6,356.09962

Timestep Collection Time: 3.61827
Timestep Consumption Time: 4.25323
PPO Batch Consumption Time: 0.53791
Total Iteration Time: 7.87149

Cumulative Model Updates: 7,812
Cumulative Timesteps: 65,171,764

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13091
Policy Entropy: 4.30773
Value Function Loss: 0.03625

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03459
Policy Update Magnitude: 0.59365
Value Function Update Magnitude: 0.40465

Collected Steps per Second: 14,144.27637
Overall Steps per Second: 6,533.73278

Timestep Collection Time: 3.53712
Timestep Consumption Time: 4.12007
PPO Batch Consumption Time: 0.52898
Total Iteration Time: 7.65718

Cumulative Model Updates: 7,818
Cumulative Timesteps: 65,221,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 65221794...
Checkpoint 65221794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15267
Policy Entropy: 4.30709
Value Function Loss: 0.03380

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03199
Policy Update Magnitude: 0.59523
Value Function Update Magnitude: 0.42015

Collected Steps per Second: 14,145.92840
Overall Steps per Second: 6,362.58835

Timestep Collection Time: 3.53515
Timestep Consumption Time: 4.32454
PPO Batch Consumption Time: 0.53833
Total Iteration Time: 7.85969

Cumulative Model Updates: 7,824
Cumulative Timesteps: 65,271,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16874
Policy Entropy: 4.29902
Value Function Loss: 0.03218

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02398
Policy Update Magnitude: 0.58343
Value Function Update Magnitude: 0.40389

Collected Steps per Second: 14,541.11439
Overall Steps per Second: 6,775.37663

Timestep Collection Time: 3.44018
Timestep Consumption Time: 3.94303
PPO Batch Consumption Time: 0.49998
Total Iteration Time: 7.38321

Cumulative Model Updates: 7,830
Cumulative Timesteps: 65,321,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 65321826...
Checkpoint 65321826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.26674
Policy Entropy: 4.29047
Value Function Loss: 0.04299

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.62539
Value Function Update Magnitude: 0.41410

Collected Steps per Second: 13,991.72225
Overall Steps per Second: 6,669.10983

Timestep Collection Time: 3.57426
Timestep Consumption Time: 3.92450
PPO Batch Consumption Time: 0.48363
Total Iteration Time: 7.49875

Cumulative Model Updates: 7,836
Cumulative Timesteps: 65,371,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.23784
Policy Entropy: 4.29171
Value Function Loss: 0.04385

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03270
Policy Update Magnitude: 0.64442
Value Function Update Magnitude: 0.40681

Collected Steps per Second: 14,386.24099
Overall Steps per Second: 6,702.77520

Timestep Collection Time: 3.47582
Timestep Consumption Time: 3.98437
PPO Batch Consumption Time: 0.49767
Total Iteration Time: 7.46019

Cumulative Model Updates: 7,842
Cumulative Timesteps: 65,421,840

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 65421840...
Checkpoint 65421840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10990
Policy Entropy: 4.30113
Value Function Loss: 0.03885

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02802
Policy Update Magnitude: 0.63394
Value Function Update Magnitude: 0.41334

Collected Steps per Second: 14,368.68915
Overall Steps per Second: 6,753.36045

Timestep Collection Time: 3.48062
Timestep Consumption Time: 3.92487
PPO Batch Consumption Time: 0.49544
Total Iteration Time: 7.40550

Cumulative Model Updates: 7,848
Cumulative Timesteps: 65,471,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07468
Policy Entropy: 4.30445
Value Function Loss: 0.02515

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02298
Policy Update Magnitude: 0.59980
Value Function Update Magnitude: 0.39871

Collected Steps per Second: 15,027.82988
Overall Steps per Second: 6,816.96616

Timestep Collection Time: 3.32783
Timestep Consumption Time: 4.00828
PPO Batch Consumption Time: 0.50373
Total Iteration Time: 7.33611

Cumulative Model Updates: 7,854
Cumulative Timesteps: 65,521,862

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 65521862...
Checkpoint 65521862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04977
Policy Entropy: 4.30272
Value Function Loss: 0.02340

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01934
Policy Update Magnitude: 0.56879
Value Function Update Magnitude: 0.38640

Collected Steps per Second: 14,754.79598
Overall Steps per Second: 7,060.84291

Timestep Collection Time: 3.39022
Timestep Consumption Time: 3.69420
PPO Batch Consumption Time: 0.48301
Total Iteration Time: 7.08442

Cumulative Model Updates: 7,860
Cumulative Timesteps: 65,571,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09949
Policy Entropy: 4.30145
Value Function Loss: 0.02304

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02154
Policy Update Magnitude: 0.56914
Value Function Update Magnitude: 0.37505

Collected Steps per Second: 14,432.05700
Overall Steps per Second: 6,810.08637

Timestep Collection Time: 3.46520
Timestep Consumption Time: 3.87832
PPO Batch Consumption Time: 0.48656
Total Iteration Time: 7.34352

Cumulative Model Updates: 7,866
Cumulative Timesteps: 65,621,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 65621894...
Checkpoint 65621894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.35385
Policy Entropy: 4.30405
Value Function Loss: 0.02477

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02390
Policy Update Magnitude: 0.57221
Value Function Update Magnitude: 0.38452

Collected Steps per Second: 14,459.81799
Overall Steps per Second: 6,767.46110

Timestep Collection Time: 3.45896
Timestep Consumption Time: 3.93169
PPO Batch Consumption Time: 0.48497
Total Iteration Time: 7.39066

Cumulative Model Updates: 7,872
Cumulative Timesteps: 65,671,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06755
Policy Entropy: 4.30138
Value Function Loss: 0.02519

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01932
Policy Update Magnitude: 0.56910
Value Function Update Magnitude: 0.37500

Collected Steps per Second: 15,318.74420
Overall Steps per Second: 7,159.14511

Timestep Collection Time: 3.26437
Timestep Consumption Time: 3.72055
PPO Batch Consumption Time: 0.47424
Total Iteration Time: 6.98491

Cumulative Model Updates: 7,878
Cumulative Timesteps: 65,721,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 65721916...
Checkpoint 65721916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05247
Policy Entropy: 4.29781
Value Function Loss: 0.03265

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02264
Policy Update Magnitude: 0.58177
Value Function Update Magnitude: 0.40375

Collected Steps per Second: 14,310.86477
Overall Steps per Second: 6,793.08495

Timestep Collection Time: 3.49525
Timestep Consumption Time: 3.86812
PPO Batch Consumption Time: 0.47294
Total Iteration Time: 7.36337

Cumulative Model Updates: 7,884
Cumulative Timesteps: 65,771,936

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03686
Policy Entropy: 4.29531
Value Function Loss: 0.03178

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02337
Policy Update Magnitude: 0.61226
Value Function Update Magnitude: 0.41715

Collected Steps per Second: 14,469.34066
Overall Steps per Second: 6,917.57788

Timestep Collection Time: 3.45752
Timestep Consumption Time: 3.77449
PPO Batch Consumption Time: 0.47677
Total Iteration Time: 7.23201

Cumulative Model Updates: 7,890
Cumulative Timesteps: 65,821,964

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 65821964...
Checkpoint 65821964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08110
Policy Entropy: 4.29697
Value Function Loss: 0.02801

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.60947
Value Function Update Magnitude: 0.42458

Collected Steps per Second: 14,595.97153
Overall Steps per Second: 6,750.74996

Timestep Collection Time: 3.42711
Timestep Consumption Time: 3.98273
PPO Batch Consumption Time: 0.49659
Total Iteration Time: 7.40984

Cumulative Model Updates: 7,896
Cumulative Timesteps: 65,871,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05265
Policy Entropy: 4.29956
Value Function Loss: 0.02845

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02119
Policy Update Magnitude: 0.58930
Value Function Update Magnitude: 0.43203

Collected Steps per Second: 14,416.80791
Overall Steps per Second: 6,662.27433

Timestep Collection Time: 3.47067
Timestep Consumption Time: 4.03968
PPO Batch Consumption Time: 0.51834
Total Iteration Time: 7.51035

Cumulative Model Updates: 7,902
Cumulative Timesteps: 65,922,022

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 65922022...
Checkpoint 65922022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07323
Policy Entropy: 4.29853
Value Function Loss: 0.02676

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02076
Policy Update Magnitude: 0.59710
Value Function Update Magnitude: 0.43078

Collected Steps per Second: 13,821.73749
Overall Steps per Second: 6,561.90097

Timestep Collection Time: 3.61966
Timestep Consumption Time: 4.00465
PPO Batch Consumption Time: 0.49615
Total Iteration Time: 7.62431

Cumulative Model Updates: 7,908
Cumulative Timesteps: 65,972,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19338
Policy Entropy: 4.29654
Value Function Loss: 0.03185

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02568
Policy Update Magnitude: 0.62995
Value Function Update Magnitude: 0.44762

Collected Steps per Second: 14,129.30469
Overall Steps per Second: 6,792.96695

Timestep Collection Time: 3.53945
Timestep Consumption Time: 3.82257
PPO Batch Consumption Time: 0.48601
Total Iteration Time: 7.36203

Cumulative Model Updates: 7,914
Cumulative Timesteps: 66,022,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 66022062...
Checkpoint 66022062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15490
Policy Entropy: 4.29591
Value Function Loss: 0.03070

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02766
Policy Update Magnitude: 0.65240
Value Function Update Magnitude: 0.46817

Collected Steps per Second: 14,244.29354
Overall Steps per Second: 6,787.30308

Timestep Collection Time: 3.51032
Timestep Consumption Time: 3.85667
PPO Batch Consumption Time: 0.48138
Total Iteration Time: 7.36699

Cumulative Model Updates: 7,920
Cumulative Timesteps: 66,072,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04593
Policy Entropy: 4.29441
Value Function Loss: 0.03343

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03142
Policy Update Magnitude: 0.67098
Value Function Update Magnitude: 0.46223

Collected Steps per Second: 14,296.78248
Overall Steps per Second: 6,791.36824

Timestep Collection Time: 3.49883
Timestep Consumption Time: 3.86670
PPO Batch Consumption Time: 0.47846
Total Iteration Time: 7.36553

Cumulative Model Updates: 7,926
Cumulative Timesteps: 66,122,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 66122086...
Checkpoint 66122086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15875
Policy Entropy: 4.29605
Value Function Loss: 0.02581

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.02952
Policy Update Magnitude: 0.63223
Value Function Update Magnitude: 0.43010

Collected Steps per Second: 14,045.34184
Overall Steps per Second: 6,663.81394

Timestep Collection Time: 3.56047
Timestep Consumption Time: 3.94394
PPO Batch Consumption Time: 0.49380
Total Iteration Time: 7.50441

Cumulative Model Updates: 7,932
Cumulative Timesteps: 66,172,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14214
Policy Entropy: 4.30133
Value Function Loss: 0.02168

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02420
Policy Update Magnitude: 0.56797
Value Function Update Magnitude: 0.38987

Collected Steps per Second: 14,080.32597
Overall Steps per Second: 6,593.20540

Timestep Collection Time: 3.55290
Timestep Consumption Time: 4.03461
PPO Batch Consumption Time: 0.49830
Total Iteration Time: 7.58751

Cumulative Model Updates: 7,938
Cumulative Timesteps: 66,222,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 66222120...
Checkpoint 66222120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00584
Policy Entropy: 4.30562
Value Function Loss: 0.02160

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02193
Policy Update Magnitude: 0.53396
Value Function Update Magnitude: 0.38011

Collected Steps per Second: 14,221.07599
Overall Steps per Second: 6,818.42083

Timestep Collection Time: 3.51605
Timestep Consumption Time: 3.81732
PPO Batch Consumption Time: 0.47968
Total Iteration Time: 7.33337

Cumulative Model Updates: 7,944
Cumulative Timesteps: 66,272,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19852
Policy Entropy: 4.30666
Value Function Loss: 0.02191

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.53890
Value Function Update Magnitude: 0.40537

Collected Steps per Second: 13,935.15394
Overall Steps per Second: 6,644.28256

Timestep Collection Time: 3.58862
Timestep Consumption Time: 3.93785
PPO Batch Consumption Time: 0.48331
Total Iteration Time: 7.52647

Cumulative Model Updates: 7,950
Cumulative Timesteps: 66,322,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 66322130...
Checkpoint 66322130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03080
Policy Entropy: 4.30177
Value Function Loss: 0.02439

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.01980
Policy Update Magnitude: 0.56917
Value Function Update Magnitude: 0.40490

Collected Steps per Second: 13,912.28469
Overall Steps per Second: 6,455.35563

Timestep Collection Time: 3.59567
Timestep Consumption Time: 4.15355
PPO Batch Consumption Time: 0.52289
Total Iteration Time: 7.74922

Cumulative Model Updates: 7,956
Cumulative Timesteps: 66,372,154

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11680
Policy Entropy: 4.30159
Value Function Loss: 0.02186

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.57857
Value Function Update Magnitude: 0.39648

Collected Steps per Second: 13,802.56804
Overall Steps per Second: 6,441.60667

Timestep Collection Time: 3.62454
Timestep Consumption Time: 4.14184
PPO Batch Consumption Time: 0.52084
Total Iteration Time: 7.76639

Cumulative Model Updates: 7,962
Cumulative Timesteps: 66,422,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 66422182...
Checkpoint 66422182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09904
Policy Entropy: 4.30268
Value Function Loss: 0.02159

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.56093
Value Function Update Magnitude: 0.39083

Collected Steps per Second: 13,699.65864
Overall Steps per Second: 6,226.14940

Timestep Collection Time: 3.65075
Timestep Consumption Time: 4.38215
PPO Batch Consumption Time: 0.55744
Total Iteration Time: 8.03289

Cumulative Model Updates: 7,968
Cumulative Timesteps: 66,472,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19287
Policy Entropy: 4.30163
Value Function Loss: 0.02870

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02150
Policy Update Magnitude: 0.58714
Value Function Update Magnitude: 0.41952

Collected Steps per Second: 13,791.44710
Overall Steps per Second: 6,396.49097

Timestep Collection Time: 3.62660
Timestep Consumption Time: 4.19269
PPO Batch Consumption Time: 0.53217
Total Iteration Time: 7.81929

Cumulative Model Updates: 7,974
Cumulative Timesteps: 66,522,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 66522212...
Checkpoint 66522212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09594
Policy Entropy: 4.30035
Value Function Loss: 0.03061

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03041
Policy Update Magnitude: 0.61595
Value Function Update Magnitude: 0.40597

Collected Steps per Second: 13,947.61051
Overall Steps per Second: 6,609.28462

Timestep Collection Time: 3.58570
Timestep Consumption Time: 3.98123
PPO Batch Consumption Time: 0.48828
Total Iteration Time: 7.56693

Cumulative Model Updates: 7,980
Cumulative Timesteps: 66,572,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00701
Policy Entropy: 4.29988
Value Function Loss: 0.03399

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.03701
Policy Update Magnitude: 0.60946
Value Function Update Magnitude: 0.39510

Collected Steps per Second: 14,372.39539
Overall Steps per Second: 6,710.94751

Timestep Collection Time: 3.47987
Timestep Consumption Time: 3.97273
PPO Batch Consumption Time: 0.50205
Total Iteration Time: 7.45260

Cumulative Model Updates: 7,986
Cumulative Timesteps: 66,622,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 66622238...
Checkpoint 66622238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00793
Policy Entropy: 4.30787
Value Function Loss: 0.02638

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 0.58562
Value Function Update Magnitude: 0.39934

Collected Steps per Second: 14,105.04531
Overall Steps per Second: 6,383.39226

Timestep Collection Time: 3.54625
Timestep Consumption Time: 4.28971
PPO Batch Consumption Time: 0.53366
Total Iteration Time: 7.83596

Cumulative Model Updates: 7,992
Cumulative Timesteps: 66,672,258

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08050
Policy Entropy: 4.30741
Value Function Loss: 0.02834

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02813
Policy Update Magnitude: 0.55587
Value Function Update Magnitude: 0.38527

Collected Steps per Second: 14,225.03268
Overall Steps per Second: 6,737.35414

Timestep Collection Time: 3.51563
Timestep Consumption Time: 3.90716
PPO Batch Consumption Time: 0.48305
Total Iteration Time: 7.42280

Cumulative Model Updates: 7,998
Cumulative Timesteps: 66,722,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 66722268...
Checkpoint 66722268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14686
Policy Entropy: 4.30761
Value Function Loss: 0.02816

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02684
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.37806

Collected Steps per Second: 14,432.05076
Overall Steps per Second: 6,739.27161

Timestep Collection Time: 3.46590
Timestep Consumption Time: 3.95627
PPO Batch Consumption Time: 0.49456
Total Iteration Time: 7.42217

Cumulative Model Updates: 8,004
Cumulative Timesteps: 66,772,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05046
Policy Entropy: 4.30263
Value Function Loss: 0.02762

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03079
Policy Update Magnitude: 0.58505
Value Function Update Magnitude: 0.37357

Collected Steps per Second: 14,175.73081
Overall Steps per Second: 6,676.75876

Timestep Collection Time: 3.52730
Timestep Consumption Time: 3.96167
PPO Batch Consumption Time: 0.48914
Total Iteration Time: 7.48896

Cumulative Model Updates: 8,010
Cumulative Timesteps: 66,822,290

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 66822290...
Checkpoint 66822290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02718
Policy Entropy: 4.30678
Value Function Loss: 0.02482

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02722
Policy Update Magnitude: 0.55265
Value Function Update Magnitude: 0.39498

Collected Steps per Second: 14,352.12105
Overall Steps per Second: 6,794.77515

Timestep Collection Time: 3.48562
Timestep Consumption Time: 3.87680
PPO Batch Consumption Time: 0.48394
Total Iteration Time: 7.36242

Cumulative Model Updates: 8,016
Cumulative Timesteps: 66,872,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04029
Policy Entropy: 4.31626
Value Function Loss: 0.01809

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02096
Policy Update Magnitude: 0.50988
Value Function Update Magnitude: 0.35906

Collected Steps per Second: 14,295.21975
Overall Steps per Second: 6,736.47141

Timestep Collection Time: 3.49949
Timestep Consumption Time: 3.92665
PPO Batch Consumption Time: 0.48635
Total Iteration Time: 7.42614

Cumulative Model Updates: 8,022
Cumulative Timesteps: 66,922,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 66922342...
Checkpoint 66922342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04479
Policy Entropy: 4.31881
Value Function Loss: 0.01945

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02071
Policy Update Magnitude: 0.48960
Value Function Update Magnitude: 0.36297

Collected Steps per Second: 14,285.78978
Overall Steps per Second: 6,779.94899

Timestep Collection Time: 3.50054
Timestep Consumption Time: 3.87533
PPO Batch Consumption Time: 0.48316
Total Iteration Time: 7.37587

Cumulative Model Updates: 8,028
Cumulative Timesteps: 66,972,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01642
Policy Entropy: 4.31884
Value Function Loss: 0.01494

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01647
Policy Update Magnitude: 0.47277
Value Function Update Magnitude: 0.35218

Collected Steps per Second: 14,440.27519
Overall Steps per Second: 6,711.43524

Timestep Collection Time: 3.46337
Timestep Consumption Time: 3.98839
PPO Batch Consumption Time: 0.49214
Total Iteration Time: 7.45176

Cumulative Model Updates: 8,034
Cumulative Timesteps: 67,022,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 67022362...
Checkpoint 67022362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00550
Policy Entropy: 4.31498
Value Function Loss: 0.02411

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01898
Policy Update Magnitude: 0.50137
Value Function Update Magnitude: 0.38166

Collected Steps per Second: 14,587.65929
Overall Steps per Second: 6,835.75611

Timestep Collection Time: 3.42824
Timestep Consumption Time: 3.88770
PPO Batch Consumption Time: 0.48675
Total Iteration Time: 7.31594

Cumulative Model Updates: 8,040
Cumulative Timesteps: 67,072,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04905
Policy Entropy: 4.31954
Value Function Loss: 0.02359

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02273
Policy Update Magnitude: 0.55870
Value Function Update Magnitude: 0.41661

Collected Steps per Second: 14,820.33104
Overall Steps per Second: 6,902.94878

Timestep Collection Time: 3.37536
Timestep Consumption Time: 3.87139
PPO Batch Consumption Time: 0.47893
Total Iteration Time: 7.24676

Cumulative Model Updates: 8,046
Cumulative Timesteps: 67,122,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 67122396...
Checkpoint 67122396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03611
Policy Entropy: 4.31716
Value Function Loss: 0.02933

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02206
Policy Update Magnitude: 0.56537
Value Function Update Magnitude: 0.39935

Collected Steps per Second: 14,039.38439
Overall Steps per Second: 6,772.81739

Timestep Collection Time: 3.56212
Timestep Consumption Time: 3.82181
PPO Batch Consumption Time: 0.47103
Total Iteration Time: 7.38393

Cumulative Model Updates: 8,052
Cumulative Timesteps: 67,172,406

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.37054
Policy Entropy: 4.31972
Value Function Loss: 0.02557

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02514
Policy Update Magnitude: 0.56006
Value Function Update Magnitude: 0.39447

Collected Steps per Second: 14,644.15768
Overall Steps per Second: 6,813.80918

Timestep Collection Time: 3.41583
Timestep Consumption Time: 3.92543
PPO Batch Consumption Time: 0.49003
Total Iteration Time: 7.34127

Cumulative Model Updates: 8,058
Cumulative Timesteps: 67,222,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 67222428...
Checkpoint 67222428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04424
Policy Entropy: 4.31992
Value Function Loss: 0.02875

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02252
Policy Update Magnitude: 0.54312
Value Function Update Magnitude: 0.38393

Collected Steps per Second: 14,074.59773
Overall Steps per Second: 6,634.95304

Timestep Collection Time: 3.55264
Timestep Consumption Time: 3.98351
PPO Batch Consumption Time: 0.49071
Total Iteration Time: 7.53615

Cumulative Model Updates: 8,064
Cumulative Timesteps: 67,272,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00000
Policy Entropy: 4.32282
Value Function Loss: 0.02535

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02529
Policy Update Magnitude: 0.52925
Value Function Update Magnitude: 0.38963

Collected Steps per Second: 14,879.63984
Overall Steps per Second: 6,872.31569

Timestep Collection Time: 3.36043
Timestep Consumption Time: 3.91543
PPO Batch Consumption Time: 0.48494
Total Iteration Time: 7.27586

Cumulative Model Updates: 8,070
Cumulative Timesteps: 67,322,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 67322432...
Checkpoint 67322432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02285
Policy Entropy: 4.31742
Value Function Loss: 0.03201

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02173
Policy Update Magnitude: 0.55608
Value Function Update Magnitude: 0.40156

Collected Steps per Second: 14,141.08006
Overall Steps per Second: 6,649.60284

Timestep Collection Time: 3.53750
Timestep Consumption Time: 3.98536
PPO Batch Consumption Time: 0.49414
Total Iteration Time: 7.52286

Cumulative Model Updates: 8,076
Cumulative Timesteps: 67,372,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01450
Policy Entropy: 4.31444
Value Function Loss: 0.03367

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.58203
Value Function Update Magnitude: 0.39795

Collected Steps per Second: 14,470.98848
Overall Steps per Second: 6,756.11215

Timestep Collection Time: 3.45547
Timestep Consumption Time: 3.94583
PPO Batch Consumption Time: 0.50006
Total Iteration Time: 7.40130

Cumulative Model Updates: 8,082
Cumulative Timesteps: 67,422,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 67422460...
Checkpoint 67422460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04731
Policy Entropy: 4.31030
Value Function Loss: 0.03281

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02538
Policy Update Magnitude: 0.57105
Value Function Update Magnitude: 0.37151

Collected Steps per Second: 14,206.26923
Overall Steps per Second: 6,748.02209

Timestep Collection Time: 3.52028
Timestep Consumption Time: 3.89078
PPO Batch Consumption Time: 0.48006
Total Iteration Time: 7.41106

Cumulative Model Updates: 8,088
Cumulative Timesteps: 67,472,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08727
Policy Entropy: 4.30823
Value Function Loss: 0.03258

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02550
Policy Update Magnitude: 0.56296
Value Function Update Magnitude: 0.42580

Collected Steps per Second: 14,389.81813
Overall Steps per Second: 6,869.08923

Timestep Collection Time: 3.47662
Timestep Consumption Time: 3.80644
PPO Batch Consumption Time: 0.46638
Total Iteration Time: 7.28306

Cumulative Model Updates: 8,094
Cumulative Timesteps: 67,522,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 67522498...
Checkpoint 67522498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.20962
Policy Entropy: 4.31365
Value Function Loss: 0.02434

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02362
Policy Update Magnitude: 0.56076
Value Function Update Magnitude: 0.41216

Collected Steps per Second: 14,168.17939
Overall Steps per Second: 6,824.24004

Timestep Collection Time: 3.52988
Timestep Consumption Time: 3.79870
PPO Batch Consumption Time: 0.48133
Total Iteration Time: 7.32858

Cumulative Model Updates: 8,100
Cumulative Timesteps: 67,572,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16180
Policy Entropy: 4.30922
Value Function Loss: 0.02996

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02390
Policy Update Magnitude: 0.55794
Value Function Update Magnitude: 0.38875

Collected Steps per Second: 14,479.98855
Overall Steps per Second: 6,757.50493

Timestep Collection Time: 3.45428
Timestep Consumption Time: 3.94756
PPO Batch Consumption Time: 0.48583
Total Iteration Time: 7.40184

Cumulative Model Updates: 8,106
Cumulative Timesteps: 67,622,528

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 67622528...
Checkpoint 67622528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04484
Policy Entropy: 4.30522
Value Function Loss: 0.02619

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02870
Policy Update Magnitude: 0.56653
Value Function Update Magnitude: 0.39177

Collected Steps per Second: 14,244.55750
Overall Steps per Second: 6,789.32106

Timestep Collection Time: 3.51180
Timestep Consumption Time: 3.85624
PPO Batch Consumption Time: 0.48513
Total Iteration Time: 7.36804

Cumulative Model Updates: 8,112
Cumulative Timesteps: 67,672,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05912
Policy Entropy: 4.30433
Value Function Loss: 0.02360

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 0.53695
Value Function Update Magnitude: 0.35147

Collected Steps per Second: 14,396.39628
Overall Steps per Second: 6,682.20790

Timestep Collection Time: 3.47490
Timestep Consumption Time: 4.01155
PPO Batch Consumption Time: 0.49612
Total Iteration Time: 7.48645

Cumulative Model Updates: 8,118
Cumulative Timesteps: 67,722,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 67722578...
Checkpoint 67722578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.23295
Policy Entropy: 4.30450
Value Function Loss: 0.02341

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02921
Policy Update Magnitude: 0.52509
Value Function Update Magnitude: 0.36234

Collected Steps per Second: 14,144.01755
Overall Steps per Second: 6,699.65534

Timestep Collection Time: 3.53577
Timestep Consumption Time: 3.92879
PPO Batch Consumption Time: 0.49664
Total Iteration Time: 7.46456

Cumulative Model Updates: 8,124
Cumulative Timesteps: 67,772,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06469
Policy Entropy: 4.30215
Value Function Loss: 0.02353

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.54466
Value Function Update Magnitude: 0.39266

Collected Steps per Second: 14,724.37364
Overall Steps per Second: 6,809.28493

Timestep Collection Time: 3.39627
Timestep Consumption Time: 3.94782
PPO Batch Consumption Time: 0.49179
Total Iteration Time: 7.34409

Cumulative Model Updates: 8,130
Cumulative Timesteps: 67,822,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 67822596...
Checkpoint 67822596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12482
Policy Entropy: 4.30092
Value Function Loss: 0.02913

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.03457
Policy Update Magnitude: 0.57228
Value Function Update Magnitude: 0.43360

Collected Steps per Second: 14,342.23596
Overall Steps per Second: 6,708.44041

Timestep Collection Time: 3.48718
Timestep Consumption Time: 3.96820
PPO Batch Consumption Time: 0.49852
Total Iteration Time: 7.45538

Cumulative Model Updates: 8,136
Cumulative Timesteps: 67,872,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15456
Policy Entropy: 4.30843
Value Function Loss: 0.02156

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.02869
Policy Update Magnitude: 0.57017
Value Function Update Magnitude: 0.41738

Collected Steps per Second: 14,528.64823
Overall Steps per Second: 6,846.49863

Timestep Collection Time: 3.44148
Timestep Consumption Time: 3.86153
PPO Batch Consumption Time: 0.48502
Total Iteration Time: 7.30300

Cumulative Model Updates: 8,142
Cumulative Timesteps: 67,922,610

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 67922610...
Checkpoint 67922610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06482
Policy Entropy: 4.30936
Value Function Loss: 0.01990

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02828
Policy Update Magnitude: 0.53303
Value Function Update Magnitude: 0.38148

Collected Steps per Second: 14,305.49826
Overall Steps per Second: 6,759.10762

Timestep Collection Time: 3.49670
Timestep Consumption Time: 3.90398
PPO Batch Consumption Time: 0.48100
Total Iteration Time: 7.40068

Cumulative Model Updates: 8,148
Cumulative Timesteps: 67,972,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05989
Policy Entropy: 4.31247
Value Function Loss: 0.02288

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.54904
Value Function Update Magnitude: 0.37529

Collected Steps per Second: 14,797.86872
Overall Steps per Second: 6,827.67084

Timestep Collection Time: 3.38022
Timestep Consumption Time: 3.94585
PPO Batch Consumption Time: 0.49447
Total Iteration Time: 7.32607

Cumulative Model Updates: 8,154
Cumulative Timesteps: 68,022,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 68022652...
Checkpoint 68022652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08359
Policy Entropy: 4.31208
Value Function Loss: 0.02558

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.56699
Value Function Update Magnitude: 0.38790

Collected Steps per Second: 14,561.20485
Overall Steps per Second: 6,790.49468

Timestep Collection Time: 3.43516
Timestep Consumption Time: 3.93102
PPO Batch Consumption Time: 0.49173
Total Iteration Time: 7.36618

Cumulative Model Updates: 8,160
Cumulative Timesteps: 68,072,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04888
Policy Entropy: 4.31094
Value Function Loss: 0.02469

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02696
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.37466

Collected Steps per Second: 14,514.86186
Overall Steps per Second: 6,886.35114

Timestep Collection Time: 3.44543
Timestep Consumption Time: 3.81676
PPO Batch Consumption Time: 0.47054
Total Iteration Time: 7.26219

Cumulative Model Updates: 8,166
Cumulative Timesteps: 68,122,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 68122682...
Checkpoint 68122682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03134
Policy Entropy: 4.31447
Value Function Loss: 0.01937

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02424
Policy Update Magnitude: 0.50931
Value Function Update Magnitude: 0.31419

Collected Steps per Second: 14,146.48525
Overall Steps per Second: 6,708.29056

Timestep Collection Time: 3.53530
Timestep Consumption Time: 3.91996
PPO Batch Consumption Time: 0.50134
Total Iteration Time: 7.45525

Cumulative Model Updates: 8,172
Cumulative Timesteps: 68,172,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08836
Policy Entropy: 4.31270
Value Function Loss: 0.01824

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01740
Policy Update Magnitude: 0.49008
Value Function Update Magnitude: 0.31865

Collected Steps per Second: 14,499.60241
Overall Steps per Second: 6,786.87632

Timestep Collection Time: 3.44989
Timestep Consumption Time: 3.92051
PPO Batch Consumption Time: 0.47906
Total Iteration Time: 7.37040

Cumulative Model Updates: 8,178
Cumulative Timesteps: 68,222,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 68222716...
Checkpoint 68222716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.19530
Policy Entropy: 4.31746
Value Function Loss: 0.01965

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02026
Policy Update Magnitude: 0.51843
Value Function Update Magnitude: 0.36788

Collected Steps per Second: 14,563.19088
Overall Steps per Second: 6,821.80872

Timestep Collection Time: 3.43496
Timestep Consumption Time: 3.89799
PPO Batch Consumption Time: 0.49390
Total Iteration Time: 7.33295

Cumulative Model Updates: 8,184
Cumulative Timesteps: 68,272,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02877
Policy Entropy: 4.31475
Value Function Loss: 0.02484

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02038
Policy Update Magnitude: 0.55058
Value Function Update Magnitude: 0.39691

Collected Steps per Second: 14,536.67770
Overall Steps per Second: 6,765.46096

Timestep Collection Time: 3.44013
Timestep Consumption Time: 3.95154
PPO Batch Consumption Time: 0.49193
Total Iteration Time: 7.39166

Cumulative Model Updates: 8,190
Cumulative Timesteps: 68,322,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 68322748...
Checkpoint 68322748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16192
Policy Entropy: 4.31568
Value Function Loss: 0.02664

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02572
Policy Update Magnitude: 0.59136
Value Function Update Magnitude: 0.41964

Collected Steps per Second: 14,273.01008
Overall Steps per Second: 6,738.14434

Timestep Collection Time: 3.50368
Timestep Consumption Time: 3.91795
PPO Batch Consumption Time: 0.49233
Total Iteration Time: 7.42163

Cumulative Model Updates: 8,196
Cumulative Timesteps: 68,372,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02563
Policy Entropy: 4.31628
Value Function Loss: 0.02613

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02250
Policy Update Magnitude: 0.57758
Value Function Update Magnitude: 0.41406

Collected Steps per Second: 14,674.74512
Overall Steps per Second: 6,825.00539

Timestep Collection Time: 3.40844
Timestep Consumption Time: 3.92020
PPO Batch Consumption Time: 0.48490
Total Iteration Time: 7.32864

Cumulative Model Updates: 8,202
Cumulative Timesteps: 68,422,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 68422774...
Checkpoint 68422774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03163
Policy Entropy: 4.31855
Value Function Loss: 0.02546

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.01985
Policy Update Magnitude: 0.59193
Value Function Update Magnitude: 0.45216

Collected Steps per Second: 14,444.15705
Overall Steps per Second: 6,706.56575

Timestep Collection Time: 3.46368
Timestep Consumption Time: 3.99617
PPO Batch Consumption Time: 0.49491
Total Iteration Time: 7.45985

Cumulative Model Updates: 8,208
Cumulative Timesteps: 68,472,804

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02571
Policy Entropy: 4.31733
Value Function Loss: 0.02583

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02083
Policy Update Magnitude: 0.61412
Value Function Update Magnitude: 0.46554

Collected Steps per Second: 14,443.69089
Overall Steps per Second: 6,800.43529

Timestep Collection Time: 3.46463
Timestep Consumption Time: 3.89402
PPO Batch Consumption Time: 0.48869
Total Iteration Time: 7.35865

Cumulative Model Updates: 8,214
Cumulative Timesteps: 68,522,846

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 68522846...
Checkpoint 68522846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07941
Policy Entropy: 4.31936
Value Function Loss: 0.02412

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.60283
Value Function Update Magnitude: 0.41725

Collected Steps per Second: 14,254.82666
Overall Steps per Second: 6,724.66911

Timestep Collection Time: 3.50899
Timestep Consumption Time: 3.92930
PPO Batch Consumption Time: 0.48735
Total Iteration Time: 7.43828

Cumulative Model Updates: 8,220
Cumulative Timesteps: 68,572,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05542
Policy Entropy: 4.31891
Value Function Loss: 0.02670

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02331
Policy Update Magnitude: 0.60407
Value Function Update Magnitude: 0.38075

Collected Steps per Second: 14,401.24777
Overall Steps per Second: 6,766.90737

Timestep Collection Time: 3.47359
Timestep Consumption Time: 3.91886
PPO Batch Consumption Time: 0.48801
Total Iteration Time: 7.39245

Cumulative Model Updates: 8,226
Cumulative Timesteps: 68,622,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 68622890...
Checkpoint 68622890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15391
Policy Entropy: 4.31746
Value Function Loss: 0.02934

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02537
Policy Update Magnitude: 0.59564
Value Function Update Magnitude: 0.35944

Collected Steps per Second: 14,787.64804
Overall Steps per Second: 6,804.64666

Timestep Collection Time: 3.38120
Timestep Consumption Time: 3.96672
PPO Batch Consumption Time: 0.49684
Total Iteration Time: 7.34792

Cumulative Model Updates: 8,232
Cumulative Timesteps: 68,672,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07416
Policy Entropy: 4.31322
Value Function Loss: 0.03362

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02817
Policy Update Magnitude: 0.61542
Value Function Update Magnitude: 0.38598

Collected Steps per Second: 14,535.19293
Overall Steps per Second: 6,822.07737

Timestep Collection Time: 3.44089
Timestep Consumption Time: 3.89031
PPO Batch Consumption Time: 0.47247
Total Iteration Time: 7.33120

Cumulative Model Updates: 8,238
Cumulative Timesteps: 68,722,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 68722904...
Checkpoint 68722904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04057
Policy Entropy: 4.30827
Value Function Loss: 0.03964

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02605
Policy Update Magnitude: 0.64828
Value Function Update Magnitude: 0.41404

Collected Steps per Second: 14,352.18652
Overall Steps per Second: 6,835.90718

Timestep Collection Time: 3.48560
Timestep Consumption Time: 3.83252
PPO Batch Consumption Time: 0.48251
Total Iteration Time: 7.31812

Cumulative Model Updates: 8,244
Cumulative Timesteps: 68,772,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06438
Policy Entropy: 4.30803
Value Function Loss: 0.03548

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03024
Policy Update Magnitude: 0.65613
Value Function Update Magnitude: 0.44160

Collected Steps per Second: 14,648.44479
Overall Steps per Second: 6,855.83971

Timestep Collection Time: 3.41483
Timestep Consumption Time: 3.88143
PPO Batch Consumption Time: 0.47444
Total Iteration Time: 7.29626

Cumulative Model Updates: 8,250
Cumulative Timesteps: 68,822,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 68822952...
Checkpoint 68822952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05177
Policy Entropy: 4.31206
Value Function Loss: 0.03215

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03209
Policy Update Magnitude: 0.65575
Value Function Update Magnitude: 0.41179

Collected Steps per Second: 14,344.59919
Overall Steps per Second: 6,765.95276

Timestep Collection Time: 3.48717
Timestep Consumption Time: 3.90603
PPO Batch Consumption Time: 0.49270
Total Iteration Time: 7.39319

Cumulative Model Updates: 8,256
Cumulative Timesteps: 68,872,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01378
Policy Entropy: 4.31970
Value Function Loss: 0.02512

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02023
Policy Update Magnitude: 0.61027
Value Function Update Magnitude: 0.40853

Collected Steps per Second: 14,533.91686
Overall Steps per Second: 6,827.38210

Timestep Collection Time: 3.44257
Timestep Consumption Time: 3.88586
PPO Batch Consumption Time: 0.48513
Total Iteration Time: 7.32843

Cumulative Model Updates: 8,262
Cumulative Timesteps: 68,923,008

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 68923008...
Checkpoint 68923008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01337
Policy Entropy: 4.31153
Value Function Loss: 0.03125

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.61055
Value Function Update Magnitude: 0.41750

Collected Steps per Second: 14,217.63183
Overall Steps per Second: 6,708.43499

Timestep Collection Time: 3.51760
Timestep Consumption Time: 3.93749
PPO Batch Consumption Time: 0.49088
Total Iteration Time: 7.45509

Cumulative Model Updates: 8,268
Cumulative Timesteps: 68,973,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11595
Policy Entropy: 4.31088
Value Function Loss: 0.03132

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03045
Policy Update Magnitude: 0.62966
Value Function Update Magnitude: 0.43551

Collected Steps per Second: 14,392.73908
Overall Steps per Second: 6,811.79184

Timestep Collection Time: 3.47467
Timestep Consumption Time: 3.86701
PPO Batch Consumption Time: 0.48435
Total Iteration Time: 7.34168

Cumulative Model Updates: 8,274
Cumulative Timesteps: 69,023,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 69023030...
Checkpoint 69023030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05108
Policy Entropy: 4.30864
Value Function Loss: 0.03841

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02768
Policy Update Magnitude: 0.64663
Value Function Update Magnitude: 0.42328

Collected Steps per Second: 14,419.70168
Overall Steps per Second: 6,752.44607

Timestep Collection Time: 3.46970
Timestep Consumption Time: 3.93977
PPO Batch Consumption Time: 0.48369
Total Iteration Time: 7.40946

Cumulative Model Updates: 8,280
Cumulative Timesteps: 69,073,062

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09347
Policy Entropy: 4.30811
Value Function Loss: 0.03601

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.64595
Value Function Update Magnitude: 0.37183

Collected Steps per Second: 14,491.12736
Overall Steps per Second: 6,755.20109

Timestep Collection Time: 3.45149
Timestep Consumption Time: 3.95258
PPO Batch Consumption Time: 0.48619
Total Iteration Time: 7.40407

Cumulative Model Updates: 8,286
Cumulative Timesteps: 69,123,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 69123078...
Checkpoint 69123078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11857
Policy Entropy: 4.30399
Value Function Loss: 0.03616

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03520
Policy Update Magnitude: 0.61816
Value Function Update Magnitude: 0.35092

Collected Steps per Second: 14,642.47670
Overall Steps per Second: 6,696.00641

Timestep Collection Time: 3.41677
Timestep Consumption Time: 4.05485
PPO Batch Consumption Time: 0.50762
Total Iteration Time: 7.47162

Cumulative Model Updates: 8,292
Cumulative Timesteps: 69,173,108

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00147
Policy Entropy: 4.30812
Value Function Loss: 0.02778

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03007
Policy Update Magnitude: 0.58690
Value Function Update Magnitude: 0.36202

Collected Steps per Second: 14,517.86894
Overall Steps per Second: 6,787.44819

Timestep Collection Time: 3.44596
Timestep Consumption Time: 3.92470
PPO Batch Consumption Time: 0.48802
Total Iteration Time: 7.37066

Cumulative Model Updates: 8,298
Cumulative Timesteps: 69,223,136

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 69223136...
Checkpoint 69223136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17899
Policy Entropy: 4.30546
Value Function Loss: 0.02911

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.57232
Value Function Update Magnitude: 0.39376

Collected Steps per Second: 14,439.34458
Overall Steps per Second: 6,773.52426

Timestep Collection Time: 3.46609
Timestep Consumption Time: 3.92268
PPO Batch Consumption Time: 0.50028
Total Iteration Time: 7.38877

Cumulative Model Updates: 8,304
Cumulative Timesteps: 69,273,184

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12888
Policy Entropy: 4.30271
Value Function Loss: 0.02770

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02916
Policy Update Magnitude: 0.59691
Value Function Update Magnitude: 0.39536

Collected Steps per Second: 14,352.51822
Overall Steps per Second: 6,770.35103

Timestep Collection Time: 3.48510
Timestep Consumption Time: 3.90299
PPO Batch Consumption Time: 0.48339
Total Iteration Time: 7.38810

Cumulative Model Updates: 8,310
Cumulative Timesteps: 69,323,204

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 69323204...
Checkpoint 69323204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02561
Policy Entropy: 4.30570
Value Function Loss: 0.02631

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02587
Policy Update Magnitude: 0.60043
Value Function Update Magnitude: 0.39259

Collected Steps per Second: 13,868.64479
Overall Steps per Second: 6,732.04606

Timestep Collection Time: 3.60626
Timestep Consumption Time: 3.82298
PPO Batch Consumption Time: 0.48151
Total Iteration Time: 7.42924

Cumulative Model Updates: 8,316
Cumulative Timesteps: 69,373,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04770
Policy Entropy: 4.30736
Value Function Loss: 0.02256

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.58519
Value Function Update Magnitude: 0.39420

Collected Steps per Second: 14,424.83293
Overall Steps per Second: 6,768.17367

Timestep Collection Time: 3.46805
Timestep Consumption Time: 3.92331
PPO Batch Consumption Time: 0.48638
Total Iteration Time: 7.39136

Cumulative Model Updates: 8,322
Cumulative Timesteps: 69,423,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 69423244...
Checkpoint 69423244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03445
Policy Entropy: 4.30460
Value Function Loss: 0.01957

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.56781
Value Function Update Magnitude: 0.38684

Collected Steps per Second: 14,187.19666
Overall Steps per Second: 6,596.81177

Timestep Collection Time: 3.52445
Timestep Consumption Time: 4.05528
PPO Batch Consumption Time: 0.51091
Total Iteration Time: 7.57972

Cumulative Model Updates: 8,328
Cumulative Timesteps: 69,473,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02438
Policy Entropy: 4.30678
Value Function Loss: 0.02298

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.01983
Policy Update Magnitude: 0.54496
Value Function Update Magnitude: 0.38267

Collected Steps per Second: 14,444.39926
Overall Steps per Second: 6,671.97614

Timestep Collection Time: 3.46224
Timestep Consumption Time: 4.03329
PPO Batch Consumption Time: 0.51846
Total Iteration Time: 7.49553

Cumulative Model Updates: 8,334
Cumulative Timesteps: 69,523,256

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 69523256...
Checkpoint 69523256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01682
Policy Entropy: 4.30867
Value Function Loss: 0.02164

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02098
Policy Update Magnitude: 0.55912
Value Function Update Magnitude: 0.36971

Collected Steps per Second: 13,719.21983
Overall Steps per Second: 6,617.47337

Timestep Collection Time: 3.64613
Timestep Consumption Time: 3.91295
PPO Batch Consumption Time: 0.48711
Total Iteration Time: 7.55908

Cumulative Model Updates: 8,340
Cumulative Timesteps: 69,573,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14317
Policy Entropy: 4.31041
Value Function Loss: 0.02158

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02212
Policy Update Magnitude: 0.55394
Value Function Update Magnitude: 0.40278

Collected Steps per Second: 13,657.99574
Overall Steps per Second: 6,542.62338

Timestep Collection Time: 3.66364
Timestep Consumption Time: 3.98436
PPO Batch Consumption Time: 0.50127
Total Iteration Time: 7.64800

Cumulative Model Updates: 8,346
Cumulative Timesteps: 69,623,316

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 69623316...
Checkpoint 69623316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.29113
Policy Entropy: 4.31215
Value Function Loss: 0.02511

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02298
Policy Update Magnitude: 0.56593
Value Function Update Magnitude: 0.37698

Collected Steps per Second: 14,120.57864
Overall Steps per Second: 6,657.39048

Timestep Collection Time: 3.54291
Timestep Consumption Time: 3.97174
PPO Batch Consumption Time: 0.48346
Total Iteration Time: 7.51466

Cumulative Model Updates: 8,352
Cumulative Timesteps: 69,673,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 69673344...
Checkpoint 69673344 saved!
